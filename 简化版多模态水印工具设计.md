# 简化版多模态水印工具设计

## 🎯 项目目标

开发一个简单易用的多模态水印工具，支持：
- **文本水印**：基于CredID算法
- **图像水印**：基于Stable Signature算法
- **统一接口**：提供一致的嵌入和提取API

## 📁 简化目录结构

```
mmwt/                           # 多模态水印工具
├── README.md
├── requirements.txt
├── setup.py
├── config/
│   ├── text_config.yaml       # 文本水印配置
│   └── image_config.yaml      # 图像水印配置
├── src/
│   ├── __init__.py
│   ├── watermark_engine.py    # 统一水印引擎
│   ├── text_watermark/
│   │   ├── __init__.py
│   │   ├── credid_watermark.py # CredID算法封装
│   │   └── credid/             # CredID算法实现（从原项目复制）
│   ├── image_watermark/
│   │   ├── __init__.py
│   │   ├── stable_signature.py # Stable Signature算法封装
│   │   └── stable_sig/         # Stable Signature实现（从原项目复制）
│   └── utils/
│       ├── __init__.py
│       ├── config_loader.py    # 配置加载
│       └── model_manager.py    # 模型管理
├── examples/
│   ├── text_demo.py           # 文本水印演示
│   ├── image_demo.py          # 图像水印演示
│   └── unified_demo.py        # 统一接口演示
├── tests/
│   ├── test_text_watermark.py
│   └── test_image_watermark.py
└── models/                    # 预训练模型存储
```

## 🏗️ 核心架构设计

### 系统架构概览

本工具采用**分层模块化架构**，从上到下分为：
1. **用户接口层**：提供统一的API接口和使用示例
2. **核心引擎层**：WatermarkEngine统一管理所有水印操作
3. **算法实现层**：具体的水印算法封装和实现
4. **配置和工具层**：配置管理、模型管理等支持组件

### 1. 统一水印引擎 (WatermarkEngine)

**设计理念**：
- **单一入口**：用户只需要与WatermarkEngine交互，无需关心底层实现
- **懒加载**：只有在实际使用时才加载对应的算法模块，节省内存
- **配置驱动**：通过配置文件管理不同算法的参数

**核心实现**：

```python
# src/watermark_engine.py
import os
import yaml
from typing import Optional, Dict, Any

class WatermarkEngine:
    """
    多模态水印统一引擎
    
    功能职责：
    1. 提供统一的文本和图像水印接口
    2. 管理算法模块的懒加载
    3. 处理配置文件的加载和验证
    4. 协调不同模态间的操作
    """
    
    def __init__(self, base_dir: str = "."):
        """
        初始化水印引擎
        
        Args:
            base_dir: 项目根目录，用于定位配置文件
        """
        self.base_dir = base_dir
        self.text_watermark = None      # 文本水印模块实例
        self.image_watermark = None     # 图像水印模块实例
        self._config_cache = {}         # 配置文件缓存
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """
        加载并缓存配置文件
        
        Args:
            config_path: 配置文件路径
            
        Returns:
            解析后的配置字典
        """
        if config_path not in self._config_cache:
            full_path = os.path.join(self.base_dir, config_path)
            with open(full_path, 'r', encoding='utf-8') as f:
                self._config_cache[config_path] = yaml.safe_load(f)
        return self._config_cache[config_path]
    
    def setup_text_watermark(self, config_path: str = "config/text_config.yaml"):
        """
        初始化文本水印模块
        
        Args:
            config_path: 文本水印配置文件路径
        """
        from .text_watermark.credid_watermark import CredIDWatermark
        config = self._load_config(config_path)
        self.text_watermark = CredIDWatermark(config)
    
    def setup_image_watermark(self, config_path: str = "config/image_config.yaml"):
        """
        初始化图像水印模块
        
        Args:
            config_path: 图像水印配置文件路径
        """
        from .image_watermark.stable_signature import StableSignatureWatermark
        config = self._load_config(config_path)
        self.image_watermark = StableSignatureWatermark(config)
    
    # === 文本水印接口 ===
    def embed_text(self, model, tokenizer, prompt: str, message: str) -> Dict[str, Any]:
        """
        嵌入文本水印
        
        Args:
            model: 预训练语言模型 (HuggingFace model)
            tokenizer: 对应的分词器
            prompt: 输入提示文本
            message: 要嵌入的水印信息
            
        Returns:
            包含水印文本和元数据的字典
        """
        if not self.text_watermark:
            self.setup_text_watermark()
        return self.text_watermark.embed(model, tokenizer, prompt, message)
    
    def extract_text(self, watermarked_text: str) -> Dict[str, Any]:
        """
        提取文本水印
        
        Args:
            watermarked_text: 带有水印的文本
            
        Returns:
            包含提取信息和置信度的字典
        """
        if not self.text_watermark:
            self.setup_text_watermark()
        return self.text_watermark.extract(watermarked_text)
    
    # === 图像水印接口 ===
    def embed_image(self, model, prompt: str, message: str) -> Dict[str, Any]:
        """
        嵌入图像水印
        
        Args:
            model: 扩散模型 (如 Stable Diffusion)
            prompt: 图像生成提示词
            message: 要嵌入的水印信息
            
        Returns:
            包含水印图像和元数据的字典
        """
        if not self.image_watermark:
            self.setup_image_watermark()
        return self.image_watermark.embed(model, prompt, message)
    
    def extract_image(self, watermarked_image) -> Dict[str, Any]:
        """
        提取图像水印
        
        Args:
            watermarked_image: 带有水印的图像 (PIL Image 或路径)
            
        Returns:
            包含提取信息和置信度的字典
        """
        if not self.image_watermark:
            self.setup_image_watermark()
        return self.image_watermark.extract(watermarked_image)
    
    # === 工具方法 ===
    def get_config(self, config_type: str) -> Dict[str, Any]:
        """获取指定类型的配置"""
        config_map = {
            'text': 'config/text_config.yaml',
            'image': 'config/image_config.yaml'
        }
        return self._load_config(config_map[config_type])
    
    def reset(self):
        """重置引擎，清空缓存"""
        self.text_watermark = None
        self.image_watermark = None
        self._config_cache.clear()
```

### 2. 文本水印模块 (CredID Algorithm) ✅ **已实现**

**CredID算法原理**：
- **多位水印**：支持嵌入多段信息（如用户ID、时间戳、版本号等）
- **logits处理**：在语言模型的logits输出上进行修改，影响token选择概率
- **双模式支持**：LM模式（高质量）和Random模式（高效率）
- **候选优化**：支持候选消息列表的限制搜索，提升检测效率
- **智能分割**：自动处理复杂消息格式（如"log20250725143000"）

**实际实现的核心架构**：

```python
# src/text_watermark/credid_watermark.py
import torch
import logging
from typing import Dict, Any, List, Optional, Union, Tuple
from transformers import PreTrainedModel, PreTrainedTokenizer, LogitsProcessorList

class CredIDWatermark:
    """
    CredID文本水印算法统一封装
    
    ✨ 核心功能特点:
    1. 支持多种消息格式 (字符串、整数列表、字符串列表)
    2. 双模式运行: LM模式(高质量) / Random模式(高效率)
    3. 智能多段消息处理和自动分割
    4. 候选消息优化搜索机制
    5. 完整的错误处理和置信度评估
    6. 简化的代码结构，去除复杂的按位置分组逻辑
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        初始化CredID水印处理器
        
        Args:
            config: 配置字典，必须包含:
                - mode: 'lm' 或 'random' (默认'lm')
                - model_name: 预训练模型名称
                - lm_params: LM模式参数字典
                - wm_params: 水印处理参数字典
                - 其他生成参数 (max_new_tokens, num_beams等)
        """
        self.config = config
        self.mode = config.get('mode', 'lm')  # 默认LM模式
        self.model_name = config.get('model_name', 'huggyllama/llama-7b')
        
        # 算法核心参数
        self.lm_params = config.get('lm_params', {})
        self.wm_params = config.get('wm_params', {})
        
        # 延迟初始化的组件
        self.message_model = None
        self.tokenizer_ref = None
        
        logging.info(f"CredID初始化: 模式={self.mode}, 模型={self.model_name}")
```

**🔹 核心接口 1: embed() - 水印嵌入**

```python
    def embed(self, model: PreTrainedModel, tokenizer: PreTrainedTokenizer, 
              prompt: str, message: Union[str, List[int], List[str]], 
              segmentation_mode: str = 'auto') -> Dict[str, Any]:
        """
        🎯 核心功能: 在文本生成过程中嵌入水印
        
        📋 详细工作流程:
        1. 设置处理器 (如果还没设置)
        2. 将消息转换为CredID兼容的二进制格式 (支持多段)
        3. 创建包含水印处理器的LogitsProcessorList
        4. 使用model.generate()生成带水印文本
        5. 返回完整结果和详细元数据
        
        📥 参数说明:
            model: HuggingFace预训练语言模型 (如Llama, GPT等)
            tokenizer: 对应的分词器，必须设置pad_token
            prompt: 输入提示文本，如 "Hello, today is"
            message: 水印信息，支持多种格式:
                - str: "hello" 或复杂字符串 "log20250725143000"
                - List[int]: [123, 456, 789] 
                - List[str]: ["user", "2025", "admin"]
            segmentation_mode: 消息分割模式
                - 'auto': 自动判断最佳分割方式 (推荐)
                - 'smart': 智能分割，如 "alibaba20250725" → ["alibaba", "2025", "0725"]
                - 'whole': 整体处理
                - 'spaces': 按空格分割
                
        📤 返回值结构:
            {
                'watermarked_text': str,      # 🎯 带水印的生成文本
                'original_message': Any,      # 原始水印信息
                'binary_message': List[int],  # 转换后的二进制消息序列
                'prompt': str,                # 输入提示
                'success': bool,              # ✅/❌ 是否成功
                'metadata': {                 # 详细元数据
                    'mode': str,              # 使用的模式 ('lm'/'random')
                    'model_name': str,        # 模型名称
                    'input_length': int,      # 输入token长度
                    'output_length': int,     # 输出token长度
                    'generation_config': dict,# 生成配置参数
                    'num_message_segments': int # 消息段数
                }
            }
            
        🚨 错误情况返回:
            {
                'watermarked_text': None,
                'success': False,
                'error': str                  # 错误信息
            }
        """
```

**🔹 核心接口 2: extract() - 水印提取**

```python
    def extract(self, watermarked_text: str, 
                model: Optional[PreTrainedModel] = None,
                tokenizer: Optional[PreTrainedTokenizer] = None,
                candidates_messages: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        🎯 核心功能: 从水印文本中提取水印信息
        
        📋 详细工作流程:
        1. 检查模式和参数有效性 (LM模式需要model和tokenizer)
        2. 候选消息处理: 收集所有候选消息的所有编码段 (简化策略)
        3. 使用CredID解码器进行统计检测
        4. 智能匹配: 将解码结果与候选消息进行序列匹配
        5. 置信度计算和结果验证
        
        📥 参数说明:
            watermarked_text: 可能包含水印的文本
            model: 语言模型 (LM模式必需，Random模式可选)
            tokenizer: 分词器 (LM模式必需，Random模式可选)
            candidates_messages: 候选消息列表，用于优化搜索
                🎯 推荐使用: 可大幅提升检测精度和效率
                例如: ["log20250725143000", "user987654321", "admin2025"]
                
        📤 返回值结构:
            {
                'extracted_message': str,           # 🎯 提取的消息
                'binary_message': List[int],        # 解码的二进制消息序列
                'confidence': float,                # 🎚️ 置信度 (0.0-1.0)
                'success': bool,                    # ✅/❌ 是否成功提取
                'detailed_confidence': List,       # 详细置信度信息
                'metadata': {
                    'mode': str,                    # 检测模式
                    'text_length': int,             # 文本长度
                    'num_decoded_segments': int,    # 解码段数
                    'detection_method': 'CredID',   # 检测方法
                    'confidence_threshold': float,  # 置信度阈值
                    'search_space': int,            # 搜索空间大小
                    'candidates_provided': bool     # 是否提供候选消息
                }
            }
            
        🚨 失败情况返回:
            {
                'extracted_message': None,
                'confidence': 0.0,
                'success': False,
                'error': str                        # 错误或"No watermark detected"
            }
        """
```

**🔧 核心内部方法**

```python
    # === 消息处理方法 ===
    def _message_to_binary(self, message: Union[str, List[int], List[str]], 
                          segmentation_mode: str = 'auto') -> List[int]:
        """将多种格式的消息转换为CredID兼容的整数序列"""
        
    def _binary_to_message(self, binary: List[int]) -> Union[str, List[str]]:
        """将解码的整数序列转换回原始消息格式"""
        
    # === 智能匹配方法 ===  
    def _match_decoded_with_candidates(self, decoded_messages: List[int], 
                                     candidates_messages: List[str]) -> Tuple[str, float]:
        """将解码结果与候选消息进行智能匹配 (简化版本)"""
        
    def _calculate_sequence_match(self, decoded: List[int], candidate: List[int]) -> float:
        """计算两个序列的匹配度分数"""
        
    # === 字符串分割方法 ===
    def _smart_segment_string(self, text: str) -> List[str]:
        """智能分割字符串，支持复杂格式如'log20250725143000'"""
```

**⚙️ 配置参数详解**

```yaml
# config/text_config.yaml - 完整配置示例
method: "CredID"
model_name: "huggyllama/llama-7b"          
mode: "lm"                                 # 'lm'(高质量) / 'random'(高效率)
device: "auto"                             

# === 生成参数 ===
max_new_tokens: 110                        
num_beams: 4                               
do_sample: true                            
temperature: 0.7                           
top_p: 0.9                                
top_k: 50                                 

# === CredID LM模式核心参数 ===
lm_params:
  delta: 1.5                              # logits修改强度 (关键参数)
  prefix_len: 10                          # 前缀保护长度
  message_len: 10                         # 每段消息的二进制长度
  seed: 42                                # 随机种子
  topk: -1                               # LM top-k限制
  permutation_num: 50                     # 随机排列数
  hash_prefix_len: 1                      # 哈希前缀长度
  shifts: [21, 24, 3, 8, 14, 2, 4, 28, 31, 3, 8, 14, 2, 4, 28]

# === 水印处理参数 ===
wm_params:
  encode_ratio: 8                         # 编码比率 (每消息位对应的token数)
  seed: 42                                
  strategy: "vanilla"                     # 'vanilla'/'max_confidence'
  max_confidence: 0.5                     
  top_k: 1000                            

# === 解码配置 ===
decode_batch_size: 16                      
disable_tqdm: false                        
confidence_threshold: 0.6                  # 成功检测的置信度阈值
```

**🚀 实际使用示例和最佳实践**

```python
# === 完整使用示例 ===
from src.text_watermark.credid_watermark import CredIDWatermark
from transformers import AutoModelForCausalLM, AutoTokenizer
import yaml

# 1. 初始化系统
with open('config/text_config.yaml', 'r') as f:
    config = yaml.safe_load(f)

model = AutoModelForCausalLM.from_pretrained("huggyllama/llama-7b")
tokenizer = AutoTokenizer.from_pretrained("huggyllama/llama-7b")
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

watermark = CredIDWatermark(config)

# 2. 🎯 单一消息处理
result = watermark.embed(model, tokenizer, "Hello, today is", "tech")
if result['success']:
    print(f"✅ 生成文本: {result['watermarked_text']}")
    
    # 基础提取
    extracted = watermark.extract(result['watermarked_text'], model, tokenizer)
    print(f"📤 提取结果: {extracted['extracted_message']} (置信度: {extracted['confidence']:.3f})")

# 3. 🎯 复杂消息处理
complex_messages = [
    ("系统日志", "log20250725143000"),
    ("用户信息", "alibaba20250725"),
    ("管理账户", ["admin", "2025", "secure"])
]

for desc, message in complex_messages:
    result = watermark.embed(model, tokenizer, f"Entry: ", message)
    if result['success']:
        print(f"\n=== {desc} ===")
        print(f"消息: {message}")
        print(f"生成: {result['watermarked_text']}")
        
        # 🎯 候选优化提取
        candidates = ["log20250725143000", "alibaba20250725", "admin2025secure", "tech", "hello"]
        extracted = watermark.extract(
            result['watermarked_text'], 
            model, tokenizer, 
            candidates_messages=candidates
        )
        
        success_icon = "✅" if extracted['success'] else "❌"
        print(f"{success_icon} 提取: {extracted['extracted_message']} (置信度: {extracted['confidence']:.3f})")

# 4. 🎯 批量处理性能测试
import time

test_messages = ["hello", "tech2025", "user123", "log20250725143000"]
batch_start = time.time()

batch_results = []
for i, msg in enumerate(test_messages):
    embed_result = watermark.embed(model, tokenizer, f"Test {i}: ", msg)
    if embed_result['success']:
        extract_result = watermark.extract(embed_result['watermarked_text'], model, tokenizer)
        batch_results.append({
            'original': msg,
            'extracted': extract_result['extracted_message'],
            'confidence': extract_result['confidence'],
            'success': extract_result['success']
        })

batch_time = time.time() - batch_start
print(f"\n⏱️ 批量处理({len(test_messages)}条): {batch_time:.2f}秒")

# 5. 🎯 错误处理示例
try:
    # 模拟错误情况
    error_result = watermark.extract("This text has no watermark", model, tokenizer)
    if not error_result['success']:
        print(f"❌ 检测失败: {error_result.get('error', 'No watermark detected')}")
except Exception as e:
    print(f"🚨 异常处理: {e}")
```

**📊 性能和特点总结**

| 特性 | 描述 | 优势 |
|------|------|------|
| **多消息格式** | 支持字符串、列表、复杂格式 | 灵活性高，适应不同场景 |
| **双模式运行** | LM模式(高质量) / Random模式(高效率) | 平衡质量和性能 |
| **候选优化** | 限制搜索空间提升效率 | 大幅提升检测精度 |
| **智能分割** | 自动处理复杂消息格式 | 无需手动预处理 |
| **简化架构** | 去除复杂的按位置分组逻辑 | 代码更清晰，维护性好 |
| **错误处理** | 完整的异常处理机制 | 生产环境可靠性高 |
| **性能监控** | 内置时间和资源使用统计 | 便于性能调优 |

**🎯 为图像水印和统一引擎提供的设计参考:**

1. **🏗️ 统一接口模式**: `embed(model, tokenizer, prompt, message)` → `extract(text, model, tokenizer, candidates)`
2. **⚙️ 配置驱动设计**: 通过YAML文件管理所有算法参数
3. **📋 标准返回格式**: 统一的 `{success, result, metadata, error}` 结构
4. **🔍 候选优化机制**: 支持候选列表的高效搜索策略
5. **🎨 多模态消息**: 支持多种输入格式的智能编码
6. **🛡️ 健壮错误处理**: 详细的状态报告和异常管理
7. **📈 性能监控**: 内置时间和资源使用统计

这个设计为后续图像水印模块和统一引擎提供了清晰的架构模板！🚀 