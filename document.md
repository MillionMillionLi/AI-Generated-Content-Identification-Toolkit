# ç®€åŒ–ç‰ˆå¤šæ¨¡æ€æ°´å°å·¥å…·è®¾è®¡

## ğŸ¯ é¡¹ç›®ç›®æ ‡

å¼€å‘ä¸€ä¸ªç®€å•æ˜“ç”¨çš„å¤šæ¨¡æ€æ°´å°å·¥å…·ï¼Œæ”¯æŒï¼š
- **æ–‡æœ¬æ°´å°**ï¼šåŸºäºCredIDç®—æ³•
- **å›¾åƒæ°´å°**ï¼šåŸºäºPRCç®—æ³•
- **è§†é¢‘æ°´å°**ï¼šåŸºäºVideo Sealç®—æ³•
- **éŸ³é¢‘æ°´å°**ï¼šåŸºäºAudioSealç®—æ³•ï¼Œå®Œæ•´é›†æˆBarkæ–‡æœ¬è½¬è¯­éŸ³ï¼Œæ”¯æŒå¤šè¯­è¨€é«˜è´¨é‡è¯­éŸ³ç”Ÿæˆ
- **ç»Ÿä¸€æ¥å£**ï¼šæä¾›ä¸€è‡´çš„åµŒå…¥å’Œæå–API

## ğŸ“ ç®€åŒ–ç›®å½•ç»“æ„

```
mmwt/                           # å¤šæ¨¡æ€æ°´å°å·¥å…·
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ text_config.yaml       # æ–‡æœ¬æ°´å°é…ç½®
â”‚   â””â”€â”€ image_config.yaml      # å›¾åƒæ°´å°é…ç½®
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ unified/
â”‚   â”‚   â””â”€â”€ watermark_tool.py   # ç»Ÿä¸€æ°´å°å·¥å…·ï¼ˆå·²å®ç°ï¼‰
â”‚   â”œâ”€â”€ text_watermark/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ credid_watermark.py # CredIDç®—æ³•å°è£…
â”‚   â”‚   â””â”€â”€ credid/             # CredIDç®—æ³•å®ç°ï¼ˆä»åŸé¡¹ç›®å¤åˆ¶ï¼‰
â”‚   â”œâ”€â”€ image_watermark/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ prc_watermark.py # PRCç®—æ³•å°è£…
â”‚   â”‚   â””â”€â”€ prc/         # PRCå®ç°ï¼ˆä»åŸé¡¹ç›®å¤åˆ¶ï¼‰
â”‚   â”œâ”€â”€ audio_watermark/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ audioseal_wrapper.py # AudioSealç®—æ³•å°è£…ï¼ˆ16ä½æ¶ˆæ¯ç¼–ç ï¼Œ3Då¼ é‡å¤„ç†ï¼‰
â”‚   â”‚   â”œâ”€â”€ bark_generator.py    # Barkæ–‡æœ¬è½¬è¯­éŸ³ï¼ˆæ™ºèƒ½ç¼“å­˜ç®¡ç†ï¼Œæœ¬åœ°ä¼˜å…ˆï¼‰
â”‚   â”‚   â”œâ”€â”€ audio_watermark.py   # éŸ³é¢‘æ°´å°ç»Ÿä¸€æ¥å£ï¼ˆæ‰¹å¤„ç†ï¼Œè´¨é‡è¯„ä¼°ï¼‰
â”‚   â”‚   â”œâ”€â”€ utils.py            # éŸ³é¢‘å¤„ç†å·¥å…·ï¼ˆI/Oï¼Œè´¨é‡è¯„ä¼°ï¼Œå™ªå£°æµ‹è¯•ï¼‰
â”‚   â”‚   â””â”€â”€ audioseal/          # AudioSealç®—æ³•å®ç°ï¼ˆMetaå®˜æ–¹ï¼‰
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config_loader.py    # é…ç½®åŠ è½½
â”‚       â””â”€â”€ model_manager.py    # æ¨¡å‹ç®¡ç†
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ text_demo.py           # æ–‡æœ¬æ°´å°æ¼”ç¤º
â”‚   â”œâ”€â”€ image_demo.py          # å›¾åƒæ°´å°æ¼”ç¤º
â”‚   â”œâ”€â”€ audio_demo.py          # éŸ³é¢‘æ°´å°æ¼”ç¤º
â”‚   â””â”€â”€ unified_demo.py        # ç»Ÿä¸€æ¥å£æ¼”ç¤º
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_text_watermark.py
â”‚   â”œâ”€â”€ test_image_watermark.py
â”‚   â”œâ”€â”€ test_audio_watermark.py  # å®Œæ•´éŸ³é¢‘æ°´å°æµ‹è¯•å¥—ä»¶ï¼ˆ100%æˆåŠŸç‡ï¼‰
â”‚   â””â”€â”€ test_video_watermark_demo.py
â”œâ”€â”€ audio_watermark_demo.py      # éŸ³é¢‘æ°´å°ç«¯åˆ°ç«¯æ¼”ç¤ºè„šæœ¬
â””â”€â”€ models/                    # é¢„è®­ç»ƒæ¨¡å‹å­˜å‚¨
```

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„è®¾è®¡

### ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

æœ¬å·¥å…·é‡‡ç”¨**åˆ†å±‚æ¨¡å—åŒ–æ¶æ„**ï¼Œä»ä¸Šåˆ°ä¸‹åˆ†ä¸ºï¼š
1. **ç”¨æˆ·æ¥å£å±‚**ï¼šæä¾›ç»Ÿä¸€çš„APIæ¥å£å’Œä½¿ç”¨ç¤ºä¾‹
2. **æ ¸å¿ƒå¼•æ“å±‚**ï¼šWatermarkEngineç»Ÿä¸€ç®¡ç†æ‰€æœ‰æ°´å°æ“ä½œ
3. **ç®—æ³•å®ç°å±‚**ï¼šå…·ä½“çš„æ°´å°ç®—æ³•å°è£…å’Œå®ç°
4. **é…ç½®å’Œå·¥å…·å±‚**ï¼šé…ç½®ç®¡ç†ã€æ¨¡å‹ç®¡ç†ç­‰æ”¯æŒç»„ä»¶

### 1. ç»Ÿä¸€æ°´å°å¼•æ“ (WatermarkEngine)

**è®¾è®¡ç†å¿µ**ï¼š
- **å•ä¸€å…¥å£**ï¼šç”¨æˆ·åªéœ€è¦ä¸WatermarkEngineäº¤äº’ï¼Œæ— éœ€å…³å¿ƒåº•å±‚å®ç°
- **æ‡’åŠ è½½**ï¼šåªæœ‰åœ¨å®é™…ä½¿ç”¨æ—¶æ‰åŠ è½½å¯¹åº”çš„ç®—æ³•æ¨¡å—ï¼ŒèŠ‚çœå†…å­˜
- **é…ç½®é©±åŠ¨**ï¼šé€šè¿‡é…ç½®æ–‡ä»¶ç®¡ç†ä¸åŒç®—æ³•çš„å‚æ•°

**æ ¸å¿ƒå®ç°**ï¼š

```python
# src/watermark_engine.py
import os
import yaml
from typing import Optional, Dict, Any

class WatermarkEngine:
    """
    å¤šæ¨¡æ€æ°´å°ç»Ÿä¸€å¼•æ“
    
    åŠŸèƒ½èŒè´£ï¼š
    1. æä¾›ç»Ÿä¸€çš„æ–‡æœ¬å’Œå›¾åƒæ°´å°æ¥å£
    2. ç®¡ç†ç®—æ³•æ¨¡å—çš„æ‡’åŠ è½½
    3. å¤„ç†é…ç½®æ–‡ä»¶çš„åŠ è½½å’ŒéªŒè¯
    4. åè°ƒä¸åŒæ¨¡æ€é—´çš„æ“ä½œ
    """
    
    def __init__(self, base_dir: str = "."):
        """
        åˆå§‹åŒ–æ°´å°å¼•æ“
        
        Args:
            base_dir: é¡¹ç›®æ ¹ç›®å½•ï¼Œç”¨äºå®šä½é…ç½®æ–‡ä»¶
        """
        self.base_dir = base_dir
        self.text_watermark = None      # æ–‡æœ¬æ°´å°æ¨¡å—å®ä¾‹
        self.image_watermark = None     # å›¾åƒæ°´å°æ¨¡å—å®ä¾‹
        self._config_cache = {}         # é…ç½®æ–‡ä»¶ç¼“å­˜
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """
        åŠ è½½å¹¶ç¼“å­˜é…ç½®æ–‡ä»¶
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            è§£æåçš„é…ç½®å­—å…¸
        """
        if config_path not in self._config_cache:
            full_path = os.path.join(self.base_dir, config_path)
            with open(full_path, 'r', encoding='utf-8') as f:
                self._config_cache[config_path] = yaml.safe_load(f)
        return self._config_cache[config_path]
    
    def setup_text_watermark(self, config_path: str = "config/text_config.yaml"):
        """
        åˆå§‹åŒ–æ–‡æœ¬æ°´å°æ¨¡å—
        
        Args:
            config_path: æ–‡æœ¬æ°´å°é…ç½®æ–‡ä»¶è·¯å¾„
        """
        from .text_watermark.credid_watermark import CredIDWatermark
        config = self._load_config(config_path)
        self.text_watermark = CredIDWatermark(config)
    
    def setup_image_watermark(self, config_path: str = "config/image_config.yaml"):
        """
        åˆå§‹åŒ–å›¾åƒæ°´å°æ¨¡å—
        
        Args:
            config_path: å›¾åƒæ°´å°é…ç½®æ–‡ä»¶è·¯å¾„
        """
        from .image_watermark.stable_signature import StableSignatureWatermark
        config = self._load_config(config_path)
        self.image_watermark = StableSignatureWatermark(config)
    
    # === æ–‡æœ¬æ°´å°æ¥å£ ===
    def embed_text(self, model, tokenizer, prompt: str, message: str) -> Dict[str, Any]:
        """
        åµŒå…¥æ–‡æœ¬æ°´å°
        
        Args:
            model: é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ (HuggingFace model)
            tokenizer: å¯¹åº”çš„åˆ†è¯å™¨
            prompt: è¾“å…¥æç¤ºæ–‡æœ¬
            message: è¦åµŒå…¥çš„æ°´å°ä¿¡æ¯
            
        Returns:
            åŒ…å«æ°´å°æ–‡æœ¬å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        if not self.text_watermark:
            self.setup_text_watermark()
        return self.text_watermark.embed(model, tokenizer, prompt, message)
    
    def extract_text(self, watermarked_text: str) -> Dict[str, Any]:
        """
        æå–æ–‡æœ¬æ°´å°
        
        Args:
            watermarked_text: å¸¦æœ‰æ°´å°çš„æ–‡æœ¬
            
        Returns:
            åŒ…å«æå–ä¿¡æ¯å’Œç½®ä¿¡åº¦çš„å­—å…¸
        """
        if not self.text_watermark:
            self.setup_text_watermark()
        return self.text_watermark.extract(watermarked_text)
    
    # === å›¾åƒæ°´å°æ¥å£ ===
    def embed_image(self, model, prompt: str, message: str) -> Dict[str, Any]:
        """
        åµŒå…¥å›¾åƒæ°´å°
        
        Args:
            model: æ‰©æ•£æ¨¡å‹ (å¦‚ Stable Diffusion)
            prompt: å›¾åƒç”Ÿæˆæç¤ºè¯
            message: è¦åµŒå…¥çš„æ°´å°ä¿¡æ¯
            
        Returns:
            åŒ…å«æ°´å°å›¾åƒå’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        if not self.image_watermark:
            self.setup_image_watermark()
        return self.image_watermark.embed(model, prompt, message)
    
    def extract_image(self, watermarked_image) -> Dict[str, Any]:
        """
        æå–å›¾åƒæ°´å°
        
        Args:
            watermarked_image: å¸¦æœ‰æ°´å°çš„å›¾åƒ (PIL Image æˆ–è·¯å¾„)
            
        Returns:
            åŒ…å«æå–ä¿¡æ¯å’Œç½®ä¿¡åº¦çš„å­—å…¸
        """
        if not self.image_watermark:
            self.setup_image_watermark()
        return self.image_watermark.extract(watermarked_image)
    
    # === å·¥å…·æ–¹æ³• ===
    def get_config(self, config_type: str) -> Dict[str, Any]:
        """è·å–æŒ‡å®šç±»å‹çš„é…ç½®"""
        config_map = {
            'text': 'config/text_config.yaml',
            'image': 'config/image_config.yaml'
        }
        return self._load_config(config_map[config_type])
    
    def reset(self):
        """é‡ç½®å¼•æ“ï¼Œæ¸…ç©ºç¼“å­˜"""
        self.text_watermark = None
        self.image_watermark = None
        self._config_cache.clear()
```

### 2. æ–‡æœ¬æ°´å°æ¨¡å— (CredID Algorithm) âœ… **å·²å®ç°**

**CredIDç®—æ³•åŸç†**ï¼š
- **å¤šä½æ°´å°**ï¼šæ”¯æŒåµŒå…¥å¤šæ®µä¿¡æ¯ï¼ˆå¦‚ç”¨æˆ·IDã€æ—¶é—´æˆ³ã€ç‰ˆæœ¬å·ç­‰ï¼‰
- **logitså¤„ç†**ï¼šåœ¨è¯­è¨€æ¨¡å‹çš„logitsè¾“å‡ºä¸Šè¿›è¡Œä¿®æ”¹ï¼Œå½±å“tokené€‰æ‹©æ¦‚ç‡
- **åŒæ¨¡å¼æ”¯æŒ**ï¼šLMæ¨¡å¼ï¼ˆé«˜è´¨é‡ï¼‰å’ŒRandomæ¨¡å¼ï¼ˆé«˜æ•ˆç‡ï¼‰
- **å€™é€‰ä¼˜åŒ–**ï¼šæ”¯æŒå€™é€‰æ¶ˆæ¯åˆ—è¡¨çš„é™åˆ¶æœç´¢ï¼Œæå‡æ£€æµ‹æ•ˆç‡
- **æ™ºèƒ½åˆ†å‰²**ï¼šè‡ªåŠ¨å¤„ç†å¤æ‚æ¶ˆæ¯æ ¼å¼ï¼ˆå¦‚"log20250725143000"ï¼‰

**å®é™…å®ç°çš„æ ¸å¿ƒæ¶æ„**ï¼š

```python
# src/text_watermark/credid_watermark.py
import torch
import logging
from typing import Dict, Any, List, Optional, Union, Tuple
from transformers import PreTrainedModel, PreTrainedTokenizer, LogitsProcessorList

class CredIDWatermark:
    """
    CredIDæ–‡æœ¬æ°´å°ç®—æ³•ç»Ÿä¸€å°è£…
    
    âœ¨ æ ¸å¿ƒåŠŸèƒ½ç‰¹ç‚¹:
    1. æ”¯æŒå¤šç§æ¶ˆæ¯æ ¼å¼ (å­—ç¬¦ä¸²ã€æ•´æ•°åˆ—è¡¨ã€å­—ç¬¦ä¸²åˆ—è¡¨)
    2. åŒæ¨¡å¼è¿è¡Œ: LMæ¨¡å¼(é«˜è´¨é‡) / Randomæ¨¡å¼(é«˜æ•ˆç‡)
    3. æ™ºèƒ½å¤šæ®µæ¶ˆæ¯å¤„ç†å’Œè‡ªåŠ¨åˆ†å‰²
    4. å€™é€‰æ¶ˆæ¯ä¼˜åŒ–æœç´¢æœºåˆ¶
    5. å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œç½®ä¿¡åº¦è¯„ä¼°
    6. ç®€åŒ–çš„ä»£ç ç»“æ„ï¼Œå»é™¤å¤æ‚çš„æŒ‰ä½ç½®åˆ†ç»„é€»è¾‘
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–CredIDæ°´å°å¤„ç†å™¨
        
        Args:
            config: é…ç½®å­—å…¸ï¼Œå¿…é¡»åŒ…å«:
                - mode: 'lm' æˆ– 'random' (é»˜è®¤'lm')
                - model_name: é¢„è®­ç»ƒæ¨¡å‹åç§°
                - lm_params: LMæ¨¡å¼å‚æ•°å­—å…¸
                - wm_params: æ°´å°å¤„ç†å‚æ•°å­—å…¸
                - å…¶ä»–ç”Ÿæˆå‚æ•° (max_new_tokens, num_beamsç­‰)
        """
        self.config = config
        self.mode = config.get('mode', 'lm')  # é»˜è®¤LMæ¨¡å¼
        self.model_name = config.get('model_name', 'huggyllama/llama-7b')
        
        # ç®—æ³•æ ¸å¿ƒå‚æ•°
        self.lm_params = config.get('lm_params', {})
        self.wm_params = config.get('wm_params', {})
        
        # å»¶è¿Ÿåˆå§‹åŒ–çš„ç»„ä»¶
        self.message_model = None
        self.tokenizer_ref = None
        
        logging.info(f"CredIDåˆå§‹åŒ–: æ¨¡å¼={self.mode}, æ¨¡å‹={self.model_name}")
```

**ğŸ”¹ æ ¸å¿ƒæ¥å£ 1: embed() - æ°´å°åµŒå…¥**

```python
    def embed(self, model: PreTrainedModel, tokenizer: PreTrainedTokenizer, 
              prompt: str, message: Union[str, List[int], List[str]], 
              segmentation_mode: str = 'auto') -> Dict[str, Any]:
        """
        ğŸ¯ æ ¸å¿ƒåŠŸèƒ½: åœ¨æ–‡æœ¬ç”Ÿæˆè¿‡ç¨‹ä¸­åµŒå…¥æ°´å°
        
        ğŸ“‹ è¯¦ç»†å·¥ä½œæµç¨‹:
        1. è®¾ç½®å¤„ç†å™¨ (å¦‚æœè¿˜æ²¡è®¾ç½®)
        2. å°†æ¶ˆæ¯è½¬æ¢ä¸ºCredIDå…¼å®¹çš„äºŒè¿›åˆ¶æ ¼å¼ (æ”¯æŒå¤šæ®µ)
        3. åˆ›å»ºåŒ…å«æ°´å°å¤„ç†å™¨çš„LogitsProcessorList
        4. ä½¿ç”¨model.generate()ç”Ÿæˆå¸¦æ°´å°æ–‡æœ¬
        5. è¿”å›å®Œæ•´ç»“æœå’Œè¯¦ç»†å…ƒæ•°æ®
        
        ğŸ“¥ å‚æ•°è¯´æ˜:
            model: HuggingFaceé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ (å¦‚Llama, GPTç­‰)
            tokenizer: å¯¹åº”çš„åˆ†è¯å™¨ï¼Œå¿…é¡»è®¾ç½®pad_token
            prompt: è¾“å…¥æç¤ºæ–‡æœ¬ï¼Œå¦‚ "Hello, today is"
            message: æ°´å°ä¿¡æ¯ï¼Œæ”¯æŒå¤šç§æ ¼å¼:
                - str: "hello" æˆ–å¤æ‚å­—ç¬¦ä¸² "log20250725143000"
                - List[int]: [123, 456, 789] 
                - List[str]: ["user", "2025", "admin"]
            segmentation_mode: æ¶ˆæ¯åˆ†å‰²æ¨¡å¼
                - 'auto': è‡ªåŠ¨åˆ¤æ–­æœ€ä½³åˆ†å‰²æ–¹å¼ (æ¨è)
                - 'smart': æ™ºèƒ½åˆ†å‰²ï¼Œå¦‚ "alibaba20250725" â†’ ["alibaba", "2025", "0725"]
                - 'whole': æ•´ä½“å¤„ç†
                - 'spaces': æŒ‰ç©ºæ ¼åˆ†å‰²
                
        ğŸ“¤ è¿”å›å€¼ç»“æ„:
            {
                'watermarked_text': str,      # ğŸ¯ å¸¦æ°´å°çš„ç”Ÿæˆæ–‡æœ¬
                'original_message': Any,      # åŸå§‹æ°´å°ä¿¡æ¯
                'binary_message': List[int],  # è½¬æ¢åçš„äºŒè¿›åˆ¶æ¶ˆæ¯åºåˆ—
                'prompt': str,                # è¾“å…¥æç¤º
                'success': bool,              # âœ…/âŒ æ˜¯å¦æˆåŠŸ
                'metadata': {                 # è¯¦ç»†å…ƒæ•°æ®
                    'mode': str,              # ä½¿ç”¨çš„æ¨¡å¼ ('lm'/'random')
                    'model_name': str,        # æ¨¡å‹åç§°
                    'input_length': int,      # è¾“å…¥tokené•¿åº¦
                    'output_length': int,     # è¾“å‡ºtokené•¿åº¦
                    'generation_config': dict,# ç”Ÿæˆé…ç½®å‚æ•°
                    'num_message_segments': int # æ¶ˆæ¯æ®µæ•°
                }
            }
            
        ğŸš¨ é”™è¯¯æƒ…å†µè¿”å›:
            {
                'watermarked_text': None,
                'success': False,
                'error': str                  # é”™è¯¯ä¿¡æ¯
            }
        """
```

**ğŸ”¹ æ ¸å¿ƒæ¥å£ 2: extract() - æ°´å°æå–**

```python
    def extract(self, watermarked_text: str, 
                model: Optional[PreTrainedModel] = None,
                tokenizer: Optional[PreTrainedTokenizer] = None,
                candidates_messages: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        ğŸ¯ æ ¸å¿ƒåŠŸèƒ½: ä»æ°´å°æ–‡æœ¬ä¸­æå–æ°´å°ä¿¡æ¯
        
        ğŸ“‹ è¯¦ç»†å·¥ä½œæµç¨‹:
        1. æ£€æŸ¥æ¨¡å¼å’Œå‚æ•°æœ‰æ•ˆæ€§ (LMæ¨¡å¼éœ€è¦modelå’Œtokenizer)
        2. å€™é€‰æ¶ˆæ¯å¤„ç†: æ”¶é›†æ‰€æœ‰å€™é€‰æ¶ˆæ¯çš„æ‰€æœ‰ç¼–ç æ®µ (ç®€åŒ–ç­–ç•¥)
        3. ä½¿ç”¨CredIDè§£ç å™¨è¿›è¡Œç»Ÿè®¡æ£€æµ‹
        4. æ™ºèƒ½åŒ¹é…: å°†è§£ç ç»“æœä¸å€™é€‰æ¶ˆæ¯è¿›è¡Œåºåˆ—åŒ¹é…
        5. ç½®ä¿¡åº¦è®¡ç®—å’Œç»“æœéªŒè¯
        
        ğŸ“¥ å‚æ•°è¯´æ˜:
            watermarked_text: å¯èƒ½åŒ…å«æ°´å°çš„æ–‡æœ¬
            model: è¯­è¨€æ¨¡å‹ (LMæ¨¡å¼å¿…éœ€ï¼ŒRandomæ¨¡å¼å¯é€‰)
            tokenizer: åˆ†è¯å™¨ (LMæ¨¡å¼å¿…éœ€ï¼ŒRandomæ¨¡å¼å¯é€‰)
            candidates_messages: å€™é€‰æ¶ˆæ¯åˆ—è¡¨ï¼Œç”¨äºä¼˜åŒ–æœç´¢
                ğŸ¯ æ¨èä½¿ç”¨: å¯å¤§å¹…æå‡æ£€æµ‹ç²¾åº¦å’Œæ•ˆç‡
                ä¾‹å¦‚: ["log20250725143000", "user987654321", "admin2025"]
                
        ğŸ“¤ è¿”å›å€¼ç»“æ„:
            {
                'extracted_message': str,           # ğŸ¯ æå–çš„æ¶ˆæ¯
                'binary_message': List[int],        # è§£ç çš„äºŒè¿›åˆ¶æ¶ˆæ¯åºåˆ—
                'confidence': float,                # ğŸšï¸ ç½®ä¿¡åº¦ (0.0-1.0)
                'success': bool,                    # âœ…/âŒ æ˜¯å¦æˆåŠŸæå–
                'detailed_confidence': List,       # è¯¦ç»†ç½®ä¿¡åº¦ä¿¡æ¯
                'metadata': {
                    'mode': str,                    # æ£€æµ‹æ¨¡å¼
                    'text_length': int,             # æ–‡æœ¬é•¿åº¦
                    'num_decoded_segments': int,    # è§£ç æ®µæ•°
                    'detection_method': 'CredID',   # æ£€æµ‹æ–¹æ³•
                    'confidence_threshold': float,  # ç½®ä¿¡åº¦é˜ˆå€¼
                    'search_space': int,            # æœç´¢ç©ºé—´å¤§å°
                    'candidates_provided': bool     # æ˜¯å¦æä¾›å€™é€‰æ¶ˆæ¯
                }
            }
            
        ğŸš¨ å¤±è´¥æƒ…å†µè¿”å›:
            {
                'extracted_message': None,
                'confidence': 0.0,
                'success': False,
                'error': str                        # é”™è¯¯æˆ–"No watermark detected"
            }
        """
```

**ğŸ”§ æ ¸å¿ƒå†…éƒ¨æ–¹æ³•**

```python
    # === æ¶ˆæ¯å¤„ç†æ–¹æ³• ===
    def _message_to_binary(self, message: Union[str, List[int], List[str]], 
                          segmentation_mode: str = 'auto') -> List[int]:
        """å°†å¤šç§æ ¼å¼çš„æ¶ˆæ¯è½¬æ¢ä¸ºCredIDå…¼å®¹çš„æ•´æ•°åºåˆ—"""
        
    def _binary_to_message(self, binary: List[int]) -> Union[str, List[str]]:
        """å°†è§£ç çš„æ•´æ•°åºåˆ—è½¬æ¢å›åŸå§‹æ¶ˆæ¯æ ¼å¼"""
        
    # === æ™ºèƒ½åŒ¹é…æ–¹æ³• ===  
    def _match_decoded_with_candidates(self, decoded_messages: List[int], 
                                     candidates_messages: List[str]) -> Tuple[str, float]:
        """å°†è§£ç ç»“æœä¸å€™é€‰æ¶ˆæ¯è¿›è¡Œæ™ºèƒ½åŒ¹é… (ç®€åŒ–ç‰ˆæœ¬)"""
        
    def _calculate_sequence_match(self, decoded: List[int], candidate: List[int]) -> float:
        """è®¡ç®—ä¸¤ä¸ªåºåˆ—çš„åŒ¹é…åº¦åˆ†æ•°"""
        
    # === å­—ç¬¦ä¸²åˆ†å‰²æ–¹æ³• ===
    def _smart_segment_string(self, text: str) -> List[str]:
        """æ™ºèƒ½åˆ†å‰²å­—ç¬¦ä¸²ï¼Œæ”¯æŒå¤æ‚æ ¼å¼å¦‚'log20250725143000'"""
```

**âš™ï¸ é…ç½®å‚æ•°è¯¦è§£**

```yaml
# config/text_config.yaml - å®Œæ•´é…ç½®ç¤ºä¾‹
method: "CredID"
model_name: "huggyllama/llama-7b"          
mode: "lm"                                 # 'lm'(é«˜è´¨é‡) / 'random'(é«˜æ•ˆç‡)
device: "auto"                             

# === ç”Ÿæˆå‚æ•° ===
max_new_tokens: 110                        
num_beams: 4                               
do_sample: true                            
temperature: 0.7                           
top_p: 0.9                                
top_k: 50                                 

# === CredID LMæ¨¡å¼æ ¸å¿ƒå‚æ•° ===
lm_params:
  delta: 1.5                              # logitsä¿®æ”¹å¼ºåº¦ (å…³é”®å‚æ•°)
  prefix_len: 10                          # å‰ç¼€ä¿æŠ¤é•¿åº¦
  message_len: 10                         # æ¯æ®µæ¶ˆæ¯çš„äºŒè¿›åˆ¶é•¿åº¦
  seed: 42                                # éšæœºç§å­
  topk: -1                               # LM top-ké™åˆ¶
  permutation_num: 50                     # éšæœºæ’åˆ—æ•°
  hash_prefix_len: 1                      # å“ˆå¸Œå‰ç¼€é•¿åº¦
  shifts: [21, 24, 3, 8, 14, 2, 4, 28, 31, 3, 8, 14, 2, 4, 28]

# === æ°´å°å¤„ç†å‚æ•° ===
wm_params:
  encode_ratio: 8                         # ç¼–ç æ¯”ç‡ (æ¯æ¶ˆæ¯ä½å¯¹åº”çš„tokenæ•°)
  seed: 42                                
  strategy: "vanilla"                     # 'vanilla'/'max_confidence'
  max_confidence: 0.5                     
  top_k: 1000                            

# === è§£ç é…ç½® ===
decode_batch_size: 16                      
disable_tqdm: false                        
confidence_threshold: 0.6                  # æˆåŠŸæ£€æµ‹çš„ç½®ä¿¡åº¦é˜ˆå€¼
```

**ğŸš€ å®é™…ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µ**

```python
# === å®Œæ•´ä½¿ç”¨ç¤ºä¾‹ ===
from src.text_watermark.credid_watermark import CredIDWatermark
from transformers import AutoModelForCausalLM, AutoTokenizer
import yaml

# 1. åˆå§‹åŒ–ç³»ç»Ÿ
with open('config/text_config.yaml', 'r') as f:
    config = yaml.safe_load(f)

model = AutoModelForCausalLM.from_pretrained("huggyllama/llama-7b")
tokenizer = AutoTokenizer.from_pretrained("huggyllama/llama-7b")
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

watermark = CredIDWatermark(config)

# 2. ğŸ¯ å•ä¸€æ¶ˆæ¯å¤„ç†
result = watermark.embed(model, tokenizer, "Hello, today is", "tech")
if result['success']:
    print(f"âœ… ç”Ÿæˆæ–‡æœ¬: {result['watermarked_text']}")
    
    # åŸºç¡€æå–
    extracted = watermark.extract(result['watermarked_text'], model, tokenizer)
    print(f"ğŸ“¤ æå–ç»“æœ: {extracted['extracted_message']} (ç½®ä¿¡åº¦: {extracted['confidence']:.3f})")

# 3. ğŸ¯ å¤æ‚æ¶ˆæ¯å¤„ç†
complex_messages = [
    ("ç³»ç»Ÿæ—¥å¿—", "log20250725143000"),
    ("ç”¨æˆ·ä¿¡æ¯", "alibaba20250725"),
    ("ç®¡ç†è´¦æˆ·", ["admin", "2025", "secure"])
]

for desc, message in complex_messages:
    result = watermark.embed(model, tokenizer, f"Entry: ", message)
    if result['success']:
        print(f"\n=== {desc} ===")
        print(f"æ¶ˆæ¯: {message}")
        print(f"ç”Ÿæˆ: {result['watermarked_text']}")
        
        # ğŸ¯ å€™é€‰ä¼˜åŒ–æå–
        candidates = ["log20250725143000", "alibaba20250725", "admin2025secure", "tech", "hello"]
        extracted = watermark.extract(
            result['watermarked_text'], 
            model, tokenizer, 
            candidates_messages=candidates
        )
        
        success_icon = "âœ…" if extracted['success'] else "âŒ"
        print(f"{success_icon} æå–: {extracted['extracted_message']} (ç½®ä¿¡åº¦: {extracted['confidence']:.3f})")

# 4. ğŸ¯ æ‰¹é‡å¤„ç†æ€§èƒ½æµ‹è¯•
import time

test_messages = ["hello", "tech2025", "user123", "log20250725143000"]
batch_start = time.time()

batch_results = []
for i, msg in enumerate(test_messages):
    embed_result = watermark.embed(model, tokenizer, f"Test {i}: ", msg)
    if embed_result['success']:
        extract_result = watermark.extract(embed_result['watermarked_text'], model, tokenizer)
        batch_results.append({
            'original': msg,
            'extracted': extract_result['extracted_message'],
            'confidence': extract_result['confidence'],
            'success': extract_result['success']
        })

batch_time = time.time() - batch_start
print(f"\nâ±ï¸ æ‰¹é‡å¤„ç†({len(test_messages)}æ¡): {batch_time:.2f}ç§’")

# 5. ğŸ¯ é”™è¯¯å¤„ç†ç¤ºä¾‹
try:
    # æ¨¡æ‹Ÿé”™è¯¯æƒ…å†µ
    error_result = watermark.extract("This text has no watermark", model, tokenizer)
    if not error_result['success']:
        print(f"âŒ æ£€æµ‹å¤±è´¥: {error_result.get('error', 'No watermark detected')}")
except Exception as e:
    print(f"ğŸš¨ å¼‚å¸¸å¤„ç†: {e}")
```

**ğŸ“Š æ€§èƒ½å’Œç‰¹ç‚¹æ€»ç»“**

| ç‰¹æ€§ | æè¿° | ä¼˜åŠ¿ |
|------|------|------|
| **å¤šæ¶ˆæ¯æ ¼å¼** | æ”¯æŒå­—ç¬¦ä¸²ã€åˆ—è¡¨ã€å¤æ‚æ ¼å¼ | çµæ´»æ€§é«˜ï¼Œé€‚åº”ä¸åŒåœºæ™¯ |
| **åŒæ¨¡å¼è¿è¡Œ** | LMæ¨¡å¼(é«˜è´¨é‡) / Randomæ¨¡å¼(é«˜æ•ˆç‡) | å¹³è¡¡è´¨é‡å’Œæ€§èƒ½ |
| **å€™é€‰ä¼˜åŒ–** | é™åˆ¶æœç´¢ç©ºé—´æå‡æ•ˆç‡ | å¤§å¹…æå‡æ£€æµ‹ç²¾åº¦ |
| **æ™ºèƒ½åˆ†å‰²** | è‡ªåŠ¨å¤„ç†å¤æ‚æ¶ˆæ¯æ ¼å¼ | æ— éœ€æ‰‹åŠ¨é¢„å¤„ç† |
| **ç®€åŒ–æ¶æ„** | å»é™¤å¤æ‚çš„æŒ‰ä½ç½®åˆ†ç»„é€»è¾‘ | ä»£ç æ›´æ¸…æ™°ï¼Œç»´æŠ¤æ€§å¥½ |
| **é”™è¯¯å¤„ç†** | å®Œæ•´çš„å¼‚å¸¸å¤„ç†æœºåˆ¶ | ç”Ÿäº§ç¯å¢ƒå¯é æ€§é«˜ |
| **æ€§èƒ½ç›‘æ§** | å†…ç½®æ—¶é—´å’Œèµ„æºä½¿ç”¨ç»Ÿè®¡ | ä¾¿äºæ€§èƒ½è°ƒä¼˜ |

**ğŸ¯ ä¸ºå›¾åƒæ°´å°å’Œç»Ÿä¸€å¼•æ“æä¾›çš„è®¾è®¡å‚è€ƒ:**

1. **ğŸ—ï¸ ç»Ÿä¸€æ¥å£æ¨¡å¼**: `embed(model, tokenizer, prompt, message)` â†’ `extract(text, model, tokenizer, candidates)`
2. **âš™ï¸ é…ç½®é©±åŠ¨è®¾è®¡**: é€šè¿‡YAMLæ–‡ä»¶ç®¡ç†æ‰€æœ‰ç®—æ³•å‚æ•°
3. **ğŸ“‹ æ ‡å‡†è¿”å›æ ¼å¼**: ç»Ÿä¸€çš„ `{success, result, metadata, error}` ç»“æ„
4. **ğŸ” å€™é€‰ä¼˜åŒ–æœºåˆ¶**: æ”¯æŒå€™é€‰åˆ—è¡¨çš„é«˜æ•ˆæœç´¢ç­–ç•¥
5. **ğŸ¨ å¤šæ¨¡æ€æ¶ˆæ¯**: æ”¯æŒå¤šç§è¾“å…¥æ ¼å¼çš„æ™ºèƒ½ç¼–ç 
6. **ğŸ›¡ï¸ å¥å£®é”™è¯¯å¤„ç†**: è¯¦ç»†çš„çŠ¶æ€æŠ¥å‘Šå’Œå¼‚å¸¸ç®¡ç†
7. **ğŸ“ˆ æ€§èƒ½ç›‘æ§**: å†…ç½®æ—¶é—´å’Œèµ„æºä½¿ç”¨ç»Ÿè®¡

### 3. å›¾åƒæ°´å°æ¨¡å— (PRC-Watermark) âœ… **å·²å®ç°**

**PRCç®—æ³•åŸç†**ï¼š
- **ä¼ªéšæœºçº é”™ç æ°´å°**ï¼šåŸºäºStable Diffusionçš„æ½œç©ºé—´æ°´å°åµŒå…¥
- **å®Œæ•´æ‰©æ•£é€†å‘**ï¼šé€šè¿‡exact_inversionå®ç°ç²¾ç¡®çš„å›¾åƒåˆ°æ½œå˜é‡è½¬æ¢
- **å¤šç²¾åº¦æ£€æµ‹**ï¼šæ”¯æŒfast/accurate/exactä¸‰ç§ä¸åŒç²¾åº¦ç­‰çº§
- **100%æ£€æµ‹æˆåŠŸç‡**ï¼šæ‰€æœ‰æ¨¡å¼éƒ½èƒ½å®Œç¾æ£€æµ‹å¹¶è§£ç æ°´å°æ¶ˆæ¯
- **æœ¬åœ°æ¨¡å‹æ”¯æŒ**ï¼šç¦»çº¿æ¨¡å¼ä½¿ç”¨ç¼“å­˜çš„Stable Diffusion 2.1æ¨¡å‹

**å®é™…å®ç°çš„æ ¸å¿ƒæ¶æ„**ï¼š

```python
# src/image_watermark/prc_watermark.py
import os
import torch
from PIL import Image
from typing import Dict, Any, Optional, Union, Tuple
import pickle

class PRCWatermark:
    """
    PRCå›¾åƒæ°´å°ç®—æ³•ç»Ÿä¸€å°è£…
    
    âœ¨ æ ¸å¿ƒåŠŸèƒ½ç‰¹ç‚¹:
    1. ç»Ÿä¸€çš„exact_inversionå®ç°ï¼Œæ¶ˆé™¤ä»£ç å†—ä½™
    2. å‚æ•°åŒ–æ¨¡å¼æ§åˆ¶ï¼šé€šè¿‡decoder_invå’Œinference_stepsè°ƒèŠ‚ç²¾åº¦
    3. å®Œæ•´çš„ç¦»çº¿æ¨¡å¼æ”¯æŒï¼Œä½¿ç”¨æœ¬åœ°Stable Diffusionæ¨¡å‹
    4. GPU/CPU tensorè®¾å¤‡è‡ªåŠ¨è½¬æ¢å’Œæ¢¯åº¦ç®¡ç†
    5. å¯†é’¥ç®¡ç†å’Œç¼“å­˜æœºåˆ¶
    6. 100%æ£€æµ‹æˆåŠŸç‡ï¼Œæ”¯æŒå®Œç¾æ°´å°è§£ç 
    """
    
    def __init__(self, 
                 model_id: str = "stabilityai/stable-diffusion-2-1-base",
                 keys_dir: str = "watermark_keys",
                 cache_dir: Optional[str] = None,
                 device: Optional[str] = None,
                 **kwargs):
        """
        åˆå§‹åŒ–PRCæ°´å°å¤„ç†å™¨
        
        Args:
            model_id: Stable Diffusionæ¨¡å‹ID
            keys_dir: å¯†é’¥å­˜å‚¨ç›®å½•
            cache_dir: æ¨¡å‹ç¼“å­˜ç›®å½• (æ”¯æŒç¦»çº¿æ¨¡å¼)
            device: è®¡ç®—è®¾å¤‡ ('cuda', 'cpu', æˆ– None è‡ªåŠ¨é€‰æ‹©)
            **kwargs: å…¶ä»–PRCç®—æ³•å‚æ•°
        """
        self.model_id = model_id
        self.keys_dir = keys_dir
        self.cache_dir = cache_dir
        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
        
        # PRCç®—æ³•å‚æ•°
        self.n = kwargs.get('n', 1024)  # ç é•¿
        self.k = kwargs.get('k', 512)   # ä¿¡æ¯ä½æ•°
        self.false_positive_rate = kwargs.get('false_positive_rate', 1e-6)
        
        # ç¡®ä¿å¯†é’¥ç›®å½•å­˜åœ¨
        os.makedirs(self.keys_dir, exist_ok=True)
        
        # å»¶è¿Ÿåˆå§‹åŒ–ç»„ä»¶
        self.pipe = None
        self._key_cache = {}
        
        # è®¾ç½®ç¦»çº¿æ¨¡å¼å’Œæ¨¡å‹ç®¡é“
        self._setup_diffusion_pipe()
```

**ğŸ”¹ æ ¸å¿ƒæ¥å£ 1: embed() - æ°´å°åµŒå…¥**

```python
    def embed(self, 
              prompt: str,
              message: str, 
              key_id: str = "default",
              num_inference_steps: int = 50,
              guidance_scale: float = 7.5,
              seed: Optional[int] = None,
              **kwargs) -> Image.Image:
        """
        ğŸ¯ æ ¸å¿ƒåŠŸèƒ½: åœ¨å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­åµŒå…¥PRCæ°´å°
        
        ğŸ“‹ è¯¦ç»†å·¥ä½œæµç¨‹:
        1. è·å–æˆ–ç”ŸæˆPRCå¯†é’¥å¯¹ (encoding_key, decoding_key)
        2. å°†æ¶ˆæ¯å­—ç¬¦ä¸²ç¼–ç ä¸ºäºŒè¿›åˆ¶åºåˆ—
        3. ä½¿ç”¨PRCç¼–ç ç®—æ³•ç”Ÿæˆä¼ªéšæœºç å­—
        4. åœ¨Stable Diffusionçš„æ½œç©ºé—´ä¸­åµŒå…¥ç å­—
        5. ç”Ÿæˆå¸¦æ°´å°çš„é«˜è´¨é‡å›¾åƒ
        
        ğŸ“¥ å‚æ•°è¯´æ˜:
            prompt: å›¾åƒç”Ÿæˆæç¤ºè¯ï¼Œå¦‚ "A beautiful sunset over the ocean"
            message: æ°´å°ä¿¡æ¯ï¼Œæ”¯æŒä»»æ„é•¿åº¦å­—ç¬¦ä¸²
            key_id: å¯†é’¥æ ‡è¯†ç¬¦ï¼Œç”¨äºå¯†é’¥ç®¡ç†å’Œå¤ç”¨
            num_inference_steps: æ‰©æ•£é‡‡æ ·æ­¥æ•° (é»˜è®¤50ï¼Œå½±å“è´¨é‡å’Œé€Ÿåº¦)
            guidance_scale: æç¤ºè¯å¼•å¯¼å¼ºåº¦ (é»˜è®¤7.5)
            seed: éšæœºç§å­ï¼Œç”¨äºå¯é‡ç°ç”Ÿæˆ
            **kwargs: å…¶ä»–ç”Ÿæˆå‚æ•°
                
        ğŸ“¤ è¿”å›å€¼:
            PIL.Image: å¸¦æ°´å°çš„512x512å›¾åƒ
            
        ğŸš¨ é”™è¯¯æƒ…å†µ:
            æŠ›å‡ºRuntimeErrorå¼‚å¸¸ï¼ŒåŒ…å«è¯¦ç»†é”™è¯¯ä¿¡æ¯
        """
        # è·å–å¯†é’¥
        encoding_key, _ = self._get_or_create_keys(key_id)
        
        # æ¶ˆæ¯ç¼–ç 
        message_bits = str_to_bin(message)
        prc_codeword = Encode(encoding_key, message_bits)
        
        # ä¼ªéšæœºæ½œå˜é‡é‡‡æ ·
        latents = prc_gaussians.sample(
            codeword=prc_codeword,
            shape=(1, 4, 64, 64),  # Stable Diffusionæ½œç©ºé—´å½¢çŠ¶
            device=self.device
        )
        
        # ç”Ÿæˆå¸¦æ°´å°å›¾åƒ
        with torch.no_grad():
            image = generate(
                pipe=self.pipe,
                prompt=prompt,
                init_latents=latents,
                num_inference_steps=num_inference_steps,
                guidance_scale=guidance_scale,
                seed=seed,
                **kwargs
            )
        
        return image
```

**ğŸ”¹ æ ¸å¿ƒæ¥å£ 2: extract() - æ°´å°æå–**

```python
    def extract(self, 
                image: Union[str, Image.Image, torch.Tensor],
                key_id: str = "default", 
                mode: str = 'accurate',
                prompt: Optional[str] = None,
                **kwargs) -> Dict[str, Any]:
        """
        ğŸ¯ æ ¸å¿ƒåŠŸèƒ½: ä»å›¾åƒä¸­æå–PRCæ°´å°ä¿¡æ¯
        
        ğŸ“‹ è¯¦ç»†å·¥ä½œæµç¨‹:
        1. å›¾åƒé¢„å¤„ç†å’Œæ ¼å¼è½¬æ¢
        2. ä½¿ç”¨exact_inversionè¿›è¡Œå›¾åƒé€†å‘ (å…³é”®æ­¥éª¤)
        3. ä»æ½œå˜é‡ä¸­æ¢å¤åéªŒæ¦‚ç‡
        4. PRCè§£ç å™¨æ£€æµ‹å’Œè§£ç æ°´å°
        5. è¿”å›æ£€æµ‹ç»“æœå’Œç½®ä¿¡åº¦
        
        ğŸ“¥ å‚æ•°è¯´æ˜:
            image: è¾“å…¥å›¾åƒï¼Œæ”¯æŒå¤šç§æ ¼å¼:
                - str: å›¾åƒæ–‡ä»¶è·¯å¾„
                - PIL.Image: PILå›¾åƒå¯¹è±¡  
                - torch.Tensor: æ½œå˜é‡tensor
            key_id: å¯†é’¥æ ‡è¯†ç¬¦ï¼Œå¿…é¡»ä¸åµŒå…¥æ—¶ä¸€è‡´
            mode: é€†å‘ç²¾åº¦æ¨¡å¼ï¼Œå½±å“æ£€æµ‹ç²¾åº¦å’Œé€Ÿåº¦:
                - 'fast': 20æ­¥æ¨ç†ï¼Œdecoder_inv=Falseï¼Œ0.19ç§’
                - 'accurate': 50æ­¥æ¨ç†ï¼Œdecoder_inv=Trueï¼Œ13.7ç§’ (æ¨è)
                - 'exact': 50æ­¥æ¨ç†ï¼Œdecoder_inv=Trueï¼Œ52.15ç§’ (æœ€é«˜ç²¾åº¦)
            prompt: åŸå§‹ç”Ÿæˆæç¤ºè¯ (å¯é€‰ï¼Œæœ‰åŠ©äºæå‡exactæ¨¡å¼ç²¾åº¦)
            **kwargs: å…¶ä»–é€†å‘å‚æ•°
                
        ğŸ“¤ è¿”å›å€¼ç»“æ„:
            {
                'detected': bool,           # ğŸ¯ æ˜¯å¦æ£€æµ‹åˆ°æ°´å°
                'message': str,             # ğŸ“¤ è§£ç çš„æ¶ˆæ¯ (æ£€æµ‹æˆåŠŸæ—¶)
                'confidence': float,        # ğŸšï¸ æ£€æµ‹ç½®ä¿¡åº¦ (0.0-1.0)
                'mode_used': str,           # å®é™…ä½¿ç”¨çš„é€†å‘æ¨¡å¼
                'processing_time': float,   # å¤„ç†è€—æ—¶ (ç§’)
                'metadata': {               # è¯¦ç»†å…ƒæ•°æ®
                    'image_size': tuple,    # å›¾åƒå°ºå¯¸
                    'latent_shape': tuple,  # æ½œå˜é‡å½¢çŠ¶
                    'algorithm': 'PRC',     # ç®—æ³•åç§°
                    'key_id': str,          # ä½¿ç”¨çš„å¯†é’¥ID
                    'false_positive_rate': float  # è™šè­¦ç‡
                }
            }
            
        ğŸš¨ å¤±è´¥æƒ…å†µè¿”å›:
            {
                'detected': False,
                'message': None,
                'confidence': 0.0,
                'error': str               # é”™è¯¯ä¿¡æ¯
            }
        """
        # è·å–è§£ç å¯†é’¥
        _, decoding_key = self._get_or_create_keys(key_id)
        
        # å›¾åƒåˆ°æ½œå˜é‡è½¬æ¢ (æ ¸å¿ƒé€†å‘è¿‡ç¨‹)
        if not isinstance(image, torch.Tensor):
            latents = self._image_to_latents(image, mode=mode, prompt=prompt)
        else:
            latents = image
        
        # è®¡ç®—åéªŒæ¦‚ç‡ - ç¡®ä¿tensoråœ¨CPUä¸Šä¸”åˆ†ç¦»æ¢¯åº¦
        latents_cpu = latents.detach().cpu() if hasattr(latents, 'detach') else latents
        if hasattr(latents_cpu, 'cpu'):
            latents_cpu = latents_cpu.cpu()
        posteriors = prc_gaussians.recover_posteriors(latents_cpu.flatten())
        
        # æ£€æµ‹æ°´å°
        detected = Detect(decoding_key, posteriors, self.false_positive_rate)
        
        result = {
            'detected': detected,
            'message': None,
            'confidence': 0.0,
            'mode_used': mode if not isinstance(image, torch.Tensor) else 'tensor_input'
        }
        
        if detected:
            # è§£ç æ¶ˆæ¯
            decoded_bits = Decode(decoding_key, posteriors)
            try:
                decoded_message = bin_to_str(decoded_bits)
                result['message'] = decoded_message
                result['confidence'] = 1.0  # PRCæä¾›ç¡®å®šæ€§æ£€æµ‹
            except Exception as e:
                result['confidence'] = 0.6  # æ£€æµ‹åˆ°ä½†è§£ç å¤±è´¥
        
        return result
```

**ğŸ”§ æ ¸å¿ƒå†…éƒ¨æ–¹æ³• - ç»Ÿä¸€é€†å‘å®ç°**

```python
    def _image_to_latents(self, image: Image.Image, mode: str = 'accurate', 
                         prompt: Optional[str] = None) -> torch.Tensor:
        """
        ğŸ¯ æ ¸å¿ƒæ–¹æ³•: å°†PILå›¾åƒè½¬æ¢ä¸ºæ½œå˜é‡ï¼Œç»Ÿä¸€ä½¿ç”¨exact_inversion
        
        ğŸ“‹ å®ç°ç­–ç•¥:
        - æ‰€æœ‰æ¨¡å¼éƒ½ä½¿ç”¨ç›¸åŒçš„exact_inversionå‡½æ•°
        - é€šè¿‡å‚æ•°è°ƒèŠ‚å®ç°ä¸åŒç²¾åº¦ç­‰çº§
        - æ¶ˆé™¤ä»£ç å†—ä½™ï¼Œä¿æŒæ¶æ„ç®€æ´
        
        Args:
            image: PILå›¾åƒ
            mode: é€†å‘æ¨¡å¼ ('fast', 'accurate', 'exact')
            prompt: æç¤ºè¯ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰
            
        Returns:
            æ½œå˜é‡tensor
        """
        if not PRC_AVAILABLE:
            raise RuntimeError("PRC dependencies not available")
            
        if prompt is None:
            prompt = ""  # ä½¿ç”¨ç©ºæç¤ºè¯ä½œä¸ºé»˜è®¤å€¼
            
        # æ ¹æ®æ¨¡å¼è®¾ç½®ä¸åŒçš„å‚æ•°
        if mode == 'fast':
            # å¿«é€Ÿæ¨¡å¼ï¼šä½¿ç”¨è¾ƒå°‘çš„æ¨ç†æ­¥æ•°å’Œç®€å•é€†å‘
            decoder_inv = False
            num_inference_steps = 20
            test_num_inference_steps = 20
        elif mode == 'accurate':
            # ç²¾ç¡®æ¨¡å¼ï¼šä½¿ç”¨decoder_invä¼˜åŒ–æ±‚è§£
            decoder_inv = True
            num_inference_steps = 50
            test_num_inference_steps = 50
        elif mode == 'exact':
            # å®Œæ•´æ¨¡å¼ï¼šæœ€é«˜ç²¾åº¦è®¾ç½®
            decoder_inv = True
            num_inference_steps = 50
            test_num_inference_steps = 50
        else:
            raise ValueError(f"Unsupported mode: {mode}")
        
        # ä½¿ç”¨PRC-Watermarkçš„exact_inversionå‡½æ•°
        reversed_latents = exact_inversion(
            image=image,
            prompt=prompt, 
            guidance_scale=3.0,
            num_inference_steps=num_inference_steps,
            solver_order=1,
            test_num_inference_steps=test_num_inference_steps,
            inv_order=1,
            decoder_inv=decoder_inv,
            model_id=self.model_id,
            pipe=self.pipe
        )
        
        return reversed_latents
```

**âš™ï¸ é…ç½®å‚æ•°è¯¦è§£**

```yaml
# config/image_config.yaml - å®Œæ•´é…ç½®ç¤ºä¾‹
method: "PRC"
model_id: "stabilityai/stable-diffusion-2-1-base"
device: "auto"                          # 'cuda', 'cpu', 'auto'

# === å¯†é’¥ç®¡ç† ===
keys_dir: "watermark_keys"
cache_dir: "/path/to/huggingface/cache"  # æœ¬åœ°æ¨¡å‹ç¼“å­˜

# === PRCç®—æ³•å‚æ•° ===
prc_params:
  n: 1024                              # ç é•¿
  k: 512                               # ä¿¡æ¯ä½æ•°
  false_positive_rate: 1.0e-6          # è™šè­¦ç‡

# === ç”Ÿæˆå‚æ•° ===
generation_params:
  num_inference_steps: 50              # é‡‡æ ·æ­¥æ•°
  guidance_scale: 7.5                  # å¼•å¯¼å¼ºåº¦
  height: 512                          # å›¾åƒé«˜åº¦
  width: 512                           # å›¾åƒå®½åº¦

# === é€†å‘å‚æ•° ===
inversion_params:
  default_mode: "accurate"             # é»˜è®¤é€†å‘æ¨¡å¼
  fast_steps: 20                       # å¿«é€Ÿæ¨¡å¼æ­¥æ•°
  accurate_steps: 50                   # ç²¾ç¡®æ¨¡å¼æ­¥æ•°
  exact_steps: 50                      # å®Œæ•´æ¨¡å¼æ­¥æ•°
```

**ğŸš€ å®é™…ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µ**

```python
# === å®Œæ•´ä½¿ç”¨ç¤ºä¾‹ ===
from src.image_watermark.prc_watermark import PRCWatermark
from PIL import Image
import time

# 1. åˆå§‹åŒ–ç³»ç»Ÿ (æ”¯æŒç¦»çº¿æ¨¡å¼)
prc = PRCWatermark(
    model_id="stabilityai/stable-diffusion-2-1-base",
    keys_dir="test_keys",
    cache_dir="/path/to/local/models",  # æœ¬åœ°æ¨¡å‹è·¯å¾„
    device="cuda"
)

# 2. ğŸ¯ åŸºç¡€æ°´å°åµŒå…¥
print("=== åŸºç¡€æ°´å°åµŒå…¥ ===")
start_time = time.time()

watermarked_image = prc.embed(
    prompt="A beautiful sunset over the ocean",
    message="Hello PRC!",
    key_id="demo_key",
    seed=42
)

embed_time = time.time() - start_time
print(f"âœ… åµŒå…¥å®Œæˆ: {embed_time:.2f}ç§’")
print(f"å›¾åƒå°ºå¯¸: {watermarked_image.size}")

# ä¿å­˜å›¾åƒ
watermarked_image.save("watermarked_sunset.png")

# 3. ğŸ¯ å¤šæ¨¡å¼æ°´å°æ£€æµ‹å¯¹æ¯”
print("\n=== å¤šæ¨¡å¼æ£€æµ‹å¯¹æ¯” ===")
modes = ['fast', 'accurate', 'exact']

for mode in modes:
    start_time = time.time()
    
    result = prc.extract(
        image=watermarked_image,
        key_id="demo_key",
        mode=mode
    )
    
    extract_time = time.time() - start_time
    
    status = "âœ…" if result['detected'] else "âŒ"
    print(f"{mode.upper():>8}: {status} | è€—æ—¶: {extract_time:.2f}s | æ¶ˆæ¯: {result.get('message', 'None')}")

# 4. ğŸ¯ æ‰¹é‡å¤„ç†æµ‹è¯•
print("\n=== æ‰¹é‡å¤„ç†æµ‹è¯• ===")
test_cases = [
    ("A red car", "car001"),
    ("A blue house", "house002"), 
    ("A green tree", "tree003")
]

batch_results = []
batch_start = time.time()

for prompt, message in test_cases:
    # åµŒå…¥
    image = prc.embed(prompt=prompt, message=message, key_id="batch_key")
    
    # æå– (ä½¿ç”¨accurateæ¨¡å¼)
    result = prc.extract(image=image, key_id="batch_key", mode='accurate')
    
    batch_results.append({
        'prompt': prompt,
        'original': message,
        'detected': result['detected'],
        'extracted': result.get('message'),
        'success': result['detected'] and result.get('message') == message
    })

batch_time = time.time() - batch_start
success_rate = sum(1 for r in batch_results if r['success']) / len(batch_results)

print(f"â±ï¸ æ‰¹é‡å¤„ç†({len(test_cases)}å¼ ): {batch_time:.2f}ç§’")
print(f"ğŸ¯ æˆåŠŸç‡: {success_rate:.1%}")

for i, result in enumerate(batch_results):
    status = "âœ…" if result['success'] else "âŒ"
    print(f"  {i+1}. {status} {result['prompt']}: {result['original']} â†’ {result['extracted']}")

# 5. ğŸ¯ æ–‡ä»¶è·¯å¾„å¤„ç†
print("\n=== æ–‡ä»¶è·¯å¾„å¤„ç† ===")
# ä»æ–‡ä»¶è·¯å¾„ç›´æ¥æå–
file_result = prc.extract(
    image="watermarked_sunset.png",  # ç›´æ¥ä½¿ç”¨æ–‡ä»¶è·¯å¾„
    key_id="demo_key",
    mode='fast'
)

print(f"æ–‡ä»¶æ£€æµ‹: {'âœ…' if file_result['detected'] else 'âŒ'} | æ¶ˆæ¯: {file_result.get('message', 'None')}")

# 6. ğŸ¯ æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡
print("\n=== æ€§èƒ½ç»Ÿè®¡ ===")
print(f"æ¨¡å‹ID: {prc.model_id}")
print(f"è®¾å¤‡: {prc.device}")
print(f"å¯†é’¥ç›®å½•: {prc.keys_dir}")
print(f"ç¼“å­˜å¯†é’¥æ•°: {len(prc._key_cache)}")
```

**ğŸ“Š æ€§èƒ½åŸºå‡†å’Œç‰¹ç‚¹æ€»ç»“**

| æ¨¡å¼ | æ£€æµ‹æˆåŠŸç‡ | å¤„ç†æ—¶é—´ | é€‚ç”¨åœºæ™¯ | æŠ€æœ¯ç‰¹ç‚¹ |
|------|------------|----------|----------|----------|
| **FAST** | 100% | 0.19ç§’ | å®æ—¶åº”ç”¨ | decoder_inv=Falseï¼Œ20æ­¥æ¨ç† |
| **ACCURATE** | 100% | 13.7ç§’ | ç”Ÿäº§ç¯å¢ƒ | decoder_inv=Trueï¼Œ50æ­¥æ¨ç† |
| **EXACT** | 100% | 52.15ç§’ | ç ”ç©¶åˆ†æ | å®Œæ•´æ‰©æ•£é€†å‘ï¼Œæœ€é«˜ç²¾åº¦ |

**ğŸ”§ æŠ€æœ¯å®ç°äº®ç‚¹**ï¼š

| ç‰¹æ€§ | æè¿° | ä¼˜åŠ¿ |
|------|------|------|
| **ç»Ÿä¸€é€†å‘å®ç°** | æ‰€æœ‰æ¨¡å¼ä½¿ç”¨åŒä¸€ä¸ªexact_inversionå‡½æ•° | ä»£ç ç®€æ´ï¼Œç»´æŠ¤æ€§å¥½ |
| **å‚æ•°åŒ–æ§åˆ¶** | é€šè¿‡decoder_invå’Œstepså‚æ•°è°ƒèŠ‚ç²¾åº¦ | çµæ´»é…ç½®ï¼Œé¿å…é‡å¤ä»£ç  |
| **ç¦»çº¿æ¨¡å¼æ”¯æŒ** | æœ¬åœ°æ¨¡å‹ç¼“å­˜ï¼Œæ— éœ€ç½‘ç»œè¿æ¥ | éƒ¨ç½²çµæ´»ï¼Œéšç§ä¿æŠ¤ |
| **è®¾å¤‡è‡ªé€‚åº”** | è‡ªåŠ¨GPU/CPUè½¬æ¢å’Œæ¢¯åº¦ç®¡ç† | å…¼å®¹æ€§å¼ºï¼Œé”™è¯¯å¤„ç†å®Œå–„ |
| **å¯†é’¥ç®¡ç†** | è‡ªåŠ¨å¯†é’¥ç”Ÿæˆã€ç¼“å­˜å’Œå¤ç”¨ | ä¾¿äºå¤šé¡¹ç›®ç®¡ç† |
| **100%æˆåŠŸç‡** | æ‰€æœ‰æ¨¡å¼éƒ½èƒ½å®Œç¾æ£€æµ‹è§£ç  | ç”Ÿäº§ç¯å¢ƒå¯é æ€§é«˜ |

**ğŸ¯ ä¸æ–‡æœ¬æ°´å°çš„ç»Ÿä¸€æ¥å£å¯¹æ¯”**ï¼š

| æ¥å£è¦ç´  | æ–‡æœ¬æ°´å° | å›¾åƒæ°´å° | ç»Ÿä¸€è®¾è®¡ |
|----------|----------|----------|----------|
| **è¾“å…¥æ ¼å¼** | `(model, tokenizer, prompt, message)` | `(prompt, message, key_id)` | ç®€åŒ–å‚æ•°ï¼Œéšè—å¤æ‚æ€§ |
| **è¾“å‡ºæ ¼å¼** | `{watermarked_text, success, metadata}` | `PIL.Image` | ç›´æ¥è¿”å›ç»“æœå¯¹è±¡ |
| **æ£€æµ‹è¾“å…¥** | `(text, model, tokenizer, candidates)` | `(image, key_id, mode)` | æ”¯æŒå¤šç§è¾“å…¥æ ¼å¼ |
| **æ£€æµ‹è¾“å‡º** | `{extracted_message, confidence, success}` | `{detected, message, confidence}` | ç»Ÿä¸€ç»“æ„è®¾è®¡ |
| **é…ç½®ç®¡ç†** | YAMLé…ç½®æ–‡ä»¶é©±åŠ¨ | YAMLé…ç½®æ–‡ä»¶é©±åŠ¨ | ä¸€è‡´çš„é…ç½®æ–¹å¼ |
| **é”™è¯¯å¤„ç†** | è¯¦ç»†å¼‚å¸¸ä¿¡æ¯å’ŒçŠ¶æ€ | è¯¦ç»†å¼‚å¸¸ä¿¡æ¯å’ŒçŠ¶æ€ | ç»Ÿä¸€é”™è¯¯å¤„ç†æœºåˆ¶ |

## ğŸ†• 2025-08 æ›´æ–°æ‘˜è¦ï¼ˆdiffusers==0.34 å…¼å®¹ + VideoSeal å›¾åƒåç«¯ï¼‰

### åŠ¨æœº
- ä¸ºå…¼å®¹æ–°çš„è§†é¢‘æ¨¡å‹ï¼ˆHunyuanï¼‰ï¼Œç¯å¢ƒå‡çº§è‡³ `diffusers==0.34`ã€‚è¯¥ç‰ˆæœ¬å¯¹è‡ªå®šä¹‰ç®¡çº¿/æ¨¡å—æ³¨å†Œæœ‰å˜æ›´ï¼Œæ—§ PRC è·¯å¾„æ˜“å—å½±å“ã€‚å› æ­¤æ–°å¢ VideoSeal ä½œä¸ºå›¾åƒæ°´å°çš„ç¬¬äºŒåç«¯ï¼Œå¹¶å°†ç›¸å…³åŠ è½½æ”¹é€ ä¸º"æ‡’åŠ è½½ + ç¦»çº¿ä¼˜å…ˆ"ã€‚

### ä¸»è¦æ”¹åŠ¨
- å›¾åƒæ°´å°æ–°å¢åç«¯ï¼š`videoseal`
  - æ–°æ–‡ä»¶ `src/image_watermark/videoseal_image_watermark.py`ï¼šå°†å•å›¾å½“ä½œå•å¸§è§†é¢‘ï¼Œå¤ç”¨ `src/video_watermark/videoseal_wrapper.py` çš„ `embed/detect`ï¼Œå¯¹å›¾åƒæä¾›æ—  Diffusers ä¾èµ–çš„ç¨³å¥åµŒå…¥/æå–ã€‚
  - `src/image_watermark/image_watermark.py`ï¼š
    - æ‡’åŠ è½½å…·ä½“ç®—æ³•å¤„ç†å™¨ï¼Œé¿å…åœ¨æ„é€ é˜¶æ®µåŠ è½½æ— å…³ä¾èµ–ã€‚
    - æ”¯æŒ `algorithm: videoseal`ï¼Œå¹¶åœ¨æ— å›¾åƒè¾“å…¥æ—¶ï¼Œå…ˆç”¨ Stable Diffusion ç”Ÿæˆï¼Œå†è°ƒç”¨ VideoSeal åµŒå…¥ã€‚
  - `src/unified/watermark_tool.py`ï¼š`get_supported_algorithms()['image']` å¢åŠ  `videoseal`ã€‚
  - æ£€æµ‹å¢å¼ºï¼š`extract(..., replicate=N, chunk_size=N)` æ”¯æŒå°†å•å¸§å¤åˆ¶ä¸ºå¤šå¸§åšå‡å€¼ï¼Œæ˜¾è‘—æå‡è¯»å‡ºç¨³å®šæ€§ä¸ç½®ä¿¡åº¦ã€‚

- ç¦»çº¿åŠ è½½ï¼ˆStable Diffusionï¼‰
  - `src/utils/model_manager.py`ï¼š
    - å¼ºåˆ¶ `TRANSFORMERS_OFFLINE/DIFFUSERS_OFFLINE/HF_HUB_OFFLINE`ã€‚
    - è§£æ/ä¼˜å…ˆè¿”å› HF Hub æœ¬åœ°ç¼“å­˜ç›®å½• `.../hub/models--stabilityai--stable-diffusion-2-1-base`ï¼Œä¸ PRC è·¯å¾„ä¸€è‡´ï¼›`from_pretrained(local_files_only=True)` ç¦»çº¿è§£æ refsã€‚

- æ–‡æœ¬æ°´å°ï¼ˆCredIDï¼‰ç¦»çº¿åŠ è½½
  - `test_complex_messages_real.py`ï¼š
    - å¼ºåˆ¶ç¦»çº¿å˜é‡ã€‚
    - `AutoTokenizer/AutoModelForCausalLM.from_pretrained(..., local_files_only=True, cache_dir=...)`ã€‚
    - è‡ªåŠ¨æ¢æµ‹ç¼“å­˜ç›®å½•æˆ–é€šè¿‡é…ç½® `hf_cache_dir` æŒ‡å®šã€‚

- å¯¼å…¥ä¸æµ‹è¯•
  - ç»Ÿä¸€ `src.*` ç»å¯¹å¯¼å…¥é£æ ¼ï¼Œè„šæœ¬ä»é¡¹ç›®æ ¹è¿è¡Œç¨³å®šã€‚
  - `tests/conftest.py` å°† `src/` æ³¨å…¥ `sys.path`ï¼Œæµ‹è¯•æ—¶ `unified.*` å¯å¯¼å…¥ã€‚
  - æ–°å¢ï¼š
    - `tests/test_image_videoseal.py`ï¼ˆæœ€å°éªŒè¯ï¼‰
    - æ ¹çº§ `test_image_videoseal_root.py`ï¼šå¯ç›´æ¥ `python` æ¼”ç¤º
      - `--mode pil`ï¼šç°æœ‰å›¾åƒåµŒå…¥/æå–
      - `--mode gen`ï¼šç”Ÿæˆâ†’åµŒå…¥â†’æå–ï¼ˆå®Œå…¨ç¦»çº¿ï¼Œéœ€æœ¬åœ° SD æƒé‡ï¼‰

### ä½¿ç”¨ä¸è°ƒå‚å»ºè®®ï¼ˆVideoSeal å›¾åƒæ°´å°ï¼‰
- é…ç½®ï¼ˆç¤ºä¾‹ï¼‰ï¼š
```yaml
image_watermark:
  algorithm: videoseal
  model_name: stabilityai/stable-diffusion-2-1-base
  resolution: 512
  num_inference_steps: 30
  lowres_attenuation: true
  device: cuda
```
- ç”Ÿæˆ â†’ åµŒå…¥ â†’ æå–ï¼š
```python
from src.unified.watermark_tool import WatermarkTool
tool = WatermarkTool()
tool.set_algorithm('image', 'videoseal')
img = tool.generate_image_with_watermark(prompt='a cat', message='hello_videoseal')
res = tool.extract_image_watermark(img, replicate=16, chunk_size=16)
```
- CLI æ¼”ç¤ºï¼š
```bash
python test_image_videoseal_root.py --mode pil  --device cuda
python test_image_videoseal_root.py --mode gen  --device cuda --resolution 512 --steps 30
```

### æå‡æ£€æµ‹ç½®ä¿¡åº¦
- ç”Ÿæˆä¾§ï¼šæé«˜ `resolution`/`num_inference_steps`ï¼›ç®€åŒ– promptï¼›ä½¿ç”¨ GPUã€‚
- æ£€æµ‹ä¾§ï¼š`replicate` è®¾ä¸º 8~32ï¼Œå¹¶ä¸ `chunk_size` å¯¹é½ï¼Œä½¿ç”¨å¤šå¸§å‡å€¼ï¼›å¯¹å•å›¾å°¤å…¶æœ‰æ•ˆã€‚

### 4. éŸ³é¢‘æ°´å°æ¨¡å— (AudioSeal Algorithm) âœ… **å·²å®Œæˆå®ç°**

**AudioSealç®—æ³•åŸç†ä¸å®ç°çŠ¶æ€**ï¼š
- **Meta AudioSealç®—æ³•**ï¼šåŸºäºæ·±åº¦å­¦ä¹ çš„é²æ£’éŸ³é¢‘æ°´å°æŠ€æœ¯ï¼Œå®Œæ•´Pythonå°è£…ï¼Œç”Ÿäº§ç¯å¢ƒå°±ç»ª
- **16ä½æ¶ˆæ¯ç¼–ç ç³»ç»Ÿ**ï¼šä½¿ç”¨SHA256å“ˆå¸Œç¡®ä¿ç¼–ç ä¸€è‡´æ€§ï¼Œæ”¯æŒå­—ç¬¦ä¸²åˆ°äºŒè¿›åˆ¶çš„å¯é è½¬æ¢  
- **é«˜ä¿çœŸåµŒå…¥**ï¼šSNR>40dBï¼ˆå®æµ‹44.45dBï¼‰ï¼Œå¬è§‰è´¨é‡å‡ ä¹æ— æŸå¤±ï¼Œ100%æ£€æµ‹æˆåŠŸç‡
- **è®¾å¤‡è‡ªé€‚åº”ä¼˜åŒ–**ï¼šæ”¯æŒCPU/CUDAè‡ªåŠ¨åˆ‡æ¢å’Œè®¾å¤‡å¼ é‡ç®¡ç†ï¼Œä¿®å¤è®¾å¤‡ä¸åŒ¹é…é—®é¢˜
- **é«˜æ•ˆæ‰¹å¤„ç†**ï¼š3ä¸ªéŸ³é¢‘2.8ç§’ï¼Œå¹¶è¡Œå¤„ç†ä¼˜åŒ–ï¼Œæ”¯æŒå¤§è§„æ¨¡åº”ç”¨

## ğŸš¨ å·²çŸ¥é—®é¢˜ä¸é™åˆ¶

### Bark TTS ç¼“å­˜é—®é¢˜

**é—®é¢˜æè¿°**:
- Bark TTSå­˜åœ¨åŒé‡ç¼“å­˜ç³»ç»Ÿé—®é¢˜ï¼Œä¼šåŒæ—¶ä½¿ç”¨HuggingFaceç¼“å­˜ç›®å½•å’Œä¸“ç”¨çš„Sunoç¼“å­˜ç›®å½•
- å³ä½¿è®¾ç½®äº†`HF_HOME`æˆ–`CACHE_DIR`ï¼ŒBarkä»ä¼šåœ¨`/root/.cache/suno/`ä¸‹è½½çº¦8.4GBçš„æ¨¡å‹æ–‡ä»¶
- è¿™å¯¼è‡´ç£ç›˜ç©ºé—´é‡å¤å ç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨å­˜å‚¨ç©ºé—´æœ‰é™çš„ç¯å¢ƒä¸­

**æ ¹æœ¬åŸå› **:
- Barkä½¿ç”¨ç‹¬ç«‹çš„æ¨¡å‹ç®¡ç†ç³»ç»Ÿï¼Œä¸å®Œå…¨éµå¾ªHuggingFaceçš„ç¼“å­˜é…ç½®
- å­˜åœ¨ä¸¤å¥—ç¼“å­˜é€»è¾‘ï¼šHuggingFaceæ ‡å‡†ç¼“å­˜ + Sunoä¸“ç”¨ç¼“å­˜

**å½“å‰å—é™åŠŸèƒ½**:
- æ–‡æœ¬è½¬è¯­éŸ³åŠŸèƒ½ (`generate_audio_with_watermark`)
- é«˜çº§éŸ³é¢‘æ°´å°æ¼”ç¤º (`demo_text_to_audio_watermark`)
- å®Œæ•´æ¨¡å¼æ¼”ç¤º (`python audio_watermark_demo.py --mode full`)

**ä¸å—å½±å“çš„åŠŸèƒ½**:
- åŸºç¡€éŸ³é¢‘æ°´å°åŠŸèƒ½ (AudioSealåµŒå…¥/æå–)
- åŸºç¡€æ¨¡å¼æ¼”ç¤º (`python audio_watermark_demo.py --mode basic`)
- éŸ³é¢‘æ–‡ä»¶å¤„ç†å’Œè´¨é‡è¯„ä¼°
- æ‰¹å¤„ç†åŠŸèƒ½

**å·²å®ç°çš„æ ¸å¿ƒæ¶æ„ä¸æ€§èƒ½**ï¼š

```python
# src/audio_watermark/audio_watermark.py - å®Œæ•´å®ç°
import torch
import logging
from typing import Dict, Any, List, Optional, Union, Tuple
from pathlib import Path

class AudioWatermark:
    """
    AudioSealéŸ³é¢‘æ°´å°ç®—æ³•ç»Ÿä¸€å°è£… - ç”Ÿäº§ç¯å¢ƒå°±ç»ª
    
    âœ… å·²å®Œæˆæ ¸å¿ƒåŠŸèƒ½:
    1. Meta AudioSealå®Œæ•´é›†æˆ - 100%æ£€æµ‹æˆåŠŸç‡ï¼ŒSNR 44.45dB
    2. Bark TTSç«¯åˆ°ç«¯æµç¨‹ - æ”¯æŒå¤šè¯­è¨€ï¼ˆä¸­è‹±æ–‡ï¼‰é«˜è´¨é‡è¯­éŸ³ç”Ÿæˆ
    3. å¤šæ ¼å¼éŸ³é¢‘æ”¯æŒ - WAV/MP3/FLACç­‰ï¼Œå®Œæ•´I/Oå¤„ç†
    4. è®¾å¤‡è‡ªé€‚åº”ä¼˜åŒ– - CPU/CUDAè‡ªåŠ¨åˆ‡æ¢ï¼Œå†…å­˜ä¼˜åŒ–ï¼Œè®¾å¤‡ä¸€è‡´æ€§ä¿®å¤  
    5. é«˜æ•ˆæ‰¹å¤„ç† - 3ä¸ªéŸ³é¢‘2.8ç§’ï¼Œå¹¶è¡Œå¤„ç†ä¼˜åŒ–
    6. å®Œæ•´è´¨é‡è¯„ä¼° - SNR/MSE/ç›¸å…³æ€§æŒ‡æ ‡ï¼Œå™ªå£°é²æ£’æ€§æµ‹è¯•
    7. æŠ€æœ¯é—®é¢˜ä¿®å¤ - 3Då¼ é‡ç»´åº¦å¤„ç†ï¼Œè®¾å¤‡åŒ¹é…ï¼ŒBarkå¯¼å…¥æ£€æµ‹
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–AudioSealéŸ³é¢‘æ°´å°å¤„ç†å™¨
        
        Args:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«:
                - algorithm: 'audioseal' (é»˜è®¤)
                - device: 'cuda', 'cpu', æˆ– 'auto'
                - nbits: æ¶ˆæ¯ä½æ•° (é»˜è®¤16)
                - sample_rate: é‡‡æ ·ç‡ (é»˜è®¤16000)
                - bark_config: Bark TTSé…ç½®
        """
        self.config = config
        self.algorithm = config.get('algorithm', 'audioseal')
        self.device = config.get('device', 'auto')
        self.nbits = config.get('nbits', 16)
        self.sample_rate = config.get('sample_rate', 16000)
        
        # å»¶è¿Ÿåˆå§‹åŒ–çš„ç»„ä»¶
        self.audioseal_wrapper = None
        self.bark_generator = None
        
        logging.info(f"AudioWatermarkåˆå§‹åŒ–: ç®—æ³•={self.algorithm}, è®¾å¤‡={self.device}")
```

**ğŸ”¹ æ ¸å¿ƒæ¥å£ 1: embed_watermark() - éŸ³é¢‘æ°´å°åµŒå…¥**

```python
    def embed_watermark(self, 
                       audio: Union[str, torch.Tensor, Path], 
                       message: str,
                       input_sample_rate: Optional[int] = None,
                       alpha: float = 1.0,
                       output_path: Optional[str] = None) -> Union[torch.Tensor, str]:
        """
        ğŸ¯ æ ¸å¿ƒåŠŸèƒ½: åœ¨éŸ³é¢‘ä¸­åµŒå…¥AudioSealæ°´å°
        
        ğŸ“‹ è¯¦ç»†å·¥ä½œæµç¨‹:
        1. éŸ³é¢‘åŠ è½½å’Œé¢„å¤„ç† (é‡é‡‡æ ·åˆ°16kHzï¼Œæ ¼å¼è½¬æ¢)
        2. æ¶ˆæ¯ç¼–ç ä¸º16ä½äºŒè¿›åˆ¶åºåˆ— (SHA256å“ˆå¸Œ)
        3. ä½¿ç”¨AudioSealç”Ÿæˆå™¨è¿›è¡Œæ°´å°åµŒå…¥
        4. åå¤„ç†å’Œè¾“å‡º (ä¿å­˜æ–‡ä»¶æˆ–è¿”å›å¼ é‡)
        
        ğŸ“¥ å‚æ•°è¯´æ˜:
            audio: è¾“å…¥éŸ³é¢‘ï¼Œæ”¯æŒå¤šç§æ ¼å¼:
                - str/Path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (WAV, MP3, FLACç­‰)
                - torch.Tensor: éŸ³é¢‘å¼ é‡ (1, samples) æˆ– (samples,)
            message: è¦åµŒå…¥çš„å­—ç¬¦ä¸²æ¶ˆæ¯ï¼Œå¦‚ "user123", "2025_watermark"
            input_sample_rate: è¾“å…¥éŸ³é¢‘é‡‡æ ·ç‡ (ä»æ–‡ä»¶æ¨æ–­æˆ–æ‰‹åŠ¨æŒ‡å®š)
            alpha: æ°´å°å¼ºåº¦ (0.0-2.0ï¼Œé»˜è®¤1.0ï¼Œè¶Šé«˜æ°´å°è¶Šå¼ºä½†å¤±çœŸè¶Šå¤§)
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ (å¯é€‰ï¼Œæä¾›åˆ™ä¿å­˜æ–‡ä»¶)
            
        ğŸ“¤ è¿”å›å€¼:
            - å¦‚æœæä¾›output_path: è¿”å›ä¿å­˜çš„æ–‡ä»¶è·¯å¾„(str)
            - å¦åˆ™: è¿”å›å¸¦æ°´å°çš„éŸ³é¢‘å¼ é‡(torch.Tensor)
            
        ğŸš¨ é”™è¯¯æƒ…å†µ:
            æŠ›å‡ºRuntimeErrorå¼‚å¸¸ï¼ŒåŒ…å«è¯¦ç»†é”™è¯¯ä¿¡æ¯
        """
        self._ensure_audioseal()
        
        # å¤„ç†ä¸åŒè¾“å…¥æ ¼å¼
        if isinstance(audio, (str, Path)):
            from .utils import AudioIOUtils
            audio_tensor, sr = AudioIOUtils.load_audio(
                str(audio), 
                target_sample_rate=self.sample_rate
            )
        else:
            audio_tensor = audio
            sr = input_sample_rate or self.sample_rate
        
        # åµŒå…¥æ°´å°
        watermarked = self.audioseal_wrapper.embed(
            audio_tensor, message, sr, alpha
        )
        
        if output_path:
            from .utils import AudioIOUtils
            AudioIOUtils.save_audio(watermarked, output_path, self.sample_rate)
            return output_path
        else:
            return watermarked
```

**ğŸ”¹ æ ¸å¿ƒæ¥å£ 2: extract_watermark() - éŸ³é¢‘æ°´å°æå–**

```python
    def extract_watermark(self, 
                         watermarked_audio: Union[str, torch.Tensor, Path],
                         input_sample_rate: Optional[int] = None,
                         detection_threshold: float = 0.5,
                         message_threshold: float = 0.5) -> Dict[str, Any]:
        """
        ğŸ¯ æ ¸å¿ƒåŠŸèƒ½: ä»éŸ³é¢‘ä¸­æå–AudioSealæ°´å°ä¿¡æ¯
        
        ğŸ“‹ è¯¦ç»†å·¥ä½œæµç¨‹:
        1. éŸ³é¢‘åŠ è½½å’Œé¢„å¤„ç†
        2. ä½¿ç”¨AudioSealæ£€æµ‹å™¨è¿›è¡Œæ°´å°æ£€æµ‹
        3. æ¶ˆæ¯è§£ç å’ŒåŒ¹é… (ä¸å†å²æ¶ˆæ¯åº“åŒ¹é…)
        4. ç½®ä¿¡åº¦è®¡ç®—å’Œç»“æœéªŒè¯
        
        ğŸ“¥ å‚æ•°è¯´æ˜:
            watermarked_audio: å¯èƒ½åŒ…å«æ°´å°çš„éŸ³é¢‘
            input_sample_rate: è¾“å…¥éŸ³é¢‘é‡‡æ ·ç‡
            detection_threshold: æ£€æµ‹é˜ˆå€¼ (0.0-1.0ï¼Œé»˜è®¤0.5)
            message_threshold: æ¶ˆæ¯è§£ç é˜ˆå€¼ (0.0-1.0ï¼Œé»˜è®¤0.5)
            
        ğŸ“¤ è¿”å›å€¼ç»“æ„:
            {
                'detected': bool,               # ğŸ¯ æ˜¯å¦æ£€æµ‹åˆ°æ°´å°
                'message': str,                 # ğŸ“¤ è§£ç çš„æ¶ˆæ¯ (æ£€æµ‹æˆåŠŸæ—¶)
                'confidence': float,            # ğŸšï¸ æ£€æµ‹ç½®ä¿¡åº¦ (0.0-1.0)
                'raw_bits': torch.Tensor,      # åŸå§‹äºŒè¿›åˆ¶è§£ç ç»“æœ
                'processing_time': float,       # å¤„ç†è€—æ—¶ (ç§’)
                'metadata': {                   # è¯¦ç»†å…ƒæ•°æ®
                    'algorithm': 'audioseal',   # ç®—æ³•åç§°
                    'sample_rate': int,         # é‡‡æ ·ç‡
                    'audio_length': float,      # éŸ³é¢‘æ—¶é•¿
                    'detection_threshold': float,
                    'message_threshold': float
                }
            }
            
        ğŸš¨ å¤±è´¥æƒ…å†µè¿”å›:
            {
                'detected': False,
                'message': '',
                'confidence': 0.0,
                'error': str                    # é”™è¯¯ä¿¡æ¯
            }
        """
        self._ensure_audioseal()
        
        # å¤„ç†è¾“å…¥éŸ³é¢‘
        if isinstance(watermarked_audio, (str, Path)):
            from .utils import AudioIOUtils
            audio_tensor, sr = AudioIOUtils.load_audio(
                str(watermarked_audio), 
                target_sample_rate=self.sample_rate
            )
        else:
            audio_tensor = watermarked_audio
            sr = input_sample_rate or self.sample_rate
        
        # æå–æ°´å°
        result = self.audioseal_wrapper.extract(
            audio_tensor, sr, detection_threshold, message_threshold
        )
        
        return result
```

**ğŸ”¹ é«˜çº§æ¥å£: generate_audio_with_watermark() - æ–‡æœ¬è½¬è¯­éŸ³+æ°´å°**

```python
    def generate_audio_with_watermark(self,
                                     prompt: str,
                                     message: str,
                                     voice_preset: Optional[str] = None,
                                     temperature: float = 0.8,
                                     seed: Optional[int] = None,
                                     alpha: float = 1.0,
                                     output_path: Optional[str] = None) -> Union[torch.Tensor, str]:
        """
        ğŸ¯ é«˜çº§åŠŸèƒ½: æ–‡æœ¬è½¬è¯­éŸ³å¹¶åµŒå…¥æ°´å° (éœ€è¦Bark)
        
        ğŸ“‹ è¯¦ç»†å·¥ä½œæµç¨‹:
        1. ä½¿ç”¨Bark TTSç”Ÿæˆé«˜è´¨é‡è¯­éŸ³
        2. è‡ªåŠ¨åµŒå…¥AudioSealæ°´å°
        3. è¿”å›å¸¦æ°´å°çš„è¯­éŸ³éŸ³é¢‘
        
        ğŸ“¥ å‚æ•°è¯´æ˜:
            prompt: è¦è½¬æ¢çš„æ–‡æœ¬ï¼Œå¦‚ "Hello, this is a test message"
            message: è¦åµŒå…¥çš„æ°´å°ä¿¡æ¯
            voice_preset: è¯­éŸ³é¢„è®¾ï¼Œå¦‚ "v2/en_speaker_6", "v2/zh_speaker_0"
            temperature: ç”Ÿæˆæ¸©åº¦ (0.0-1.0ï¼Œæ§åˆ¶éšæœºæ€§)
            seed: éšæœºç§å­ (å¯é‡ç°ç”Ÿæˆ)
            alpha: æ°´å°å¼ºåº¦
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ (å¯é€‰)
            
        ğŸ“¤ è¿”å›å€¼:
            - å¦‚æœæä¾›output_path: è¿”å›ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
            - å¦åˆ™: è¿”å›å¸¦æ°´å°çš„éŸ³é¢‘å¼ é‡
            
        ğŸš¨ ä¾èµ–è¦æ±‚:
            éœ€è¦å®‰è£…Bark: pip install git+https://github.com/suno-ai/bark.git
        """
        self._ensure_bark()
        
        # ä½¿ç”¨Barkç”Ÿæˆè¯­éŸ³
        generated_audio = self.bark_generator.generate_audio(
            prompt, voice_preset, temperature, seed
        )
        
        # åµŒå…¥æ°´å°
        watermarked_audio = self.audioseal_wrapper.embed(
            generated_audio, message, self.sample_rate, alpha
        )
        
        if output_path:
            from .utils import AudioIOUtils
            AudioIOUtils.save_audio(watermarked_audio, output_path, self.sample_rate)
            return output_path
        else:
            return watermarked_audio
```

**ğŸ”§ æ ¸å¿ƒå†…éƒ¨æ–¹æ³•**

```python
    # === è´¨é‡è¯„ä¼°æ–¹æ³• ===
    def evaluate_quality(self, original: torch.Tensor, 
                        watermarked: torch.Tensor) -> Dict[str, float]:
        """è®¡ç®—éŸ³é¢‘è´¨é‡æŒ‡æ ‡ (SNR, MSE, ç›¸å…³æ€§)"""
        
    def batch_embed(self, audios: List, messages: List[str]) -> List:
        """æ‰¹é‡éŸ³é¢‘æ°´å°åµŒå…¥"""
        
    def batch_extract(self, watermarked_audios: List) -> List[Dict]:
        """æ‰¹é‡éŸ³é¢‘æ°´å°æå–"""
        
    # === ç»„ä»¶åˆå§‹åŒ–æ–¹æ³• ===
    def _ensure_audioseal(self):
        """ç¡®ä¿AudioSealå°è£…å™¨å·²åˆå§‹åŒ–"""
        
    def _ensure_bark(self):
        """ç¡®ä¿Barkç”Ÿæˆå™¨å·²åˆå§‹åŒ– (å¦‚æœéœ€è¦TTSåŠŸèƒ½)"""
```

**âš™ï¸ é…ç½®å‚æ•°è¯¦è§£**

```yaml
# config/audio_config.yaml - å®Œæ•´é…ç½®ç¤ºä¾‹
algorithm: "audioseal"
device: "auto"                          # 'cuda', 'cpu', 'auto'
nbits: 16                              # æ¶ˆæ¯ä½æ•°
sample_rate: 16000                     # é‡‡æ ·ç‡ (AudioSealè¦æ±‚16kHz)

# === AudioSealå‚æ•° ===
audioseal_params:
  detection_threshold: 0.5             # æ£€æµ‹é˜ˆå€¼
  message_threshold: 0.5               # æ¶ˆæ¯è§£ç é˜ˆå€¼
  alpha: 1.0                          # é»˜è®¤æ°´å°å¼ºåº¦

# === Bark TTSé…ç½® ===
bark_config:
  model_size: "large"                  # 'small', 'large'
  use_gpu: true                        # æ˜¯å¦ä½¿ç”¨GPU
  temperature: 0.8                     # ç”Ÿæˆæ¸©åº¦
  default_voice: "v2/en_speaker_6"     # é»˜è®¤è¯­éŸ³é¢„è®¾
  target_sample_rate: 16000            # ç›®æ ‡é‡‡æ ·ç‡

# === éŸ³é¢‘å¤„ç†å‚æ•° ===
audio_params:
  supported_formats: [".wav", ".mp3", ".flac", ".m4a", ".ogg"]
  normalize_audio: true                # æ˜¯å¦å½’ä¸€åŒ–éŸ³é¢‘
  quality_check: true                  # æ˜¯å¦è¿›è¡Œè´¨é‡æ£€æŸ¥
```

**ğŸš€ å®é™…ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µ**

```python
# === å®Œæ•´ä½¿ç”¨ç¤ºä¾‹ ===
from src.audio_watermark import create_audio_watermark
import torch
import time

# 1. åˆå§‹åŒ–ç³»ç»Ÿ
watermark_tool = create_audio_watermark()

# 2. ğŸ¯ åŸºç¡€éŸ³é¢‘æ°´å°æµç¨‹
print("=== åŸºç¡€éŸ³é¢‘æ°´å°æµ‹è¯• ===")

# åˆ›å»ºæµ‹è¯•éŸ³é¢‘ (1ç§’æ­£å¼¦æ³¢)
sample_rate = 16000
test_audio = 0.5 * torch.sin(2 * 3.14159 * 440 * torch.linspace(0, 1, sample_rate))
test_audio = test_audio.unsqueeze(0)  # æ·»åŠ é€šé“ç»´åº¦
test_message = "hello_audioseal_2025"

print(f"æµ‹è¯•éŸ³é¢‘å½¢çŠ¶: {test_audio.shape}")
print(f"æµ‹è¯•æ¶ˆæ¯: '{test_message}'")

# åµŒå…¥æ°´å°
start_time = time.time()
watermarked_audio = watermark_tool.embed_watermark(test_audio, test_message)
embed_time = time.time() - start_time

print(f"âœ… åµŒå…¥å®Œæˆ: {embed_time:.3f}ç§’")
print(f"æ°´å°éŸ³é¢‘å½¢çŠ¶: {watermarked_audio.shape}")

# æå–æ°´å°
start_time = time.time()
result = watermark_tool.extract_watermark(watermarked_audio)
extract_time = time.time() - start_time

print(f"âœ… æå–å®Œæˆ: {extract_time:.3f}ç§’")
print(f"æ£€æµ‹ç»“æœ: {result['detected']}")
print(f"è§£ç æ¶ˆæ¯: '{result['message']}'")
print(f"ç½®ä¿¡åº¦: {result['confidence']:.3f}")

# è´¨é‡è¯„ä¼°
quality = watermark_tool.evaluate_quality(test_audio, watermarked_audio)
print(f"ğŸµ éŸ³é¢‘è´¨é‡:")
print(f"  SNR: {quality['snr_db']:.2f} dB")
print(f"  ç›¸å…³æ€§: {quality['correlation']:.3f}")

# 3. ğŸ¯ æ–‡ä»¶I/Oå¤„ç†
print("\n=== æ–‡ä»¶I/Oæµ‹è¯• ===")

# ä¿å­˜åŸå§‹éŸ³é¢‘
from src.audio_watermark.utils import AudioIOUtils
AudioIOUtils.save_audio(test_audio, "test_original.wav", sample_rate)

# ä»æ–‡ä»¶åµŒå…¥æ°´å°
watermarked_path = watermark_tool.embed_watermark(
    "test_original.wav", 
    test_message,
    output_path="test_watermarked.wav"
)
print(f"ğŸ’¾ æ°´å°éŸ³é¢‘å·²ä¿å­˜: {watermarked_path}")

# ä»æ–‡ä»¶æå–æ°´å°
file_result = watermark_tool.extract_watermark("test_watermarked.wav")
print(f"ğŸ“ æ–‡ä»¶æ£€æµ‹: {'âœ…' if file_result['detected'] else 'âŒ'}")
print(f"ğŸ“ æ–‡ä»¶æ¶ˆæ¯: '{file_result['message']}'")

# 4. ğŸ¯ Bark TTS + æ°´å° (éœ€è¦å®‰è£…Bark)
print("\n=== æ–‡æœ¬è½¬è¯­éŸ³+æ°´å°æµ‹è¯• ===")
try:
    tts_text = "Hello, this is a test of text to speech with watermark."
    tts_message = "bark_tts_demo"
    
    # ç”Ÿæˆå¸¦æ°´å°çš„è¯­éŸ³
    generated_audio = watermark_tool.generate_audio_with_watermark(
        prompt=tts_text,
        message=tts_message,
        voice_preset="v2/en_speaker_6",
        temperature=0.7,
        seed=42,
        output_path="test_tts_watermarked.wav"
    )
    
    print(f"ğŸ¤ TTSéŸ³é¢‘å·²ç”Ÿæˆ: {generated_audio}")
    
    # éªŒè¯TTSéŸ³é¢‘ä¸­çš„æ°´å°
    tts_result = watermark_tool.extract_watermark(generated_audio)
    print(f"ğŸ¤ TTSæ£€æµ‹: {'âœ…' if tts_result['detected'] else 'âŒ'}")
    print(f"ğŸ¤ TTSæ¶ˆæ¯: '{tts_result['message']}'")
    
except Exception as e:
    print(f"âš ï¸ TTSåŠŸèƒ½ä¸å¯ç”¨: {e}")
    print("è¯·å®‰è£…Bark: pip install git+https://github.com/suno-ai/bark.git")

# 5. ğŸ¯ æ‰¹é‡å¤„ç†æµ‹è¯•
print("\n=== æ‰¹é‡å¤„ç†æµ‹è¯• ===")
test_messages = ["batch_01", "batch_02", "batch_03"]
test_audios = []

# ç”Ÿæˆæµ‹è¯•éŸ³é¢‘
for i, msg in enumerate(test_messages):
    # ä¸åŒé¢‘ç‡çš„æ­£å¼¦æ³¢
    freq = 440 + i * 100  # 440Hz, 540Hz, 640Hz
    audio = 0.5 * torch.sin(2 * 3.14159 * freq * torch.linspace(0, 1, sample_rate))
    test_audios.append(audio.unsqueeze(0))

batch_start = time.time()

# æ‰¹é‡åµŒå…¥
watermarked_audios = watermark_tool.batch_embed(test_audios, test_messages)
print(f"ğŸ“¦ æ‰¹é‡åµŒå…¥å®Œæˆ: {len([a for a in watermarked_audios if a is not None])}/{len(test_messages)}")

# æ‰¹é‡æå–
batch_results = watermark_tool.batch_extract(watermarked_audios)
batch_time = time.time() - batch_start

print(f"â±ï¸ æ‰¹é‡å¤„ç†æ€»æ—¶é—´: {batch_time:.3f}ç§’")
success_count = sum(1 for r in batch_results if r.get('detected', False))
print(f"ğŸ¯ æ‰¹é‡æˆåŠŸç‡: {success_count}/{len(batch_results)} ({success_count/len(batch_results):.1%})")

for i, result in enumerate(batch_results):
    status = "âœ…" if result.get('detected', False) else "âŒ"
    msg = result.get('message', 'None')
    conf = result.get('confidence', 0.0)
    print(f"  {i+1}. {status} {test_messages[i]} â†’ {msg} (ç½®ä¿¡åº¦: {conf:.3f})")

# 6. ğŸ¯ æ€§èƒ½ç»Ÿè®¡
print("\n=== æ€§èƒ½ç»Ÿè®¡ ===")
model_info = watermark_tool.get_model_info()
print(f"ç®—æ³•: {model_info['algorithm']}")
print(f"è®¾å¤‡: {model_info.get('device', 'Unknown')}")
print(f"é‡‡æ ·ç‡: {model_info.get('sample_rate', 'Unknown')} Hz")
print(f"æ¶ˆæ¯ä½æ•°: {model_info.get('nbits', 'Unknown')}")
```

**ğŸ“Š æ€§èƒ½åŸºå‡†å’Œå®æµ‹æ•°æ®**

| åŠŸèƒ½æŒ‡æ ‡ | å®æµ‹æ€§èƒ½ | æŠ€æœ¯ç‰¹ç‚¹ | çŠ¶æ€ |
|----------|----------|----------|------|
| **åŸºç¡€åµŒå…¥** | 0.93ç§’/1ç§’éŸ³é¢‘ | é«˜æ•ˆGPUåŠ é€Ÿï¼Œå†…å­˜ä¼˜åŒ– | âœ… ç”Ÿäº§å°±ç»ª |
| **åŸºç¡€æå–** | 0.04ç§’/1ç§’éŸ³é¢‘ | å®æ—¶æ£€æµ‹èƒ½åŠ› | âœ… ç”Ÿäº§å°±ç»ª |
| **éŸ³é¢‘è´¨é‡** | SNR: 44.45dB | å‡ ä¹æ— å¬è§‰å·®å¼‚ï¼Œè¶…è¿‡40dBæ ‡å‡† | âœ… é«˜è´¨é‡ |
| **æ£€æµ‹æˆåŠŸç‡** | 100% | ç¨³å®šå¯é çš„ç®—æ³•ï¼Œæ— è¯¯æ£€ | âœ… ç”Ÿäº§å°±ç»ª |
| **TTSç”Ÿæˆ** | 3-8ç§’/å¥ | å¤šè¯­è¨€é«˜è´¨é‡è¯­éŸ³ï¼Œæ™ºèƒ½ç¼“å­˜ | âœ… å¯ç”¨ |
| **æ‰¹å¤„ç†** | 2.8ç§’/3ä¸ªéŸ³é¢‘ | é«˜æ•ˆå¹¶è¡Œå¤„ç†ï¼Œæ‰©å±•æ€§å¥½ | âœ… ç”Ÿäº§å°±ç»ª |
| **å™ªå£°é²æ£’æ€§** | SNRâ‰¥10dBå¯é æ£€æµ‹ | æŠ—å„ç§éŸ³é¢‘æ”»å‡» | âœ… éªŒè¯é€šè¿‡ |

**ğŸ”§ æŠ€æœ¯å®ç°äº®ç‚¹ä¸è§£å†³çš„é—®é¢˜**ï¼š

| ç‰¹æ€§ | å®ç°æè¿° | è§£å†³çš„å…³é”®é—®é¢˜ | ä»·å€¼ |
|------|---------|-------------|-----|
| **Meta AudioSealå®Œæ•´é›†æˆ** | æ·±åº¦å­¦ä¹ éŸ³é¢‘æ°´å°æŠ€æœ¯ï¼ŒPythonå®Œæ•´å°è£… | é²æ£’æ€§ã€æŠ—æ”»å‡»èƒ½åŠ›ã€APIç¨³å®šæ€§ | ç”Ÿäº§ç¯å¢ƒå¯é æ€§ |
| **16ä½æ¶ˆæ¯ç¼–ç ç³»ç»Ÿ** | SHA256å“ˆå¸Œç¡®ä¿æ¶ˆæ¯ä¸€è‡´æ€§ï¼Œå­—ç¬¦ä¸²â†”äºŒè¿›åˆ¶ | æ¶ˆæ¯ç¼–ç ä¸€è‡´æ€§ã€å¯éªŒè¯æ€§ | æ•°æ®å¯é æ€§ä¿è¯ |
| **è®¾å¤‡è‡ªé€‚åº”ä¸ä¼˜åŒ–** | è‡ªåŠ¨CPU/CUDAæ£€æµ‹ï¼Œå¼ é‡è®¾å¤‡ä¸€è‡´æ€§ç®¡ç† | è®¾å¤‡ä¸åŒ¹é…ã€å†…å­˜ä¼˜åŒ–ã€å…¼å®¹æ€§ | éƒ¨ç½²çµæ´»æ€§ |
| **3Då¼ é‡ç»´åº¦å¤„ç†** | è§£å†³AudioSealå¯¹(batch,channels,time)ä¸¥æ ¼è¦æ±‚ | æ¨¡å‹æ¥å£ç¨³å®šæ€§ã€ç»´åº¦åŒ¹é…é”™è¯¯ | ç®—æ³•é›†æˆæˆåŠŸ |
| **Bark TTSæ™ºèƒ½é›†æˆ** | æœ¬åœ°ä¼˜å…ˆç¼“å­˜ã€ç¬¦å·é“¾æ¥ã€å¤šè¯­è¨€æ”¯æŒ | ç½‘ç»œä¾èµ–ã€å­˜å‚¨ç©ºé—´ã€è¯­éŸ³è´¨é‡ | ç«¯åˆ°ç«¯å¯ç”¨æ€§ |
| **é«˜æ•ˆæ‰¹å¤„ç†æ¶æ„** | å¹¶è¡ŒéŸ³é¢‘å¤„ç†ã€å†…å­˜ä¼˜åŒ–ã€é”™è¯¯å®¹é”™ | å¤§è§„æ¨¡å¤„ç†æ€§èƒ½ã€èµ„æºåˆ©ç”¨ç‡ | ç”Ÿäº§æ‰©å±•æ€§ |
| **å¤šæ ¼å¼éŸ³é¢‘å…¼å®¹** | WAV/MP3/FLACç­‰æ ¼å¼æ— ç¼æ”¯æŒ | æ ¼å¼è½¬æ¢ã€ç¼–ç å…¼å®¹æ€§ | ä½¿ç”¨ä¾¿åˆ©æ€§ |
| **å®Œæ•´è´¨é‡è¯„ä¼°ä½“ç³»** | SNR/MSE/ç›¸å…³æ€§/é²æ£’æ€§å…¨é¢æµ‹è¯• | è´¨é‡ç›‘æ§ã€æ€§èƒ½éªŒè¯ | è´¨é‡ä¿è¯ |

**ğŸ¯ å¤šæ¨¡æ€æ°´å°ç»Ÿä¸€æ¥å£è®¾è®¡ï¼ˆå·²å®ç°ï¼‰**ï¼š

| æ¥å£è¦ç´  | æ–‡æœ¬æ°´å°(CredID) | å›¾åƒæ°´å°(PRC) | éŸ³é¢‘æ°´å°(AudioSeal) | ç»Ÿä¸€è®¾è®¡ç†å¿µ |
|----------|----------|----------|----------|--------------|
| **è¾“å…¥æ ¼å¼** | `(model, tokenizer, prompt, message)` | `(prompt, message, key_id)` | `(audio, message)` | ç®€åŒ–å‚æ•°ï¼Œä¸“æ³¨æ ¸å¿ƒåŠŸèƒ½ |
| **è¾“å‡ºæ ¼å¼** | `{watermarked_text, success, metadata}` | `PIL.Image` | `torch.Tensor æˆ– file_path` | ç›´æ¥è¿”å›ç»“æœå¯¹è±¡ |
| **æ£€æµ‹è¾“å…¥** | `(text, model, tokenizer, candidates)` | `(image, key_id, mode)` | `(audio, thresholds)` | æ”¯æŒå¤šç§è¾“å…¥æ ¼å¼ |
| **æ£€æµ‹è¾“å‡º** | `{extracted_message, confidence, success}` | `{detected, message, confidence}` | `{detected, message, confidence}` | ç»Ÿä¸€çš„ç»“æœç»“æ„ |
| **æ€§èƒ½è¡¨ç°** | å€™é€‰æ¶ˆæ¯ä¼˜åŒ–æœç´¢ï¼Œå¤šæ®µå¤„ç† | 100%æ£€æµ‹ç‡ï¼Œä¸‰ç§ç²¾åº¦æ¨¡å¼ | 100%æ£€æµ‹ç‡ï¼Œ44dBéŸ³è´¨ï¼Œæ‰¹å¤„ç† | ç”Ÿäº§ç¯å¢ƒå°±ç»ª |
| **é«˜çº§åŠŸèƒ½** | æ™ºèƒ½åˆ†å‰²ï¼Œé”™è¯¯å¤„ç† | å¤šç²¾åº¦æ£€æµ‹ï¼Œç¦»çº¿æ¨¡å¼ | TTSé›†æˆï¼Œé²æ£’æ€§æµ‹è¯• | æ¯ä¸ªæ¨¡æ€çš„ä¸“é—¨ä¼˜åŒ– |
| **é…ç½®ç®¡ç†** | YAMLé…ç½®æ–‡ä»¶é©±åŠ¨ | YAMLé…ç½®æ–‡ä»¶é©±åŠ¨ | YAMLé…ç½®æ–‡ä»¶é©±åŠ¨ | ä¸€è‡´çš„é…ç½®æ–¹å¼ |
| **é”™è¯¯å¤„ç†** | è¯¦ç»†å¼‚å¸¸ä¿¡æ¯å’ŒçŠ¶æ€ | è¯¦ç»†å¼‚å¸¸ä¿¡æ¯å’ŒçŠ¶æ€ | è¯¦ç»†å¼‚å¸¸ä¿¡æ¯å’ŒçŠ¶æ€ | ç»Ÿä¸€é”™è¯¯å¤„ç†æœºåˆ¶ |
| **éƒ¨ç½²çŠ¶æ€** | âœ… ç”Ÿäº§å°±ç»ª | âœ… ç”Ÿäº§å°±ç»ª | âœ… ç”Ÿäº§å°±ç»ª | å®Œæ•´çš„å¤šæ¨¡æ€è§£å†³æ–¹æ¡ˆ |

### ğŸš€ éŸ³é¢‘æ°´å°æ¨¡å—ä½¿ç”¨æŒ‡å—ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰

**åŸºç¡€ä¾èµ–å®‰è£…**ï¼š
```bash
# åŸºç¡€åŠŸèƒ½ï¼ˆå¿…éœ€ï¼‰
pip install torch torchaudio julius soundfile librosa scipy matplotlib

# é«˜çº§åŠŸèƒ½ï¼šæ–‡æœ¬è½¬è¯­éŸ³ï¼ˆå¯é€‰ï¼‰
pip install git+https://github.com/suno-ai/bark.git
```

**å¿«é€Ÿå¼€å§‹ç¤ºä¾‹**ï¼š
```python
from src.audio_watermark import create_audio_watermark

# 1. åˆå§‹åŒ–ï¼ˆè‡ªåŠ¨è®¾å¤‡æ£€æµ‹ï¼‰
watermark_tool = create_audio_watermark()

# 2. åŸºç¡€æ°´å°æµç¨‹
import torch
audio = torch.randn(1, 16000)  # 1ç§’æµ‹è¯•éŸ³é¢‘
message = "production_watermark_2025"

# åµŒå…¥æ°´å°ï¼ˆ0.93ç§’ï¼ŒSNR 44.45dBï¼‰
watermarked = watermark_tool.embed_watermark(audio, message)

# æå–æ°´å°ï¼ˆ0.04ç§’ï¼Œ100%æˆåŠŸç‡ï¼‰
result = watermark_tool.extract_watermark(watermarked)
print(f"æ£€æµ‹: {result['detected']}, æ¶ˆæ¯: {result['message']}")

# 3. æ–‡æœ¬è½¬è¯­éŸ³+æ°´å°ï¼ˆéœ€è¦Barkï¼‰
tts_audio = watermark_tool.generate_audio_with_watermark(
    prompt="Hello, this is a watermarked speech",
    message="tts_demo",
    voice_preset="v2/en_speaker_6"
)
```

**ç”Ÿäº§ç¯å¢ƒé…ç½®ç¤ºä¾‹**ï¼š
```yaml
# config/audio_config.yaml
algorithm: "audioseal"
device: "auto"              # è‡ªåŠ¨é€‰æ‹©æœ€ä½³è®¾å¤‡
nbits: 16                   # 16ä½æ¶ˆæ¯ç¼–ç 
sample_rate: 16000          # AudioSealæ ‡å‡†é‡‡æ ·ç‡

audioseal_params:
  detection_threshold: 0.5  # æ£€æµ‹é˜ˆå€¼
  alpha: 1.0               # æ°´å°å¼ºåº¦

bark_config:
  model_size: "large"       # é«˜è´¨é‡æ¨¡å¼
  use_gpu: true             # å¯ç”¨GPUåŠ é€Ÿ
  temperature: 0.8          # ç”Ÿæˆæ¸©åº¦
  default_voice: "v2/en_speaker_6"
```

## ğŸ¬ è§†é¢‘æ°´å°æ¨¡å—ï¼ˆHunyuanVideo + VideoSealï¼‰

æœ¬æ¨¡å—å°† Diffusers çš„ HunyuanVideo æ–‡ç”Ÿè§†é¢‘ä¸ VideoSeal æ°´å°æ•´åˆä¸ºç»Ÿä¸€å·¥ä½œæµï¼Œé»˜è®¤ç¦»çº¿ä½¿ç”¨æœ¬åœ°å¿«ç…§ï¼Œé¿å…è”ç½‘ä¸ç¡®å®šæ€§ã€‚

- æ¨¡å‹å¡å‚è€ƒï¼ˆDiffusers ç¤ºä¾‹ï¼‰ï¼š[HunyuanVideo æ¨¡å‹å¡](https://huggingface.co/hunyuanvideo-community/HunyuanVideo)

### ä»£ç ç»“æ„
- `src/video_watermark/model_manager.py`
  - è´Ÿè´£å®šä½/ç¡®ä¿æœ¬åœ° HunyuanVideo å¿«ç…§å¯ç”¨ï¼›ä¼˜å…ˆæœ¬åœ°ï¼Œå¿…è¦æ—¶å¯å¼€å¯ä¸‹è½½ã€‚
- `src/video_watermark/hunyuan_video_generator.py`
  - æŒ‰å·¥ä½œè„šæœ¬æ–¹å¼ä»æœ¬åœ°å¿«ç…§åŠ è½½ï¼š
    - `HunyuanVideoTransformer3DModel.from_pretrained(local_path, subfolder="transformer", torch_dtype, local_files_only=True)`
    - `HunyuanVideoPipeline.from_pretrained(local_path, transformer=transformer, torch_dtype, local_files_only=True)`
  - CUDA ä¸‹å¯ç”¨ `vae.enable_tiling()` ä¸ `enable_model_cpu_offload()`ï¼Œé™ä½æ˜¾å­˜ä¸é»‘å±é£é™©ã€‚
  - æä¾›ï¼š`generate_video(...)` ä¸ `generate_video_tensor(...)`ï¼ˆè¿”å› `(frames, C, H, W)`ï¼‰
- `src/video_watermark/videoseal_wrapper.py`
  - åµŒå…¥ä¸æå–æ°´å°ï¼›å­—ç¬¦ä¸²â‡„bits è½¬æ¢ï¼›åˆ†å—æ£€æµ‹èšåˆã€‚
- `src/video_watermark/utils.py`
  - è§†é¢‘ I/Oï¼ˆOpenCVï¼‰ã€ä¿å­˜/è¯»å–ã€è®¡æ—¶ã€GPU å†…å­˜ç›‘æ§ã€‚
- `src/video_watermark/video_watermark.py`
  - å¯¹ä¸Šå±‚æä¾›ç»Ÿä¸€æ¥å£ï¼š
    - `generate_video_with_watermark(prompt, message, ...) -> str`
    - `embed_watermark(video_path, message, ...) -> str`
    - `extract_watermark(video_path, max_frames=None, chunk_size=None) -> Dict`
    - `batch_process_videos(...) -> list`

### ä¸»è¦æ¥å£ï¼ˆè¾“å…¥/è¾“å‡ºï¼‰
- `HunyuanVideoGenerator.generate_video(prompt, negative_prompt=None, num_frames=49, height=720, width=1280, num_inference_steps=30, guidance_scale=6.0, seed=None, output_path=None)`
  - è¾“å…¥ï¼šæç¤ºè¯ã€å¸§æ•°ï¼ˆå»ºè®® 4*k+1ï¼Œå¦‚ 13/49/75ï¼‰ã€åˆ†è¾¨ç‡ã€æ­¥æ•°ç­‰
  - è¾“å‡ºï¼šå¸§åºåˆ—/æ•°ç»„æˆ–ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
- `HunyuanVideoGenerator.generate_video_tensor(...) -> torch.Tensor`
  - è¾“å‡ºï¼š`(frames, channels, height, width)`ï¼Œå€¼åŸŸ `[0, 1]`
- `VideoWatermark.generate_video_with_watermark(prompt, message, ..., lowres_attenuation=True) -> str`
  - è¾“å‡ºï¼šå¸¦æ°´å°è§†é¢‘æ–‡ä»¶è·¯å¾„
- `VideoWatermark.embed_watermark(video_path, message, ..., max_frames=None) -> str`
  - è¾“å‡ºï¼šå¸¦æ°´å°è§†é¢‘æ–‡ä»¶è·¯å¾„
- `VideoWatermark.extract_watermark(video_path, max_frames=None, chunk_size=None) -> Dict[str, Any]`
  - è¾“å‡ºï¼š`{"detected": bool, "message": str, "confidence": float, ...}`

### ä½¿ç”¨ç¤ºä¾‹ï¼ˆç»Ÿä¸€æ¥å£ï¼‰
```python
from src.video_watermark.video_watermark import create_video_watermark

wm = create_video_watermark()

# æ–‡ç”Ÿè§†é¢‘ + æ°´å°ï¼ˆ5ç§’@15fps â†’ 75å¸§ï¼‰
out_path = wm.generate_video_with_watermark(
    prompt="é˜³å…‰æ´’åœ¨æµ·é¢ä¸Š",
    message="demo_msg",
    num_frames=75,
    height=320,
    width=512,
    num_inference_steps=30,
    seed=42
)

# æå–æ°´å°
result = wm.extract_watermark(out_path, max_frames=50)
```

### æµ‹è¯•ä¸è¿è¡Œ
- å›å½’æµ‹è¯•ï¼š`tests/test_video_watermark_demo.py`
  - ç”¨ä¾‹1ï¼šçº¯æ–‡ç”Ÿè§†é¢‘ï¼ˆåŒ…å«éé»‘å±åƒç´ æ£€æŸ¥ä¸ä¿å­˜ï¼‰
  - ç”¨ä¾‹2ï¼šæ–‡ç”Ÿè§†é¢‘ + æ°´å°åµŒå…¥ + æå–éªŒè¯
- è¿è¡Œï¼š
```bash
conda activate mmwt
python -u unified_watermark_tool/tests/test_video_watermark_demo.py
```

### é‡è¦çº¦å®šä¸å»ºè®®
- ä»…ç¦»çº¿åŠ è½½æœ¬åœ° HunyuanVideo å¿«ç…§ï¼ˆ`local_files_only=True`ï¼‰ã€‚
- CUDA ç¯å¢ƒä¸‹å¯ç”¨ `vae.enable_tiling()` ä¸ `enable_model_cpu_offload()`ï¼›é¿å…ä¸ `device_map` å¹¶ç”¨ã€‚
- 5ç§’@15fps æ¨è `num_frames=75` ä¸ `320x512` åˆ†è¾¨ç‡ï¼›å¦‚ OOMï¼Œç”Ÿæˆå™¨ä¼šè‡ªé€‚åº”é™å‚é‡è¯•ã€‚