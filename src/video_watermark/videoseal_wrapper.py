"""
VideoSealæ°´å°ç®—æ³•ç®€å•å°è£…
åŸºäºç°æœ‰çš„VideoSealå®ç°ï¼Œæä¾›ç»Ÿä¸€çš„æ°´å°åµŒå…¥å’Œæå–æ¥å£
"""

import os
import sys
import logging
import torch
import numpy as np
from typing import Dict, Any, Optional, Union
from pathlib import Path

# æ·»åŠ videosealè·¯å¾„åˆ°sys.path
videoseal_path = Path(__file__).parent / "videoseal"
if str(videoseal_path) not in sys.path:
    sys.path.insert(0, str(videoseal_path))

try:
    import videoseal
    from videoseal.models import Videoseal
    from videoseal.evals.metrics import bit_accuracy
    VIDEOSEAL_AVAILABLE = True
except ImportError:
    VIDEOSEAL_AVAILABLE = False
    logging.warning("VideoSeal not available. Please check the videoseal directory.")


class VideoSealWrapper:
    """VideoSealæ°´å°ç®—æ³•åŒ…è£…å™¨"""
    
    def __init__(self, device: Optional[str] = None):
        """
        åˆå§‹åŒ–VideoSealåŒ…è£…å™¨
        
        Args:
            device: è®¡ç®—è®¾å¤‡ ('cuda', 'cpu', æˆ–Noneè‡ªåŠ¨é€‰æ‹©)
        """
        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        
        # è®¾ç½®æ—¥å¿—
        self.logger = logging.getLogger(__name__)
        
        # æ£€æŸ¥ä¾èµ–
        if not VIDEOSEAL_AVAILABLE:
            raise ImportError(
                "VideoSeal not available. Please ensure the videoseal directory exists and is properly configured."
            )
    
    def _load_model(self):
        """å»¶è¿ŸåŠ è½½VideoSealæ¨¡å‹"""
        if self.model is not None:
            return
        
        self.logger.info("æ­£åœ¨åŠ è½½VideoSealæ¨¡å‹...")
        
        try:
            # åˆ‡æ¢åˆ°videosealç›®å½•ä»¥ç¡®ä¿æ­£ç¡®çš„è·¯å¾„
            current_dir = os.getcwd()
            videoseal_dir = Path(__file__).parent / "videoseal"
            
            os.chdir(videoseal_dir)
            try:
                # ä½¿ç”¨videosealçš„é»˜è®¤æ¨¡å‹åŠ è½½æ–¹å¼ï¼ˆæŒ‡å®šæ¨¡å‹å¡ï¼‰
                self.model = videoseal.load("videoseal_1.0")
            finally:
                # æ¢å¤å·¥ä½œç›®å½•
                os.chdir(current_dir)
            self.model.eval()
            self.model.to(self.device)
            
            # å¦‚æœæœ‰ç¼–è¯‘æ”¯æŒï¼Œå¯ç”¨ç¼–è¯‘ä¼˜åŒ–
            if hasattr(self.model, 'compile'):
                try:
                    self.model.compile()
                except Exception as e:
                    self.logger.warning(f"æ¨¡å‹ç¼–è¯‘å¤±è´¥ï¼Œå°†ä½¿ç”¨æœªç¼–è¯‘ç‰ˆæœ¬: {e}")
            
            self.logger.info(f"VideoSealæ¨¡å‹åŠ è½½å®Œæˆï¼Œè®¾å¤‡: {self.device}")
            
        except Exception as e:
            self.logger.error(f"åŠ è½½VideoSealæ¨¡å‹å¤±è´¥: {e}")
            raise RuntimeError(f"Failed to load VideoSeal model: {e}")
    
    def _string_to_bits(self, message: str) -> torch.Tensor:
        """
        å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºVideoSealå…¼å®¹çš„bit tensor
        
        Args:
            message: è¾“å…¥æ¶ˆæ¯å­—ç¬¦ä¸²
            
        Returns:
            torch.Tensor: bit tensorï¼Œå½¢çŠ¶ä¸º (1, n_bits)
        """
        # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºbytes
        message_bytes = message.encode('utf-8')
        
        # è½¬æ¢ä¸ºbit array
        bit_array = []
        for byte in message_bytes:
            # å°†æ¯ä¸ªå­—èŠ‚è½¬æ¢ä¸º8ä¸ªbit
            for i in range(8):
                bit_array.append((byte >> i) & 1)
        
        # å¦‚æœbitså¤ªå°‘ï¼Œå¡«å……åˆ°æœ€å°é•¿åº¦ï¼ˆæ¯”å¦‚64 bitsï¼‰
        min_bits = 64
        while len(bit_array) < min_bits:
            bit_array.append(0)
        
        # VideoSealé€šå¸¸ä½¿ç”¨256-bitæ¶ˆæ¯ï¼Œæˆªæ–­æˆ–å¡«å……åˆ°256
        target_bits = 256
        if len(bit_array) > target_bits:
            bit_array = bit_array[:target_bits]
        else:
            while len(bit_array) < target_bits:
                bit_array.append(0)
        
        # è½¬æ¢ä¸ºtensor
        bits_tensor = torch.tensor(bit_array, dtype=torch.float32, device=self.device).unsqueeze(0)
        return bits_tensor
    
    def _bits_to_string(self, bits_tensor: torch.Tensor) -> str:
        """
        å°†bit tensorè½¬æ¢å›å­—ç¬¦ä¸²
        
        Args:
            bits_tensor: bit tensor
            
        Returns:
            str: è§£ç çš„å­—ç¬¦ä¸²
        """
        # è½¬æ¢ä¸ºnumpy arrayå¹¶å–æ•´
        if isinstance(bits_tensor, torch.Tensor):
            bits_array = (bits_tensor > 0.5).cpu().numpy().astype(int).flatten()
        else:
            bits_array = (bits_tensor > 0.5).astype(int).flatten()
        
        # æŒ‰8ä¸ªbitä¸ºä¸€ç»„è½¬æ¢ä¸ºå­—èŠ‚
        bytes_list = []
        for i in range(0, len(bits_array), 8):
            if i + 8 <= len(bits_array):
                byte_bits = bits_array[i:i+8]
                # è½¬æ¢bit arrayä¸ºbyteå€¼
                byte_val = 0
                for j, bit in enumerate(byte_bits):
                    byte_val += bit * (2 ** j)
                
                if byte_val > 0:  # å¿½ç•¥0å­—èŠ‚ï¼ˆpaddingï¼‰
                    bytes_list.append(byte_val)
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        try:
            message = bytes(bytes_list).decode('utf-8', errors='ignore')
            # ç§»é™¤å°¾éƒ¨çš„ç©ºå­—ç¬¦å’Œpadding
            message = message.rstrip('\x00').rstrip()
            return message
        except Exception as e:
            self.logger.warning(f"å­—ç¬¦ä¸²è§£ç å¤±è´¥: {e}")
            return ""
    
    def embed_watermark(
        self,
        video_tensor: torch.Tensor,
        message: str,
        is_video: bool = True,
        lowres_attenuation: bool = True
    ) -> torch.Tensor:
        """
        åœ¨è§†é¢‘tensorä¸­åµŒå…¥æ°´å°
        
        Args:
            video_tensor: è¾“å…¥è§†é¢‘tensorï¼Œå½¢çŠ¶ä¸º (frames, channels, height, width)ï¼Œå€¼åŸŸ[0, 1]
            message: è¦åµŒå…¥çš„æ¶ˆæ¯å­—ç¬¦ä¸²
            is_video: æ˜¯å¦ä¸ºè§†é¢‘ï¼ˆTrueï¼‰è¿˜æ˜¯å›¾åƒåºåˆ—ï¼ˆFalseï¼‰
            lowres_attenuation: æ˜¯å¦å¯ç”¨ä½åˆ†è¾¨ç‡è¡°å‡
            
        Returns:
            torch.Tensor: å¸¦æ°´å°çš„è§†é¢‘tensor
        """
        self._load_model()
        
        self.logger.info(f"å¼€å§‹åµŒå…¥æ°´å°: '{message}'")
        self.logger.info(f"è§†é¢‘tensorå½¢çŠ¶: {video_tensor.shape}")
        
        # ç¡®ä¿tensoråœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        video_tensor = video_tensor.to(self.device)
        
        # å°†æ¶ˆæ¯è½¬æ¢ä¸ºbits
        message_bits = self._string_to_bits(message)
        
        try:
            with torch.no_grad():
                # ä½¿ç”¨VideoSealåµŒå…¥æ°´å°
                outputs = self.model.embed(
                    video_tensor,
                    msgs=message_bits,
                    is_video=is_video,
                    lowres_attenuation=lowres_attenuation
                )
                
                watermarked_video = outputs["imgs_w"]
                
                self.logger.info(f"æ°´å°åµŒå…¥å®Œæˆ: {watermarked_video.shape}")
                return watermarked_video
                
        except Exception as e:
            self.logger.error(f"æ°´å°åµŒå…¥å¤±è´¥: {e}")
            raise RuntimeError(f"Failed to embed watermark: {e}")
    
    def extract_watermark(
        self,
        watermarked_video: torch.Tensor,
        is_video: bool = True,
        chunk_size: int = 16
    ) -> Dict[str, Any]:
        """
        ä»å¸¦æ°´å°çš„è§†é¢‘ä¸­æå–æ°´å°
        
        Args:
            watermarked_video: å¸¦æ°´å°çš„è§†é¢‘tensorï¼Œå½¢çŠ¶ä¸º (frames, channels, height, width)
            is_video: æ˜¯å¦ä¸ºè§†é¢‘ï¼ˆTrueï¼‰è¿˜æ˜¯å›¾åƒåºåˆ—ï¼ˆFalseï¼‰
            
        Returns:
            Dict[str, Any]: æå–ç»“æœï¼ŒåŒ…å«detectedã€messageã€confidenceç­‰å­—æ®µ
        """
        self._load_model()
        
        self.logger.info(f"å¼€å§‹æå–æ°´å°ï¼Œè§†é¢‘å½¢çŠ¶: {watermarked_video.shape}")
        
        # ç¡®ä¿tensoråœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        watermarked_video = watermarked_video.to(self.device)
        
        try:
            with torch.no_grad():
                # å®ç°åˆ†å—å¤„ç†é€»è¾‘ï¼Œå¯¹é½inference_streaming.py
                num_frames = watermarked_video.shape[0]
                
                if num_frames <= chunk_size:
                    # å¦‚æœå¸§æ•°ä¸è¶³chunk_sizeï¼Œç›´æ¥å¤„ç†
                    outputs = self.model.detect(watermarked_video, is_video=is_video)
                    preds = outputs["preds"]
                    
                    # å¤„ç†é¢„æµ‹ç»“æœï¼Œæ’é™¤ç¬¬ä¸€ä¸ªbitï¼ˆå¯èƒ½ç”¨äºæ£€æµ‹ï¼‰
                    if len(preds.shape) > 1:
                        bits_pred = preds[0, 1:]
                    else:
                        bits_pred = preds[1:]
                else:
                    # åˆ†å—å¤„ç†ï¼Œä¸inference_streaming.pyå¯¹é½
                    self.logger.info(f"ä½¿ç”¨åˆ†å—å¤„ç†: {num_frames}å¸§ï¼Œchunk_size={chunk_size}")
                    
                    soft_msgs = []
                    num_chunks = (num_frames + chunk_size - 1) // chunk_size  # å‘ä¸Šå–æ•´
                    
                    for i in range(0, num_frames, chunk_size):
                        end_idx = min(i + chunk_size, num_frames)
                        chunk = watermarked_video[i:end_idx]
                        
                        # å¯¹æ¯ä¸ªchunkè¿›è¡Œæ£€æµ‹ï¼ˆå®Œå…¨å¯¹é½detect_video_clipå‡½æ•°ï¼‰
                        chunk_outputs = self.model.detect(chunk, is_video=is_video)
                        chunk_preds = chunk_outputs["preds"]
                        
                        # æ’é™¤ç¬¬ä¸€ä¸ªbitï¼ˆå®Œå…¨å¯¹é½inference_streaming.pyï¼‰
                        output_bits = chunk_preds[:, 1:]  # ä¿æŒbatchç»´åº¦ï¼Œå½¢çŠ¶ç±»ä¼¼[frames_in_chunk, 255]
                        
                        soft_msgs.append(output_bits)
                    
                    # æ‹¼æ¥æ‰€æœ‰chunkçš„ç»“æœå¹¶å–å¹³å‡ï¼ˆå…³é”®æ­¥éª¤ï¼‰
                    if soft_msgs:
                        soft_msgs_tensor = torch.cat(soft_msgs, dim=0)
                        bits_pred = soft_msgs_tensor.mean(dim=0)  # è·¨chunkå¹³å‡ï¼Œè¿™æ˜¯æé«˜å‡†ç¡®ç‡çš„å…³é”®
                        self.logger.info(f"åˆ†å—å¤„ç†å®Œæˆ: {len(soft_msgs)}ä¸ªchunkï¼Œå¹³å‡åbitså½¢çŠ¶: {bits_pred.shape}")
                    else:
                        # å¤‡ç”¨å¤„ç†
                        outputs = self.model.detect(watermarked_video, is_video=is_video)
                        preds = outputs["preds"]
                        if len(preds.shape) > 1:
                            bits_pred = preds[0, 1:]
                        else:
                            bits_pred = preds[1:]
                
                # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆè½¯é¢„æµ‹çš„å¹³å‡å€¼ï¼‰
                confidence = torch.mean(torch.abs(bits_pred - 0.5)).item() * 2  # è½¬æ¢åˆ°[0,1]èŒƒå›´
                
                # åˆ¤æ–­æ˜¯å¦æ£€æµ‹åˆ°æ°´å°ï¼ˆåŸºäºç½®ä¿¡åº¦é˜ˆå€¼ï¼‰
                # å‚è€ƒinference_streaming.pyï¼Œä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼æˆ–åŸºäºbitå‡†ç¡®ç‡
                detection_threshold = 0.05  # é™ä½é˜ˆå€¼ï¼Œå› ä¸ºåˆ†å—å¹³å‡åç½®ä¿¡åº¦è®¡ç®—æ›´å‡†ç¡®
                detected = confidence > detection_threshold
                
                # å°†bitsè½¬æ¢ä¸ºæ¶ˆæ¯å­—ç¬¦ä¸²
                extracted_message = ""
                if detected:
                    try:
                        # æ‰©å±•bitsåˆ°256é•¿åº¦ï¼ˆVideoSealæ ‡å‡†ï¼‰
                        if len(bits_pred) < 256:
                            # å¡«å……0
                            padded_bits = torch.zeros(256, device=bits_pred.device)
                            padded_bits[:len(bits_pred)] = bits_pred
                            bits_pred = padded_bits
                        
                        extracted_message = self._bits_to_string(bits_pred)
                    except Exception as e:
                        self.logger.warning(f"æ¶ˆæ¯è§£ç å¤±è´¥: {e}")
                        extracted_message = ""
                
                result = {
                    "detected": detected,
                    "message": extracted_message,
                    "confidence": confidence,
                    "raw_preds": bits_pred.cpu().numpy(),
                    "detection_threshold": detection_threshold
                }
                
                self.logger.info(
                    f"æ°´å°æå–å®Œæˆ - æ£€æµ‹: {detected}, ç½®ä¿¡åº¦: {confidence:.3f}, "
                    f"æ¶ˆæ¯: '{extracted_message}'"
                )
                
                return result
                
        except Exception as e:
            self.logger.error(f"æ°´å°æå–å¤±è´¥: {e}")
            return {
                "detected": False,
                "message": "",
                "confidence": 0.0,
                "error": str(e)
            }
    
    def get_random_message_bits(self) -> torch.Tensor:
        """è·å–éšæœºæ¶ˆæ¯bitsï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        self._load_model()
        return self.model.get_random_msg()
    
    def calculate_bit_accuracy(self, original_bits: torch.Tensor, extracted_bits: torch.Tensor) -> float:
        """è®¡ç®—bitå‡†ç¡®ç‡"""
        if VIDEOSEAL_AVAILABLE:
            return bit_accuracy(extracted_bits, original_bits).item()
        else:
            # ç®€å•çš„å‡†ç¡®ç‡è®¡ç®—
            return torch.mean((original_bits > 0.5) == (extracted_bits > 0.5)).item()
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        info = {
            "device": self.device,
            "model_loaded": self.model is not None,
            "videoseal_available": VIDEOSEAL_AVAILABLE
        }
        
        if self.model is not None:
            info.update({
                "model_type": type(self.model).__name__,
                "device_actual": next(self.model.parameters()).device if hasattr(self.model, 'parameters') else 'unknown'
            })
        
        return info
    
    def clear_model(self):
        """æ¸…ç†æ¨¡å‹ä»¥é‡Šæ”¾å†…å­˜"""
        if self.model is not None:
            del self.model
            self.model = None
            
            # æ¸…ç†GPUç¼“å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            self.logger.info("VideoSealæ¨¡å‹å·²æ¸…ç†")


# æ–¹ä¾¿çš„å·¥å…·å‡½æ•°
def create_videoseal_wrapper(device: Optional[str] = None) -> VideoSealWrapper:
    """
    åˆ›å»ºVideoSealåŒ…è£…å™¨çš„å¿«æ·å‡½æ•°
    
    Args:
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        VideoSealWrapper: åŒ…è£…å™¨å®ä¾‹
    """
    return VideoSealWrapper(device)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import sys
    
    logging.basicConfig(level=logging.INFO)
    
    print("æµ‹è¯•VideoSealWrapper...")
    
    try:
        wrapper = create_videoseal_wrapper()
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        info = wrapper.get_model_info()
        print("VideoSealä¿¡æ¯:")
        for key, value in info.items():
            print(f"  {key}: {value}")
        
        # å¦‚æœå‘½ä»¤è¡Œå‚æ•°åŒ…å«testï¼Œè¿›è¡Œå®é™…æµ‹è¯•
        if len(sys.argv) > 1 and sys.argv[1] == "test":
            print("\nå¼€å§‹æ°´å°æµ‹è¯•...")
            
            # åˆ›å»ºæµ‹è¯•è§†é¢‘tensorï¼ˆå¢åŠ å¸§æ•°ä»¥æµ‹è¯•åˆ†å—å¤„ç†ï¼‰
            test_video = torch.rand(32, 3, 256, 256)  # 32å¸§ï¼Œ3é€šé“ï¼Œ256x256
            
            print(f"æµ‹è¯•è§†é¢‘å½¢çŠ¶: {test_video.shape}")
            
            # æµ‹è¯•1ï¼šä½¿ç”¨éšæœºbitæ¶ˆæ¯ï¼ˆå¯¹é½inference_streaming.pyï¼‰
            print("\n=== æµ‹è¯•1ï¼šéšæœºbitæ¶ˆæ¯ ===")
            wrapper._load_model()
            random_bits = wrapper.model.get_random_msg()
            print(f"éšæœºbitså½¢çŠ¶: {random_bits.shape}")
            
            # ä½¿ç”¨VideoSealåŸç”Ÿçš„embed/detectæ–¹å¼
            with torch.no_grad():
                outputs = wrapper.model.embed(test_video, msgs=random_bits, is_video=True, lowres_attenuation=True)
                watermarked_tensor = outputs["imgs_w"]
                
                # æµ‹è¯•Aï¼šä¸åˆ†å—å¤„ç†ï¼ˆåŸå§‹æ–¹å¼ï¼‰
                print("\n-- æµ‹è¯•Aï¼šä¸åˆ†å—å¤„ç† --")
                extract_result_no_chunk = wrapper.extract_watermark(watermarked_tensor, chunk_size=999)  # å¤§äºå¸§æ•°
                original_bits = random_bits[0, 1:]
                extracted_bits_no_chunk = torch.tensor(extract_result_no_chunk['raw_preds'])[:255]
                bit_acc_no_chunk = wrapper.calculate_bit_accuracy(original_bits, extracted_bits_no_chunk) * 100
                
                print(f"  æ£€æµ‹ç»“æœ: {extract_result_no_chunk['detected']}")
                print(f"  ç½®ä¿¡åº¦: {extract_result_no_chunk['confidence']:.3f}")
                print(f"  Bitå‡†ç¡®ç‡: {bit_acc_no_chunk:.1f}%")
                
                # æµ‹è¯•Bï¼šåˆ†å—å¤„ç†ï¼ˆä¼˜åŒ–æ–¹å¼ï¼‰
                print("\n-- æµ‹è¯•Bï¼šåˆ†å—å¤„ç†(chunk_size=16) --")
                extract_result_chunk = wrapper.extract_watermark(watermarked_tensor, chunk_size=16)
                extracted_bits_chunk = torch.tensor(extract_result_chunk['raw_preds'])[:255]
                bit_acc_chunk = wrapper.calculate_bit_accuracy(original_bits, extracted_bits_chunk) * 100
                
                print(f"  æ£€æµ‹ç»“æœ: {extract_result_chunk['detected']}")
                print(f"  ç½®ä¿¡åº¦: {extract_result_chunk['confidence']:.3f}")
                print(f"  Bitå‡†ç¡®ç‡: {bit_acc_chunk:.1f}%")
                
                print(f"\nğŸ“Š å¯¹æ¯”ç»“æœ:")
                print(f"  ç½®ä¿¡åº¦æå‡: {extract_result_chunk['confidence'] - extract_result_no_chunk['confidence']:.3f}")
                print(f"  å‡†ç¡®ç‡æå‡: {bit_acc_chunk - bit_acc_no_chunk:.1f}%")
            
            # æµ‹è¯•2ï¼šå­—ç¬¦ä¸²æ¶ˆæ¯
            print("\n=== æµ‹è¯•2ï¼šå­—ç¬¦ä¸²æ¶ˆæ¯ ===")
            test_message = "test_videoseal"
            print(f"æµ‹è¯•æ¶ˆæ¯: '{test_message}'")
            
            # åµŒå…¥æ°´å°
            watermarked_video = wrapper.embed_watermark(test_video, test_message)
            print(f"âœ… æ°´å°åµŒå…¥å®Œæˆ: {watermarked_video.shape}")
            
            # æå–æ°´å°
            result = wrapper.extract_watermark(watermarked_video)
            print(f"âœ… æ°´å°æå–å®Œæˆ:")
            print(f"  æ£€æµ‹ç»“æœ: {result['detected']}")
            print(f"  æå–æ¶ˆæ¯: '{result['message']}'")
            print(f"  ç½®ä¿¡åº¦: {result['confidence']:.3f}")
            print(f"  éªŒè¯æˆåŠŸ: {result['message'] == test_message}")
    
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()