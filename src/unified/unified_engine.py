"""
å¤šæ¨¡æ€æ°´å°å·¥å…·ç»Ÿä¸€å¼•æ“
éµå¾ªKISSåŸåˆ™ï¼Œæä¾›ç®€æ´ç»Ÿä¸€çš„å¤šæ¨¡æ€æ°´å°æ¥å£
"""

import torch
import logging
from typing import Dict, Any, Optional, Union
from PIL import Image

try:
    # ç›¸å¯¹å¯¼å…¥ï¼ˆå½“ä½œä¸ºåŒ…è¿è¡Œæ—¶ï¼‰
    from ..text_watermark.credid_watermark import CredIDWatermark
    from ..image_watermark.image_watermark import ImageWatermark
    from ..audio_watermark.audio_watermark import AudioWatermark
    from ..video_watermark.video_watermark import VideoWatermark
except ImportError:
    try:
        # ç»å¯¹å¯¼å…¥ï¼ˆå½“ src åœ¨è·¯å¾„ä¸­æ—¶ï¼‰
        from text_watermark.credid_watermark import CredIDWatermark
        from image_watermark.image_watermark import ImageWatermark
        from audio_watermark.audio_watermark import AudioWatermark
        from video_watermark.video_watermark import VideoWatermark
    except ImportError as e:
        raise ImportError(f"æ— æ³•å¯¼å…¥æ°´å°æ¨¡å—: {e}. è¯·ç¡®ä¿ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼Œå¹¶ä¸” src ç›®å½•åœ¨ Python è·¯å¾„ä¸­ã€‚")


class UnifiedWatermarkEngine:
    """
    å¤šæ¨¡æ€æ°´å°ç»Ÿä¸€å¼•æ“
    
    éµå¾ªKISSåŸåˆ™çš„ç®€æ´è®¾è®¡ï¼š
    - ç»Ÿä¸€çš„embed/extractæ¥å£
    - ä½¿ç”¨æµ‹è¯•éªŒè¯çš„æœ€ä¼˜é»˜è®¤å‚æ•°
    - å›¾åƒé»˜è®¤ä½¿ç”¨videosealç®—æ³•
    - æ”¯æŒtext/image/audio/videoå››ç§æ¨¡æ€
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–ç»Ÿä¸€æ°´å°å¼•æ“
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.logger = logging.getLogger(__name__)
        
        # å»¶è¿Ÿåˆå§‹åŒ–å„æ¨¡æ€å¤„ç†å™¨ï¼ŒèŠ‚çœå†…å­˜
        self._text_watermark = None
        self._image_watermark = None  
        self._audio_watermark = None
        self._video_watermark = None
        # æ–‡æœ¬æ¨¡å‹ä¸åˆ†è¯å™¨ï¼ˆæ‡’åŠ è½½åç¼“å­˜ï¼‰
        self._text_model = None
        self._text_tokenizer = None
        
        self.config_path = config_path
        
        self.logger.info("UnifiedWatermarkEngineåˆå§‹åŒ–å®Œæˆ")
    
    def _project_root(self) -> str:
        """è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŸºäºå½“å‰æ–‡ä»¶ä½ç½®æ¨æ–­ï¼‰ã€‚"""
        import os
        return os.path.dirname(os.path.dirname(os.path.dirname(__file__)))

    def _candidate_cache_dirs(self) -> list:
        """è¿”å›å¯èƒ½çš„æœ¬åœ°ç¼“å­˜ç›®å½•åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ã€‚"""
        import os
        candidates = []
        if os.getenv('HF_HOME'):
            candidates.append(os.path.join(os.getenv('HF_HOME'), 'hub'))
        if os.getenv('HF_HUB_CACHE'):
            candidates.append(os.getenv('HF_HUB_CACHE'))
        # é¡¹ç›®å†… models ç›®å½•
        candidates.append(os.path.join(self._project_root(), 'models'))
        # ç”¨æˆ·çº§é»˜è®¤ç¼“å­˜
        candidates.append('/fs-computility/wangxuhong/limeilin/.cache/huggingface/hub')
        candidates.append(os.path.expanduser('~/.cache/huggingface/hub'))
        # å»é‡å¹¶ä¿ç•™é¡ºåº
        seen = set()
        ordered = []
        for p in candidates:
            if p and p not in seen:
                seen.add(p)
                ordered.append(p)
        return ordered

    def _load_text_config(self) -> Dict[str, Any]:
        """åŠ è½½æ–‡æœ¬æ°´å°é…ç½®ã€‚ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ config_pathï¼Œå…¶æ¬¡ä½¿ç”¨é¡¹ç›®é»˜è®¤ã€‚"""
        import os
        import yaml
        # ä¼˜å…ˆä½¿ç”¨ self.config_path
        cfg_path = None
        if self.config_path and os.path.isfile(self.config_path):
            cfg_path = self.config_path
        else:
            # é»˜è®¤æŒ‡å‘é¡¹ç›®å†… config/text_config.yaml
            default_path = os.path.join(self._project_root(), 'config', 'text_config.yaml')
            if os.path.isfile(default_path):
                cfg_path = default_path
        if cfg_path is None:
            # é€€å›åˆ°å†…ç½®é»˜è®¤
            return {
                'mode': 'lm',
                'model_name': 'sshleifer/tiny-gpt2',
                'lm_params': {
                    'delta': 1.5,
                    'prefix_len': 10,
                    'message_len': 10
                },
                'wm_params': {
                    'encode_ratio': 8,
                    'strategy': 'vanilla'
                },
                'model_config': {
                    'cache_dir': os.path.join(self._project_root(), 'models')
                }
            }
        with open(cfg_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f) or {}
        return data

    def _init_text_model_tokenizer(self):
        """ä½¿ç”¨ä¸ test_complex_messages_real.py ä¸€è‡´çš„ç­–ç•¥åˆå§‹åŒ–æ–‡æœ¬æ¨¡å‹ä¸åˆ†è¯å™¨ï¼ˆç¦»çº¿ä¼˜å…ˆï¼‰ã€‚"""
        if self._text_model is not None and self._text_tokenizer is not None:
            return
        import os
        import torch
        from transformers import AutoModelForCausalLM, AutoTokenizer

        # å¼ºåˆ¶ç¦»çº¿é¦–é€‰ï¼Œé¿å…è”ç½‘ä¾èµ–
        os.environ.setdefault('TRANSFORMERS_OFFLINE', '1')
        os.environ.setdefault('HF_HUB_OFFLINE', '1')

        cfg = self._load_text_config()
        primary_model = cfg.get('model_name', 'sshleifer/tiny-gpt2')
        model_cfg = cfg.get('model_config', {})

        # æ„é€ å€™é€‰æ¨¡å‹åˆ—è¡¨ï¼šä¼˜å…ˆé…ç½®ï¼Œå…¶æ¬¡tinyæ¨¡å‹
        candidate_models = [m for m in [primary_model, 'sshleifer/tiny-gpt2'] if m]

        # éå†å¯èƒ½çš„ç¼“å­˜ç›®å½•å¹¶å°è¯•åŠ è½½
        candidate_cache_dirs = []
        if model_cfg.get('cache_dir'):
            candidate_cache_dirs.append(model_cfg.get('cache_dir'))
        candidate_cache_dirs.extend(self._candidate_cache_dirs())

        trust_remote_code = bool(model_cfg.get('trust_remote_code', True))
        last_error = None

        for model_name in candidate_models:
            for cache_dir in candidate_cache_dirs:
                try:
                    if cache_dir and not os.path.isdir(cache_dir):
                        continue
                    tokenizer = AutoTokenizer.from_pretrained(
                        model_name,
                        cache_dir=cache_dir,
                        local_files_only=True,
                        trust_remote_code=trust_remote_code,
                        use_fast=True
                    )
                    model = AutoModelForCausalLM.from_pretrained(
                        model_name,
                        cache_dir=cache_dir,
                        local_files_only=True,
                        trust_remote_code=trust_remote_code,
                        device_map=model_cfg.get('device_map', 'auto'),
                        torch_dtype=(torch.float16 if torch.cuda.is_available() else torch.float32)
                    )
                    if tokenizer.pad_token is None:
                        tokenizer.pad_token = tokenizer.eos_token
                    self._text_model = model
                    self._text_tokenizer = tokenizer
                    self.logger.info(f"æ–‡æœ¬æ¨¡å‹åŠ è½½æˆåŠŸ: {model_name} (cache_dir={cache_dir})")
                    return
                except Exception as e:
                    last_error = e
                    continue

        # è‹¥å…¨éƒ¨å¤±è´¥ï¼Œè®°å½•è­¦å‘Š
        self.logger.warning(f"ç¦»çº¿åŠ è½½æ–‡æœ¬æ¨¡å‹å¤±è´¥ï¼Œç¨ååœ¨è°ƒç”¨æ—¶ä»å°†æŠ¥é”™ã€‚æœ€åé”™è¯¯: {last_error}")

    def _get_text_watermark(self) -> CredIDWatermark:
        """è·å–æ–‡æœ¬æ°´å°å¤„ç†å™¨ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._text_watermark is None:
            # è¯»å–é…ç½®å¹¶åˆå§‹åŒ–å¤„ç†å™¨
            config = self._load_text_config()
            self._text_watermark = CredIDWatermark(config)
            # åŒæ­¥åˆå§‹åŒ–æ¨¡å‹ä¸åˆ†è¯å™¨ï¼ˆç¦»çº¿ä¼˜å…ˆï¼‰
            self._init_text_model_tokenizer()
        return self._text_watermark
    
    def _get_image_watermark(self) -> ImageWatermark:
        """è·å–å›¾åƒæ°´å°å¤„ç†å™¨ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._image_watermark is None:
            self._image_watermark = ImageWatermark(self.config_path)
            # è®¾ç½®ä¸ºvideosealç®—æ³•ï¼ˆé»˜è®¤ï¼‰
            self._image_watermark.algorithm = 'videoseal'
        return self._image_watermark
    
    def _get_audio_watermark(self) -> AudioWatermark:
        """è·å–éŸ³é¢‘æ°´å°å¤„ç†å™¨ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._audio_watermark is None:
            self._audio_watermark = AudioWatermark(self.config_path)
        return self._audio_watermark
    
    def _get_video_watermark(self) -> VideoWatermark:
        """è·å–è§†é¢‘æ°´å°å¤„ç†å™¨ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._video_watermark is None:
            from ..video_watermark.video_watermark import create_video_watermark
            self._video_watermark = create_video_watermark()
        return self._video_watermark
    
    def embed(self, prompt: str, message: str, modality: str, **kwargs) -> Any:
        """
        ç»Ÿä¸€åµŒå…¥æ¥å£
        
        Args:
            prompt: è¾“å…¥æç¤ºï¼ˆæ–‡æœ¬å†…å®¹ã€å›¾åƒæè¿°ã€éŸ³é¢‘æ–‡æœ¬ç­‰ï¼‰
            message: è¦åµŒå…¥çš„æ°´å°æ¶ˆæ¯
            modality: æ¨¡æ€ç±»å‹ ('text', 'image', 'audio', 'video')
            **kwargs: é¢å¤–å‚æ•°ï¼ˆå¦‚model, tokenizerç­‰ï¼‰
            
        Returns:
            å¸¦æ°´å°çš„å†…å®¹ï¼ˆå…·ä½“ç±»å‹å–å†³äºæ¨¡æ€ï¼‰
            - text: str
            - image: PIL.Image
            - audio: torch.Tensor æˆ– strï¼ˆå¦‚æœæŒ‡å®šoutput_pathï¼‰
            - video: strï¼ˆè§†é¢‘æ–‡ä»¶è·¯å¾„ï¼‰
        """
        self.logger.info(f"å¼€å§‹{modality}æ°´å°åµŒå…¥: prompt='{prompt[:50]}...', message='{message}'")
        
        try:
            if modality == 'text':
                # æ–‡æœ¬æ°´å°ï¼šéœ€è¦æ¨¡å‹å’Œåˆ†è¯å™¨
                watermark = self._get_text_watermark()
                
                # CredIDéœ€è¦æ¨¡å‹å’Œåˆ†è¯å™¨å‚æ•°
                model = kwargs.get('model') or self._text_model
                tokenizer = kwargs.get('tokenizer') or self._text_tokenizer
                
                if model is None or tokenizer is None:
                    raise ValueError("æ–‡æœ¬æ°´å°éœ€è¦æä¾›modelå’Œtokenizerå‚æ•°")
                
                # è°ƒç”¨æ­£ç¡®çš„embedæ–¹æ³•
                result = watermark.embed(model, tokenizer, prompt, message)
                
                if result.get('success'):
                    return result['watermarked_text']
                else:
                    raise RuntimeError(f"æ–‡æœ¬æ°´å°åµŒå…¥å¤±è´¥: {result.get('error', 'Unknown error')}")
                    
                
            elif modality == 'image':
                # å›¾åƒæ°´å°ï¼šä½¿ç”¨videosealç®—æ³•
                watermark = self._get_image_watermark()
                if 'image_input' in kwargs:
                    # åœ¨ç°æœ‰å›¾åƒä¸ŠåµŒå…¥æ°´å°
                    image_input = kwargs.pop('image_input')  # ç§»é™¤é¿å…é‡å¤ä¼ é€’
                    return watermark.embed_watermark(
                        image_input, 
                        message=message, 
                        **kwargs
                    )
                else:
                    # ç”Ÿæˆæ–°å›¾åƒå¹¶åµŒå…¥æ°´å°
                    # ğŸ†• AIç”Ÿæˆæ¨¡å¼ï¼šè¯·æ±‚è¿”å›åŸå§‹å›¾åƒ
                    return watermark.generate_with_watermark(
                        prompt, 
                        message=message,
                        return_original=True,  # è¯·æ±‚åŒæ—¶è¿”å›åŸå§‹å›¾åƒ
                        **kwargs
                    )
                    
            elif modality == 'audio':
                # éŸ³é¢‘æ°´å°ï¼šä½¿ç”¨audiosealç®—æ³•
                watermark = self._get_audio_watermark()
                if 'audio_input' in kwargs:
                    # åœ¨ç°æœ‰éŸ³é¢‘ä¸ŠåµŒå…¥æ°´å°
                    audio_input = kwargs.pop('audio_input')  # ç§»é™¤audio_inputé¿å…é‡å¤
                    return watermark.embed_watermark(
                        audio_input, 
                        message, 
                        **kwargs
                    )
                else:
                    # æ–‡æœ¬è½¬è¯­éŸ³+æ°´å°
                    # ğŸ†• å¯¹äºAIç”ŸæˆéŸ³é¢‘ï¼Œä¼ é€’ return_original=True ä»¥æ”¯æŒå¯¹æ¯”æ˜¾ç¤º
                    return watermark.generate_audio_with_watermark(
                        prompt, 
                        message,
                        return_original=True,
                        **kwargs
                    )
                    
            elif modality == 'video':
                # è§†é¢‘æ°´å°ï¼šHunyuanVideo + VideoSeal
                watermark = self._get_video_watermark()
                if 'video_input' in kwargs:
                    # åœ¨ç°æœ‰è§†é¢‘ä¸ŠåµŒå…¥æ°´å°
                    video_input = kwargs.pop('video_input')  # ç§»é™¤video_inputé¿å…é‡å¤
                    return watermark.embed_watermark(
                        video_input, 
                        message, 
                        **kwargs
                    )
                else:
                    # æ–‡ç”Ÿè§†é¢‘+æ°´å°
                    # è‹¥æœªä¼ å…¥åˆ†è¾¨ç‡ï¼Œè®¾ç½®æ›´å®‰å…¨çš„é»˜è®¤åˆ†è¾¨ç‡ï¼ˆ16å€æ•°ï¼‰
                    if 'height' not in kwargs:
                        kwargs['height'] = 320
                    if 'width' not in kwargs:
                        kwargs['width'] = 512
                    # ğŸ†• AIç”Ÿæˆæ¨¡å¼ï¼šè¯·æ±‚è¿”å›åŸå§‹è§†é¢‘
                    return watermark.generate_video_with_watermark(
                        prompt, 
                        message,
                        return_original=True,  # è¯·æ±‚åŒæ—¶è¿”å›åŸå§‹è§†é¢‘
                        **kwargs
                    )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡æ€ç±»å‹: {modality}")
                
        except Exception as e:
            self.logger.error(f"{modality}æ°´å°åµŒå…¥å¤±è´¥: {e}")
            raise
    
    def extract(self, content: Any, modality: str, **kwargs) -> Dict[str, Any]:
        """
        ç»Ÿä¸€æå–æ¥å£
        
        Args:
            content: å¾…æ£€æµ‹å†…å®¹
                - text: str
                - image: PIL.Image æˆ– strï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰
                - audio: torch.Tensor æˆ– strï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰
                - video: strï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰
            modality: æ¨¡æ€ç±»å‹ ('text', 'image', 'audio', 'video')
            **kwargs: é¢å¤–å‚æ•°
            
        Returns:
            Dict[str, Any]: ç»Ÿä¸€æ ¼å¼çš„æ£€æµ‹ç»“æœ
                - detected: bool, æ˜¯å¦æ£€æµ‹åˆ°æ°´å°
                - message: str, æå–çš„æ¶ˆæ¯
                - confidence: float, ç½®ä¿¡åº¦ (0.0-1.0)
                - metadata: dict, é¢å¤–ä¿¡æ¯
        """
        self.logger.info(f"å¼€å§‹{modality}æ°´å°æå–")
        
        try:
            if modality == 'text':
                watermark = self._get_text_watermark()
                
                # CredIDéœ€è¦æ¨¡å‹å’Œåˆ†è¯å™¨å‚æ•°
                model = kwargs.get('model') or self._text_model
                tokenizer = kwargs.get('tokenizer') or self._text_tokenizer
                
                if model is None or tokenizer is None:
                    raise ValueError("æ–‡æœ¬æ°´å°æå–éœ€è¦æä¾›modelå’Œtokenizerå‚æ•°")
                
                # è°ƒç”¨æ­£ç¡®çš„extractæ–¹æ³•
                result = watermark.extract(content, model, tokenizer, 
                                         candidates_messages=kwargs.get('candidates_messages'))
                
                # ç»Ÿä¸€è¿”å›æ ¼å¼
                return {
                    'detected': result.get('success', False),
                    'message': result.get('extracted_message', ''),
                    'confidence': result.get('confidence', 0.0),
                    'metadata': result.get('metadata', {})
                }
                
            elif modality == 'image':
                watermark = self._get_image_watermark()
                # ä½¿ç”¨ä¼˜åŒ–çš„VideoSealå‚æ•°ï¼šreplicate=32æé«˜å¤šå¸§å¹³å‡ç¨³å®šæ€§ï¼Œchunk_size=16ä¼˜åŒ–åˆ†å—å¤„ç†
                result = watermark.extract_watermark(
                    content, 
                    replicate=kwargs.get('replicate', 32),
                    chunk_size=kwargs.get('chunk_size', 16),
                    **kwargs
                )
                return {
                    'detected': result.get('detected', False),
                    'message': result.get('message', ''),
                    'confidence': result.get('confidence', 0.0),
                    'metadata': result.get('metadata', {})
                }
                
            elif modality == 'audio':
                watermark = self._get_audio_watermark()
                result = watermark.extract_watermark(content, **kwargs)
                return {
                    'detected': result.get('detected', False),
                    'message': result.get('message', ''),
                    'confidence': result.get('confidence', 0.0),
                    'metadata': result.get('metadata', {})
                }
                
            elif modality == 'video':
                watermark = self._get_video_watermark()
                # ä½¿ç”¨æµ‹è¯•éªŒè¯çš„é»˜è®¤å‚æ•°
                result = watermark.extract_watermark(
                    content,
                    chunk_size=kwargs.get('chunk_size', 16),
                    **kwargs
                )
                return {
                    'detected': result.get('detected', False),
                    'message': result.get('message', ''),
                    'confidence': result.get('confidence', 0.0),
                    'metadata': result.get('metadata', {})
                }
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡æ€ç±»å‹: {modality}")
                
        except Exception as e:
            self.logger.error(f"{modality}æ°´å°æå–å¤±è´¥: {e}")
            return {
                'detected': False,
                'message': '',
                'confidence': 0.0,
                'metadata': {'error': str(e)}
            }
    
    def get_supported_modalities(self) -> list:
        """è·å–æ”¯æŒçš„æ¨¡æ€åˆ—è¡¨"""
        return ['text', 'image', 'audio', 'video']
    
    def get_default_algorithms(self) -> Dict[str, str]:
        """è·å–å„æ¨¡æ€çš„é»˜è®¤ç®—æ³•"""
        return {
            'text': 'credid',
            'image': 'videoseal',  # é»˜è®¤ä½¿ç”¨videoseal
            'audio': 'audioseal',
            'video': 'hunyuan+videoseal'
        }


# ä¾¿æ·å·¥å‚å‡½æ•°
def create_unified_engine(config_path: Optional[str] = None) -> UnifiedWatermarkEngine:
    """
    åˆ›å»ºç»Ÿä¸€æ°´å°å¼•æ“çš„ä¾¿æ·å‡½æ•°
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        UnifiedWatermarkEngine: ç»Ÿä¸€æ°´å°å¼•æ“å®ä¾‹
    """
    return UnifiedWatermarkEngine(config_path)


if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    logging.basicConfig(level=logging.INFO)
    
    engine = create_unified_engine()
    
    print("æ”¯æŒçš„æ¨¡æ€:", engine.get_supported_modalities())
    print("é»˜è®¤ç®—æ³•:", engine.get_default_algorithms())
    
    print("UnifiedWatermarkEngineæµ‹è¯•å®Œæˆ")