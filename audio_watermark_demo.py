#!/usr/bin/env python3
"""
éŸ³é¢‘æ°´å°ç«¯åˆ°ç«¯æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå®Œæ•´çš„æ–‡æœ¬â†’éŸ³é¢‘â†’æ°´å°â†’æå–æµç¨‹

ä½¿ç”¨æ–¹æ³•:
    python audio_watermark_demo.py --mode basic    # åŸºç¡€æ¼”ç¤º (ä»…AudioSeal)
    python audio_watermark_demo.py --mode full     # å®Œæ•´æ¼”ç¤º (AudioSeal + Bark)
    python audio_watermark_demo.py --mode custom   # è‡ªå®šä¹‰æ¼”ç¤º
"""

import os
import sys
import argparse
import logging
import torch
import time
from pathlib import Path
from typing import Optional, Dict, Any

# æ·»åŠ srcè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

try:
    from src.unified.watermark_tool import WatermarkTool
    from src.audio_watermark import (
        AudioWatermark, AUDIOSEAL_AVAILABLE, HAS_BARK,
        AudioIOUtils, AudioVisualizationUtils, print_status
    )
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


class AudioWatermarkDemo:
    """éŸ³é¢‘æ°´å°æ¼”ç¤ºç±»"""
    
    def __init__(self, output_dir: str = "demo_outputs/audio"):
        """
        åˆå§‹åŒ–æ¼”ç¤º
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–å·¥å…·
        self.unified_tool = None
        self.audio_watermark = None
        
        print("ğŸµ éŸ³é¢‘æ°´å°æ¼”ç¤ºç³»ç»Ÿ")
        print("=" * 50)
    
    def setup_tools(self):
        """åˆå§‹åŒ–å·¥å…·"""
        self.logger.info("åˆå§‹åŒ–éŸ³é¢‘æ°´å°å·¥å…·...")
        
        try:
            # åˆ›å»ºç»Ÿä¸€å·¥å…·
            self.unified_tool = WatermarkTool()
            
            # åˆ›å»ºä¸“ç”¨éŸ³é¢‘æ°´å°å·¥å…·
            from src.audio_watermark import create_audio_watermark
            self.audio_watermark = create_audio_watermark()
            
            print("âœ… å·¥å…·åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ å·¥å…·åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def print_system_status(self):
        """æ‰“å°ç³»ç»ŸçŠ¶æ€"""
        print("\nğŸ“Š ç³»ç»ŸçŠ¶æ€æ£€æŸ¥:")
        
        # æ£€æŸ¥åŠŸèƒ½å¯ç”¨æ€§
        if AUDIOSEAL_AVAILABLE:
            print("âœ… AudioSeal éŸ³é¢‘æ°´å°åŠŸèƒ½å¯ç”¨")
        else:
            print("âŒ AudioSeal ä¸å¯ç”¨ - è¯·å®‰è£…AudioSeal")
        
        if HAS_BARK:
            print("âœ… Bark æ–‡æœ¬è½¬éŸ³é¢‘åŠŸèƒ½å¯ç”¨")
        else:
            print("âŒ Bark ä¸å¯ç”¨ - è¯·å®‰è£…Bark")
        
        # æ£€æŸ¥è®¾å¤‡
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ğŸ–¥ï¸  è®¡ç®—è®¾å¤‡: {device}")
        
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            print(f"   GPU: {gpu_name} ({gpu_memory:.1f}GB)")
        
        print()
    
    def create_test_audio(self, duration: float = 3.0) -> torch.Tensor:
        """
        åˆ›å»ºæµ‹è¯•éŸ³é¢‘
        
        Args:
            duration: éŸ³é¢‘æ—¶é•¿(ç§’)
            
        Returns:
            torch.Tensor: æµ‹è¯•éŸ³é¢‘
        """
        sample_rate = 16000
        t = torch.linspace(0, duration, int(sample_rate * duration))
        
        # åˆ›å»ºå’Œå¼¦ (Cå¤§è°ƒå’Œå¼¦: C-E-G)
        frequencies = [261.63, 329.63, 392.00]  # C4, E4, G4
        audio = torch.zeros_like(t)
        
        for freq in frequencies:
            audio += 0.3 * torch.sin(2 * torch.pi * freq * t)
        
        # æ·»åŠ åŒ…ç»œä½¿å£°éŸ³æ›´è‡ªç„¶
        envelope = torch.exp(-t * 0.5)  # æŒ‡æ•°è¡°å‡
        audio = audio * envelope
        
        return audio.unsqueeze(0)  # æ·»åŠ é€šé“ç»´åº¦
    
    def demo_basic_watermarking(self):
        """åŸºç¡€æ°´å°æ¼”ç¤º (ä»…AudioSeal)"""
        print("ğŸ”¹ åŸºç¡€éŸ³é¢‘æ°´å°æ¼”ç¤º")
        print("-" * 30)
        
        if not AUDIOSEAL_AVAILABLE:
            print("âŒ AudioSealä¸å¯ç”¨ï¼Œè·³è¿‡åŸºç¡€æ¼”ç¤º")
            return
        
        # åˆ›å»ºæµ‹è¯•éŸ³é¢‘
        print("1. åˆ›å»ºæµ‹è¯•éŸ³é¢‘...")
        test_audio = self.create_test_audio(duration=2.0)
        print(f"   éŸ³é¢‘å½¢çŠ¶: {test_audio.shape}")
        print(f"   æ—¶é•¿: {test_audio.size(-1) / 16000:.2f}ç§’")
        
        # ä¿å­˜åŸå§‹éŸ³é¢‘
        original_path = self.output_dir / "demo_original.wav"
        AudioIOUtils.save_audio(test_audio, str(original_path), 16000)
        print(f"   åŸå§‹éŸ³é¢‘å·²ä¿å­˜: {original_path}")
        
        # åµŒå…¥æ°´å°
        print("\n2. åµŒå…¥æ°´å°...")
        test_message = "AudioSeal_Demo_2025"
        print(f"   æ°´å°æ¶ˆæ¯: '{test_message}'")
        
        start_time = time.time()
        watermarked_audio = self.audio_watermark.embed_watermark(
            test_audio, test_message
        )
        embed_time = time.time() - start_time
        
        print(f"   åµŒå…¥æ—¶é—´: {embed_time:.2f}ç§’")
        
        # ä¿å­˜å¸¦æ°´å°éŸ³é¢‘
        watermarked_path = self.output_dir / "demo_watermarked.wav"
        AudioIOUtils.save_audio(watermarked_audio, str(watermarked_path), 16000)
        print(f"   å¸¦æ°´å°éŸ³é¢‘å·²ä¿å­˜: {watermarked_path}")
        
        # æå–æ°´å°
        print("\n3. æå–æ°´å°...")
        start_time = time.time()
        result = self.audio_watermark.extract_watermark(watermarked_audio)
        extract_time = time.time() - start_time
        
        print(f"   æå–æ—¶é—´: {extract_time:.2f}ç§’")
        print(f"   æ£€æµ‹ç»“æœ: {result['detected']}")
        print(f"   ç½®ä¿¡åº¦: {result['confidence']:.3f}")
        print(f"   æå–æ¶ˆæ¯: '{result['message']}'")
        
        # è´¨é‡è¯„ä¼°
        print("\n4. è´¨é‡è¯„ä¼°...")
        quality = self.audio_watermark.evaluate_quality(test_audio, watermarked_audio)
        print(f"   ä¿¡å™ªæ¯” (SNR): {quality['snr_db']:.2f} dB")
        print(f"   å‡æ–¹è¯¯å·® (MSE): {quality['mse']:.6f}")
        print(f"   ç›¸å…³æ€§: {quality['correlation']:.4f}")
        
        # éªŒè¯
        success = result['detected'] and test_message in result['message']
        print(f"\n5. éªŒè¯ç»“æœ: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
        
        print()
    
    def demo_text_to_audio_watermark(self):
        """æ–‡æœ¬è½¬éŸ³é¢‘æ°´å°æ¼”ç¤º (éœ€è¦Bark)"""
        print("ğŸ”¹ æ–‡æœ¬è½¬éŸ³é¢‘æ°´å°æ¼”ç¤º")
        print("-" * 30)
        
        if not HAS_BARK:
            print("âŒ Barkä¸å¯ç”¨ï¼Œè·³è¿‡æ–‡æœ¬è½¬éŸ³é¢‘æ¼”ç¤º")
            return
        
        if not AUDIOSEAL_AVAILABLE:
            print("âŒ AudioSealä¸å¯ç”¨ï¼Œè·³è¿‡æ¼”ç¤º")
            return
        
        # è®¾ç½®æ–‡æœ¬å’Œæ¶ˆæ¯
        text_prompts = [
            "Hello, this is a demonstration of text to speech with watermark.",
            "ä½ å¥½ï¼Œè¿™æ˜¯æ–‡æœ¬è½¬è¯­éŸ³åŠ æ°´å°çš„æ¼”ç¤ºã€‚",
            "Welcome to the audio watermarking system."
        ]
        
        for i, prompt in enumerate(text_prompts):
            print(f"\n{i+1}. å¤„ç†æ–‡æœ¬: '{prompt[:40]}...'")
            
            # ç”Ÿæˆå¸¦æ°´å°çš„éŸ³é¢‘
            message = f"demo_message_{i+1}"
            print(f"   æ°´å°æ¶ˆæ¯: '{message}'")
            
            try:
                print("   æ­£åœ¨ç”ŸæˆéŸ³é¢‘...")
                start_time = time.time()
                
                generated_audio = self.audio_watermark.generate_audio_with_watermark(
                    prompt=prompt,
                    message=message,
                    temperature=0.7,
                    seed=42 + i  # ä¸åŒçš„ç§å­äº§ç”Ÿä¸åŒçš„è¯­éŸ³
                )
                
                generation_time = time.time() - start_time
                print(f"   ç”Ÿæˆæ—¶é—´: {generation_time:.2f}ç§’")
                print(f"   éŸ³é¢‘å½¢çŠ¶: {generated_audio.shape}")
                print(f"   æ—¶é•¿: {generated_audio.size(-1) / 16000:.2f}ç§’")
                
                # ä¿å­˜ç”Ÿæˆçš„éŸ³é¢‘
                output_path = self.output_dir / f"demo_generated_{i+1}.wav"
                AudioIOUtils.save_audio(generated_audio, str(output_path), 16000)
                print(f"   éŸ³é¢‘å·²ä¿å­˜: {output_path}")
                
                # éªŒè¯æ°´å°
                print("   éªŒè¯æ°´å°...")
                result = self.audio_watermark.extract_watermark(generated_audio)
                print(f"   æ£€æµ‹: {result['detected']}, ç½®ä¿¡åº¦: {result['confidence']:.3f}")
                print(f"   æ¶ˆæ¯: '{result['message']}'")
                
            except Exception as e:
                print(f"   âŒ ç”Ÿæˆå¤±è´¥: {e}")
        
        print()
    
    def demo_batch_processing(self):
        """æ‰¹å¤„ç†æ¼”ç¤º"""
        print("ğŸ”¹ æ‰¹å¤„ç†æ¼”ç¤º")
        print("-" * 30)
        
        if not AUDIOSEAL_AVAILABLE:
            print("âŒ AudioSealä¸å¯ç”¨ï¼Œè·³è¿‡æ‰¹å¤„ç†æ¼”ç¤º")
            return
        
        # åˆ›å»ºå¤šä¸ªæµ‹è¯•éŸ³é¢‘
        num_audios = 5
        test_audios = []
        test_messages = []
        
        print(f"1. åˆ›å»º {num_audios} ä¸ªæµ‹è¯•éŸ³é¢‘...")
        for i in range(num_audios):
            # åˆ›å»ºä¸åŒé¢‘ç‡çš„æµ‹è¯•éŸ³é¢‘
            duration = 1.0 + i * 0.5  # ä¸åŒæ—¶é•¿
            audio = self.create_test_audio(duration)
            
            # æ·»åŠ ä¸€äº›éšæœºå˜åŒ–
            audio = audio + 0.05 * torch.randn_like(audio)
            
            test_audios.append(audio)
            test_messages.append(f"batch_message_{i+1}")
        
        print(f"   åˆ›å»ºå®Œæˆï¼ŒéŸ³é¢‘æ—¶é•¿èŒƒå›´: {[a.size(-1)/16000 for a in test_audios]}")
        
        # æ‰¹é‡åµŒå…¥
        print("\n2. æ‰¹é‡åµŒå…¥æ°´å°...")
        start_time = time.time()
        watermarked_audios = self.audio_watermark.batch_embed(
            test_audios, test_messages
        )
        batch_embed_time = time.time() - start_time
        
        success_count = sum(1 for a in watermarked_audios if a is not None)
        print(f"   æ‰¹é‡åµŒå…¥å®Œæˆ: {success_count}/{num_audios} æˆåŠŸ")
        print(f"   æ€»è€—æ—¶: {batch_embed_time:.2f}ç§’")
        print(f"   å¹³å‡è€—æ—¶: {batch_embed_time/num_audios:.2f}ç§’/éŸ³é¢‘")
        
        # æ‰¹é‡æå–
        print("\n3. æ‰¹é‡æå–æ°´å°...")
        start_time = time.time()
        results = self.audio_watermark.batch_extract(watermarked_audios)
        batch_extract_time = time.time() - start_time
        
        print(f"   æ‰¹é‡æå–å®Œæˆï¼Œæ€»è€—æ—¶: {batch_extract_time:.2f}ç§’")
        print(f"   å¹³å‡è€—æ—¶: {batch_extract_time/num_audios:.2f}ç§’/éŸ³é¢‘")
        
        # éªŒè¯ç»“æœ
        print("\n4. éªŒè¯ç»“æœ:")
        detected_count = 0
        for i, result in enumerate(results):
            detected = result.get('detected', False)
            confidence = result.get('confidence', 0.0)
            message = result.get('message', '')
            
            if detected:
                detected_count += 1
            
            print(f"   éŸ³é¢‘ {i+1}: {'âœ…' if detected else 'âŒ'} "
                  f"ç½®ä¿¡åº¦={confidence:.3f}, æ¶ˆæ¯='{message}'")
        
        print(f"\n5. æ€»ä½“ç»“æœ: {detected_count}/{num_audios} æ£€æµ‹æˆåŠŸ "
              f"({detected_count/num_audios*100:.1f}%)")
        
        print()
    
    def demo_robustness_test(self):
        """é²æ£’æ€§æµ‹è¯•æ¼”ç¤º"""
        print("ğŸ”¹ é²æ£’æ€§æµ‹è¯•æ¼”ç¤º")
        print("-" * 30)
        
        if not AUDIOSEAL_AVAILABLE:
            print("âŒ AudioSealä¸å¯ç”¨ï¼Œè·³è¿‡é²æ£’æ€§æµ‹è¯•")
            return
        
        from src.audio_watermark.utils import AudioProcessingUtils
        
        # åˆ›å»ºæµ‹è¯•éŸ³é¢‘
        test_audio = self.create_test_audio(duration=3.0)
        test_message = "robustness_test_2025"
        
        print("1. åµŒå…¥æ°´å°...")
        watermarked_audio = self.audio_watermark.embed_watermark(test_audio, test_message)
        print(f"   åŸå§‹éŸ³é¢‘æ£€æµ‹åŸºçº¿...")
        
        baseline_result = self.audio_watermark.extract_watermark(watermarked_audio)
        print(f"   åŸºçº¿ç½®ä¿¡åº¦: {baseline_result['confidence']:.3f}")
        
        # æµ‹è¯•ä¸åŒçš„æ”»å‡»
        print("\n2. å™ªå£°æ”»å‡»æµ‹è¯•:")
        snr_levels = [20, 15, 10, 5, 0]
        
        for snr_db in snr_levels:
            noisy_audio = AudioProcessingUtils.add_noise(
                watermarked_audio, noise_type='white', snr_db=snr_db
            )
            
            result = self.audio_watermark.extract_watermark(noisy_audio)
            status = "âœ…" if result['detected'] else "âŒ"
            
            print(f"   SNR {snr_db:2d}dB: {status} ç½®ä¿¡åº¦={result['confidence']:.3f}")
        
        print("\n3. å½’ä¸€åŒ–æµ‹è¯•:")
        
        # å¹…åº¦ç¼©æ”¾æµ‹è¯•
        scale_factors = [0.1, 0.5, 2.0, 5.0]
        for scale in scale_factors:
            scaled_audio = watermarked_audio * scale
            # é‡æ–°å½’ä¸€åŒ–åˆ°[-1, 1]
            scaled_audio = AudioProcessingUtils.normalize(scaled_audio)
            
            result = self.audio_watermark.extract_watermark(scaled_audio)
            status = "âœ…" if result['detected'] else "âŒ"
            
            print(f"   ç¼©æ”¾ {scale:3.1f}x: {status} ç½®ä¿¡åº¦={result['confidence']:.3f}")
        
        print()
    
    def demo_visualization(self):
        """å¯è§†åŒ–æ¼”ç¤º"""
        print("ğŸ”¹ éŸ³é¢‘å¯è§†åŒ–æ¼”ç¤º")
        print("-" * 30)
        
        try:
            import matplotlib.pyplot as plt
            
            # åˆ›å»ºæµ‹è¯•éŸ³é¢‘
            test_audio = self.create_test_audio(duration=2.0)
            test_message = "visualization_demo"
            
            # åµŒå…¥æ°´å°
            watermarked_audio = self.audio_watermark.embed_watermark(test_audio, test_message)
            
            # ç”Ÿæˆå¯è§†åŒ–
            print("1. ç”Ÿæˆæ³¢å½¢å›¾...")
            waveform_path = self.output_dir / "demo_waveform.png"
            AudioVisualizationUtils.plot_waveform(
                test_audio, 16000, "åŸå§‹éŸ³é¢‘æ³¢å½¢", str(waveform_path)
            )
            print(f"   æ³¢å½¢å›¾å·²ä¿å­˜: {waveform_path}")
            
            print("2. ç”Ÿæˆé¢‘è°±å›¾...")
            spectrogram_path = self.output_dir / "demo_spectrogram.png"
            AudioVisualizationUtils.plot_spectrogram(
                watermarked_audio, 16000, "å¸¦æ°´å°éŸ³é¢‘é¢‘è°±å›¾", str(spectrogram_path)
            )
            print(f"   é¢‘è°±å›¾å·²ä¿å­˜: {spectrogram_path}")
            
        except ImportError:
            print("âŒ matplotlibä¸å¯ç”¨ï¼Œè·³è¿‡å¯è§†åŒ–æ¼”ç¤º")
        except Exception as e:
            print(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
        
        print()
    
    def demo_unified_interface(self):
        """ç»Ÿä¸€æ¥å£æ¼”ç¤º"""
        print("ğŸ”¹ ç»Ÿä¸€æ¥å£æ¼”ç¤º")
        print("-" * 30)
        
        # æ£€æŸ¥æ”¯æŒçš„ç®—æ³•
        algorithms = self.unified_tool.get_supported_algorithms()
        print("æ”¯æŒçš„ç®—æ³•:")
        for modality, algs in algorithms.items():
            print(f"  {modality}: {algs}")
        
        if 'audio' not in algorithms:
            print("âŒ ç»Ÿä¸€å·¥å…·ä¸­éŸ³é¢‘åŠŸèƒ½ä¸å¯ç”¨")
            return
        
        # ä½¿ç”¨ç»Ÿä¸€æ¥å£è¿›è¡Œæ¼”ç¤º
        test_audio = self.create_test_audio(duration=1.5)
        test_message = "unified_interface_demo"
        
        print(f"\nä½¿ç”¨ç»Ÿä¸€æ¥å£å¤„ç†éŸ³é¢‘...")
        print(f"æ°´å°æ¶ˆæ¯: '{test_message}'")
        
        try:
            # åµŒå…¥
            watermarked = self.unified_tool.embed_audio_watermark(
                test_audio, test_message
            )
            print("âœ… ç»Ÿä¸€æ¥å£åµŒå…¥æˆåŠŸ")
            
            # æå–
            result = self.unified_tool.extract_audio_watermark(watermarked)
            print(f"âœ… ç»Ÿä¸€æ¥å£æå–æˆåŠŸ: {result['detected']}, "
                  f"ç½®ä¿¡åº¦={result['confidence']:.3f}")
            
            # è´¨é‡è¯„ä¼°
            quality = self.unified_tool.evaluate_audio_quality(test_audio, watermarked)
            print(f"âœ… è´¨é‡è¯„ä¼°: SNR={quality['snr_db']:.2f}dB")
            
        except Exception as e:
            print(f"âŒ ç»Ÿä¸€æ¥å£æµ‹è¯•å¤±è´¥: {e}")
        
        print()
    
    def run_demo(self, mode: str = "basic"):
        """
        è¿è¡Œæ¼”ç¤º
        
        Args:
            mode: æ¼”ç¤ºæ¨¡å¼ ('basic', 'full', 'custom')
        """
        self.print_system_status()
        self.setup_tools()
        
        print(f"ğŸ“‹ æ¼”ç¤ºæ¨¡å¼: {mode}")
        print("=" * 50)
        
        if mode == "basic":
            # åŸºç¡€æ¼”ç¤º
            self.demo_basic_watermarking()
            self.demo_batch_processing()
            
        elif mode == "full":
            # å®Œæ•´æ¼”ç¤º
            self.demo_basic_watermarking()
            self.demo_text_to_audio_watermark()
            self.demo_batch_processing()
            self.demo_robustness_test()
            self.demo_unified_interface()
            self.demo_visualization()
            
        elif mode == "custom":
            # è‡ªå®šä¹‰æ¼”ç¤º - è®©ç”¨æˆ·é€‰æ‹©
            self._interactive_demo()
        
        print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶ä¿å­˜åœ¨: {self.output_dir}")
    
    def _interactive_demo(self):
        """äº¤äº’å¼æ¼”ç¤º"""
        demos = {
            '1': ('åŸºç¡€æ°´å°', self.demo_basic_watermarking),
            '2': ('æ–‡æœ¬è½¬éŸ³é¢‘æ°´å°', self.demo_text_to_audio_watermark),
            '3': ('æ‰¹å¤„ç†', self.demo_batch_processing),
            '4': ('é²æ£’æ€§æµ‹è¯•', self.demo_robustness_test),
            '5': ('ç»Ÿä¸€æ¥å£', self.demo_unified_interface),
            '6': ('å¯è§†åŒ–', self.demo_visualization),
        }
        
        print("ğŸ¯ é€‰æ‹©è¦è¿è¡Œçš„æ¼”ç¤º:")
        for key, (name, _) in demos.items():
            print(f"  {key}. {name}")
        print("  a. è¿è¡Œå…¨éƒ¨")
        print("  q. é€€å‡º")
        
        while True:
            choice = input("\nè¯·é€‰æ‹© (1-6/a/q): ").strip().lower()
            
            if choice == 'q':
                break
            elif choice == 'a':
                for _, func in demos.values():
                    func()
                break
            elif choice in demos:
                _, func = demos[choice]
                func()
            else:
                print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="éŸ³é¢‘æ°´å°ç«¯åˆ°ç«¯æ¼”ç¤º")
    parser.add_argument(
        "--mode", 
        choices=['basic', 'full', 'custom'],
        default='basic',
        help="æ¼”ç¤ºæ¨¡å¼"
    )
    parser.add_argument(
        "--output", 
        default="demo_outputs/audio",
        help="è¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--log-level",
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        default='INFO',
        help="æ—¥å¿—çº§åˆ«"
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=getattr(logging, args.log_level),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # è¿è¡Œæ¼”ç¤º
    try:
        demo = AudioWatermarkDemo(args.output)
        demo.run_demo(args.mode)
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()