#!/usr/bin/env python3
"""
HunyuanVideoè¾“å‡ºè°ƒè¯•è„šæœ¬
ä¸“é—¨ç”¨äºè¯Šæ–­é»‘å±è§†é¢‘ç”Ÿæˆé—®é¢˜
"""

import torch
import numpy as np
import logging
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.video_watermark.hunyuan_video_generator import create_hunyuan_generator

def debug_hunyuan_output():
    """è°ƒè¯•HunyuanVideoçš„åŸå§‹è¾“å‡º"""
    
    # è®¾ç½®è¯¦ç»†æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')
    
    print("ğŸ” HunyuanVideoè¾“å‡ºè°ƒè¯•åˆ†æ")
    print("=" * 50)
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = create_hunyuan_generator()
    
    # æ›´ä¿å®ˆçš„æµ‹è¯•å‚æ•°ï¼ˆé¿å…å†…å­˜é—®é¢˜ï¼‰
    test_params = {
        'prompt': 'ä¸€æœµçº¢è‰²çš„èŠ±',
        'num_frames': 9,   # æ›´å°‘çš„å¸§æ•°
        'height': 256,     # æ›´å°çš„åˆ†è¾¨ç‡
        'width': 256,
        'num_inference_steps': 5,  # æ›´å°‘çš„æ¨ç†æ­¥æ•°
        'seed': 42
    }
    
    print(f"æµ‹è¯•å‚æ•°: {test_params}")
    
    try:
        # åŠ è½½ç®¡é“
        generator._load_pipeline()
        
        print("\nğŸ“‹ ç®¡é“ä¿¡æ¯:")
        print(f"  Pipelineç±»å‹: {type(generator.pipeline)}")
        print(f"  è®¾å¤‡: {generator.device}")
        print(f"  æ•°æ®ç±»å‹: {generator.pipeline.dtype if hasattr(generator.pipeline, 'dtype') else 'unknown'}")
        
        # æ‰‹åŠ¨è°ƒç”¨ç®¡é“ï¼Œè·Ÿè¸ªæ¯ä¸€æ­¥
        print(f"\nğŸ¬ å¼€å§‹ç”Ÿæˆè§†é¢‘...")
        
        with torch.no_grad():
            # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§
            torch.manual_seed(42)
            if torch.cuda.is_available():
                torch.cuda.manual_seed(42)
            
            result = generator.pipeline(
                prompt=test_params['prompt'],
                num_frames=test_params['num_frames'],
                height=test_params['height'],
                width=test_params['width'],
                num_inference_steps=test_params['num_inference_steps'],
                guidance_scale=6.0,
                generator=torch.Generator(device=generator.device).manual_seed(42)
            )
            
            print(f"\nğŸ“¤ ç®¡é“è¿”å›ç»“æœç±»å‹: {type(result)}")
            
            # è¯¦ç»†åˆ†æresultç»“æ„
            if hasattr(result, '__dict__'):
                print(f"Resultå±æ€§: {list(result.__dict__.keys())}")
                for attr_name in result.__dict__.keys():
                    attr_value = getattr(result, attr_name)
                    print(f"  {attr_name}: {type(attr_value)}")
                    
                    if attr_name == 'frames' and attr_value is not None:
                        print(f"    framesè¯¦æƒ…:")
                        print(f"      ç±»å‹: {type(attr_value)}")
                        print(f"      é•¿åº¦: {len(attr_value) if hasattr(attr_value, '__len__') else 'N/A'}")
                        
                        if hasattr(attr_value, '__len__') and len(attr_value) > 0:
                            first_batch = attr_value[0]
                            print(f"      first_batchç±»å‹: {type(first_batch)}")
                            print(f"      first_batché•¿åº¦: {len(first_batch) if hasattr(first_batch, '__len__') else 'N/A'}")
                            
                            if hasattr(first_batch, '__len__') and len(first_batch) > 0:
                                first_frame = first_batch[0]
                                print(f"      first_frameç±»å‹: {type(first_frame)}")
                                
                                if hasattr(first_frame, 'size'):
                                    print(f"      first_frameå¤§å°: {first_frame.size}")
                                    
                                    # è½¬æ¢ä¸ºnumpyåˆ†æåƒç´ å€¼
                                    frame_array = np.array(first_frame)
                                    print(f"      numpyå½¢çŠ¶: {frame_array.shape}")
                                    print(f"      æ•°æ®ç±»å‹: {frame_array.dtype}")
                                    print(f"      å€¼åŸŸ: [{frame_array.min():.3f}, {frame_array.max():.3f}]")
                                    print(f"      å¹³å‡å€¼: {frame_array.mean():.3f}")
                                    print(f"      æ ‡å‡†å·®: {frame_array.std():.3f}")
                                    
                                    # æ£€æŸ¥æ˜¯å¦åŒ…å«NaNæˆ–inf
                                    has_nan = np.isnan(frame_array).any()
                                    has_inf = np.isinf(frame_array).any()
                                    print(f"      åŒ…å«NaN: {has_nan}")
                                    print(f"      åŒ…å«Inf: {has_inf}")
                                    
                                    # åˆ†æåƒç´ åˆ†å¸ƒ
                                    unique_values = np.unique(frame_array)
                                    print(f"      å”¯ä¸€å€¼æ•°é‡: {len(unique_values)}")
                                    if len(unique_values) <= 10:
                                        print(f"      å”¯ä¸€å€¼: {unique_values}")
                                    
                                    # æ£€æŸ¥æ¯ä¸ªé€šé“
                                    if len(frame_array.shape) == 3 and frame_array.shape[2] == 3:
                                        for i, color in enumerate(['R', 'G', 'B']):
                                            channel = frame_array[:, :, i]
                                            print(f"      {color}é€šé“: [{channel.min():.3f}, {channel.max():.3f}], å‡å€¼={channel.mean():.3f}")
            
            # å°è¯•è·å–è§†é¢‘å¸§
            if hasattr(result, 'frames') and result.frames is not None:
                video_frames = result.frames[0]
            elif hasattr(result, 'videos') and result.videos is not None:
                video_frames = result.videos[0]
            elif isinstance(result, (list, tuple)) and len(result) > 0:
                video_frames = result[0]
            else:
                video_frames = result
                
            print(f"\nğŸï¸ æå–çš„video_frames:")
            print(f"  ç±»å‹: {type(video_frames)}")
            
            if isinstance(video_frames, list) and len(video_frames) > 0:
                print(f"  åˆ—è¡¨é•¿åº¦: {len(video_frames)}")
                print(f"  ç¬¬ä¸€å¸§ç±»å‹: {type(video_frames[0])}")
                
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å¸§éƒ½æ˜¯é»‘è‰²çš„
                all_black = True
                for i, frame in enumerate(video_frames[:3]):  # æ£€æŸ¥å‰3å¸§
                    if hasattr(frame, 'convert'):
                        # PIL Image
                        img_array = np.array(frame.convert('RGB'))
                        max_val = img_array.max()
                        mean_val = img_array.mean()
                        print(f"  å¸§{i}: æœ€å¤§å€¼={max_val}, å¹³å‡å€¼={mean_val:.3f}")
                        if max_val > 0:
                            all_black = False
                
                print(f"  æ˜¯å¦å…¨é»‘: {all_black}")
            
            # ä¿å­˜ä¸€ä¸ªæµ‹è¯•å¸§æŸ¥çœ‹
            if isinstance(video_frames, list) and len(video_frames) > 0:
                test_frame = video_frames[0]
                if hasattr(test_frame, 'save'):
                    test_frame.save("debug_first_frame.png")
                    print(f"\nğŸ’¾ ç¬¬ä¸€å¸§å·²ä¿å­˜ä¸º debug_first_frame.png")
                    
                    # æ£€æŸ¥ä¿å­˜çš„æ–‡ä»¶
                    import os
                    file_size = os.path.getsize("debug_first_frame.png") / 1024
                    print(f"  æ–‡ä»¶å¤§å°: {file_size:.1f} KB")
    
    except Exception as e:
        print(f"\nâŒ è°ƒè¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    debug_hunyuan_output()