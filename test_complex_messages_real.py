#!/usr/bin/env python3
"""
å¤æ‚æ··åˆæ¶ˆæ¯çš„çœŸå®æ°´å°åµŒå…¥å’Œæå–æµ‹è¯•
æµ‹è¯•åƒ"alibaba20250725"è¿™æ ·çš„å¤æ‚å­—ç¬¦ä¸²åœ¨çœŸå®æ¨¡å‹ä¸Šçš„æ°´å°æ•ˆæœ
"""

import os
import sys
import yaml
import torch
import time
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(__file__))

def load_optimized_config():
    """åŠ è½½ä¼˜åŒ–çš„é…ç½®"""
    with open('config/text_config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # é’ˆå¯¹å¤æ‚æ¶ˆæ¯çš„ä¼˜åŒ–é…ç½®
    config['max_new_tokens'] = 300  # æ›´é•¿çš„æ–‡æœ¬æ”¯æŒå¤šæ®µæ¶ˆæ¯
    config['num_beams'] = 1  # åŠ é€Ÿæµ‹è¯•
    config['lm_params']['message_len'] = 10
    config['wm_params']['encode_ratio'] = 8  # é€‚ä¸­çš„ç¼–ç æ¯”ç‡
    config['confidence_threshold'] = 0.5  # é€‚ä¸­çš„ç½®ä¿¡åº¦é˜ˆå€¼
    
    return config

def test_complex_message_formats():
    """æµ‹è¯•å¤æ‚æ¶ˆæ¯æ ¼å¼çš„è½¬æ¢"""
    print("=== å¤æ‚æ¶ˆæ¯æ ¼å¼è½¬æ¢æµ‹è¯• ===\n")
    
    from src.text_watermark.credid_watermark import CredIDWatermark
    
    config = load_optimized_config()
    watermark = CredIDWatermark(config)
    
    # çœŸå®ä¸–ç•Œçš„å¤æ‚æ¶ˆæ¯
    complex_messages = [
        # 1. å…¬å¸+æ—¥æœŸæ ¼å¼
        {
            "message": "alibaba20250725",
            "description": "å…¬å¸å + æ—¥æœŸ",
            "expected_segments": ["alibaba", "2025", "0725"]
        },
        # 2. ç”¨æˆ·IDæ ¼å¼
        {
            "message": "user123456789",
            "description": "ç”¨æˆ·å‰ç¼€ + é•¿æ•°å­—ID",
            "expected_segments": ["user", "1234", "5678", "9"]
        },
        # 3. ç‰ˆæœ¬å·æ ¼å¼
        {
            "message": "version2024beta3",
            "description": "ç‰ˆæœ¬ + å¹´ä»½ + ç±»å‹ + ç‰ˆæœ¬å·",
            "expected_segments": ["version", "2024", "beta", "3"]
        },
        # 4. APIå¯†é’¥æ ¼å¼
        {
            "message": "key2025abc123def456",
            "description": "å‰ç¼€ + å¹´ä»½ + æ··åˆç ",
            "expected_segments": ["key", "2025", "abc", "123", "def", "456"]
        },
        # 5. æ—¶é—´æˆ³æ ¼å¼
        {
            "message": "session20250725143052",
            "description": "ä¼šè¯ + å®Œæ•´æ—¶é—´æˆ³",
            "expected_segments": ["session", "2025", "0725", "1430", "52"]
        },
        # 6. äº§å“ä»£ç 
        {
            "message": "iphone15pro256gb",
            "description": "äº§å“ + å‹å· + ç‰ˆæœ¬ + å®¹é‡",
            "expected_segments": ["iphone", "15", "pro", "256", "gb"]
        },
        # 7. è®¢å•å·
        {
            "message": "order2025010100123",
            "description": "è®¢å• + æ—¥æœŸ + åºå·",
            "expected_segments": ["order", "2025", "0101", "0012", "3"]
        }
    ]
    
    for i, case in enumerate(complex_messages, 1):
        message = case["message"]
        description = case["description"]
        
        print(f"{i}. ğŸ“ æ¶ˆæ¯: '{message}'")
        print(f"   ğŸ’­ æè¿°: {description}")
        print(f"   ğŸ“ é•¿åº¦: {len(message)} å­—ç¬¦")
        
        # æµ‹è¯•ä¸åŒçš„åˆ†å‰²æ¨¡å¼
        modes = ['auto', 'smart', 'whole']
        for mode in modes:
            try:
                segments = watermark._message_to_binary(message, mode)
                print(f"   {mode:>6} æ¨¡å¼: {segments} (å…±{len(segments)}æ®µ)")
                
                if mode == 'smart':
                    text_segments = watermark._smart_segment_string(message)
                    print(f"           åˆ†å‰²ä¸º: {text_segments}")
                    
                    # éªŒè¯åˆ†å‰²ç»“æœ
                    joined = ''.join(text_segments)
                    if joined == message:
                        print("           âœ… åˆ†å‰²æ— æŸ")
                    else:
                        print(f"           âš ï¸  åˆ†å‰²æœ‰æŸ: '{joined}' â‰  '{message}'")
                        
            except Exception as e:
                print(f"   {mode:>6} æ¨¡å¼: âŒ é”™è¯¯ - {e}")
        
        print()

def test_real_watermarking_with_complex_messages():
    """ä½¿ç”¨çœŸå®æ¨¡å‹æµ‹è¯•å¤æ‚æ¶ˆæ¯çš„æ°´å°åµŒå…¥å’Œæå–"""
    print("=== çœŸå®æ¨¡å‹å¤æ‚æ¶ˆæ¯æ°´å°æµ‹è¯• ===\n")
    
    # æ£€æŸ¥CUDA
    if torch.cuda.is_available():
        device_name = torch.cuda.get_device_name()
        memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"ğŸ”¥ CUDAå¯ç”¨: {device_name}")
        print(f"   æ˜¾å­˜: {memory_gb:.1f} GB\n")
    else:
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU\n")
    
    try:
        from src.text_watermark.credid_watermark import CredIDWatermark
        from transformers import AutoModelForCausalLM, AutoTokenizer
        
        config = load_optimized_config()
        print(f"ğŸ“‹ åŠ è½½é…ç½®...")
        print(f"   æ¨¡å‹: {config['model_name']}")
        print(f"   æœ€å¤§token: {config['max_new_tokens']}")
        print(f"   ç¼–ç æ¯”ç‡: {config['wm_params']['encode_ratio']}")
        
        # åŠ è½½æ¨¡å‹
        print(f"\nğŸ—ï¸  åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨...")
        model_name = config['model_name']
        
        start_time = time.time()
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForCausalLM.from_pretrained(
            model_name,
            device_map="auto",
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
        )
        
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        
        load_time = time.time() - start_time
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ ({load_time:.1f}s)")
        
        # åˆ›å»ºæ°´å°å¤„ç†å™¨
        watermark = CredIDWatermark(config)
        
        # æµ‹è¯•ç”¨ä¾‹ï¼šä¸åŒç±»å‹çš„å¤æ‚æ¶ˆæ¯
        test_cases = [

            {
                "name": "ç‰ˆæœ¬å·",
                "message": "v2024.1.5beta",
                "mode": "smart",
                "prompt": "The software release includes"
            },
            {
                "name": "APIå¯†é’¥",
                "message": "token2025abc123",
                "mode": "smart",
                "prompt": "The authentication service generated"
            },
            {
                "name": "æ—¶é—´æˆ³",
                "message": "log20250725143000",
                "mode": "smart",
                "prompt": "The system recorded"
            }
        ]
        
        successful_tests = 0
        total_tests = len(test_cases)
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\n--- æµ‹è¯• {i}/{total_tests}: {test_case['name']} ---")
            message = test_case['message']
            mode = test_case['mode']
            prompt = test_case['prompt']
            
            print(f"ğŸ¯ æ¶ˆæ¯: '{message}'")
            print(f"ğŸ“ æç¤º: '{prompt}'")
            print(f"ğŸ”§ åˆ†å‰²æ¨¡å¼: {mode}")
            
            try:
                # æ˜¾ç¤ºåˆ†å‰²ç»“æœ
                segments = watermark._smart_segment_string(message)
                print(f"   åˆ†å‰²ä¸º: {segments}")
                encoded = watermark._message_to_binary(message, mode)
                print(f"   ç¼–ç : {encoded}")
                
                # åµŒå…¥æ°´å°
                print(f"\nâš¡ å¼€å§‹åµŒå…¥...")
                embed_start = time.time()
                
                embed_result = watermark.embed(
                    model, tokenizer, prompt, message, segmentation_mode=mode
                )
                
                embed_time = time.time() - embed_start
                
                if embed_result['success']:
                    watermarked_text = embed_result['watermarked_text']
                    print(f"âœ… åµŒå…¥æˆåŠŸ ({embed_time:.1f}s)")
                    print(f"ğŸ“„ ç”Ÿæˆæ–‡æœ¬: {watermarked_text[:150]}...")
                    print(f"ğŸ“Š åŸå§‹æ¶ˆæ¯: {embed_result['original_message']}")
                    print(f"ğŸ”¢ ç¼–ç å½¢å¼: {embed_result['binary_message']}")
                    print(f"ğŸ“ æ–‡æœ¬é•¿åº¦: {len(watermarked_text)} å­—ç¬¦")
                    
                    # æå–æ°´å° - å…ˆå°è¯•å€™é€‰æœç´¢ï¼Œå¤±è´¥åˆ™å…¨èŒƒå›´æœç´¢
                    print(f"\nğŸ” å¼€å§‹æå–...")
                    extract_start = time.time()
                    
                    # æ–¹æ¡ˆ1ï¼šé™å®šå€™é€‰æœç´¢ï¼ˆå¿«é€Ÿï¼‰
                    candidates = [message, "token2025abc123", "v2024.1.5beta", "log20250725143000"]
                    extract_result = watermark.extract(
                        watermarked_text,
                        model=model,
                        tokenizer=tokenizer,
                        candidates_messages=candidates
                    )
                    
                    extract_time = time.time() - extract_start
                    
                    if extract_result['success']:
                        print(f"âœ… æå–æˆåŠŸ ({extract_time:.1f}s)")
                        print(f"ğŸ¯ æå–æ¶ˆæ¯: {extract_result['extracted_message']}")
                        print(f"ğŸ“ˆ ç½®ä¿¡åº¦: {extract_result['confidence']:.3f}")
                        print(f"ğŸ”¢ è§£ç å½¢å¼: {extract_result['binary_message']}")
                        
                        # éªŒè¯åŒ¹é…
                        extracted = str(extract_result['extracted_message'])
                        original = str(embed_result['original_message'])
                        
                        if extracted == original:
                            print(f"ğŸ¯ æ¶ˆæ¯åŒ¹é…: âœ… å®Œå…¨æ­£ç¡®")
                            successful_tests += 1
                        elif message in extracted or any(seg in extracted for seg in segments):
                            print(f"ğŸ¯ æ¶ˆæ¯åŒ¹é…: ğŸ”¶ éƒ¨åˆ†åŒ¹é…")
                            successful_tests += 0.5
                        else:
                            print(f"ğŸ¯ æ¶ˆæ¯åŒ¹é…: âŒ ä¸åŒ¹é…")
                            print(f"   æœŸæœ›: '{original}'")
                            print(f"   å®é™…: '{extracted}'")
                        
                        # åˆ†æå¤šæ®µæ¶ˆæ¯æ•ˆæœ
                        if len(embed_result['binary_message']) > 1:
                            print(f"ğŸ“Š å¤šæ®µåˆ†æ:")
                            print(f"   åµŒå…¥æ®µæ•°: {len(embed_result['binary_message'])}")
                            print(f"   æå–æ®µæ•°: {len(extract_result['binary_message'])}")
                            
                    else:
                        print(f"âŒ æå–å¤±è´¥: {extract_result.get('error', 'Unknown error')}")
                        print(f"   ç½®ä¿¡åº¦: {extract_result.get('confidence', 0):.3f}")
                        
                else:
                    print(f"âŒ åµŒå…¥å¤±è´¥: {embed_result.get('error', 'Unknown error')}")
                    
            except Exception as e:
                print(f"ğŸ’¥ æµ‹è¯•å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        # æµ‹è¯•ç»“æœæ€»ç»“
        print(f"\n=== æµ‹è¯•ç»“æœæ€»ç»“ ===")
        print(f"ğŸ¯ æˆåŠŸç‡: {successful_tests}/{total_tests} ({successful_tests/total_tests*100:.1f}%)")
        
        if successful_tests >= total_tests * 0.8:
            print("âœ… æ•´ä½“æµ‹è¯•æ•ˆæœ: ä¼˜ç§€")
        elif successful_tests >= total_tests * 0.6:
            print("ğŸ”¶ æ•´ä½“æµ‹è¯•æ•ˆæœ: è‰¯å¥½")
        else:
            print("âš ï¸  æ•´ä½“æµ‹è¯•æ•ˆæœ: éœ€è¦ä¼˜åŒ–")
            
    except Exception as e:
        print(f"ğŸ’¥ æµ‹è¯•åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def analyze_complex_message_performance():
    """åˆ†æå¤æ‚æ¶ˆæ¯çš„æ€§èƒ½ç‰¹å¾"""
    print("=== å¤æ‚æ¶ˆæ¯æ€§èƒ½åˆ†æ ===\n")
    
    from src.text_watermark.credid_watermark import CredIDWatermark
    
    config = load_optimized_config()
    watermark = CredIDWatermark(config)
    
    # æ€§èƒ½æµ‹è¯•æ¡ˆä¾‹
    perf_cases = [
        ("çŸ­æ¶ˆæ¯", "abc123", 1),
        ("ä¸­ç­‰æ¶ˆæ¯", "user20250725", 2),
        ("é•¿æ¶ˆæ¯", "alibaba20250725session", 3),
        ("è¶…é•¿æ¶ˆæ¯", "company2025Q1version1.2.3beta", 4),
        ("æé•¿æ¶ˆæ¯", "system20250725143052user123session456token", 6)
    ]
    
    print("æ¶ˆæ¯å¤æ‚åº¦ä¸åˆ†å‰²æ•ˆæœåˆ†æ:")
    print("-" * 60)
    
    for name, message, expected_segments in perf_cases:
        print(f"{name:>8}: '{message}'")
        
        # åˆ†æä¸åŒæ¨¡å¼çš„åˆ†å‰²æ•ˆæœ
        for mode in ['whole', 'auto', 'smart']:
            try:
                segments = watermark._message_to_binary(message, mode)
                segment_count = len(segments)
                
                # è®¡ç®—æ•ˆç‡æŒ‡æ ‡
                efficiency = min(segment_count / expected_segments, 1.0) * 100
                
                print(f"         {mode:>5}: {segment_count}æ®µ (æ•ˆç‡: {efficiency:.0f}%)")
                
                if mode == 'smart' and segment_count > 1:
                    text_segments = watermark._smart_segment_string(message)
                    print(f"               åˆ†å‰²: {text_segments}")
                    
            except Exception as e:
                print(f"         {mode:>5}: âŒ {e}")
        
        print()

def demo_usage_examples():
    """æ¼”ç¤ºä½¿ç”¨ç¤ºä¾‹"""
    print("=== ä½¿ç”¨ç¤ºä¾‹æ¼”ç¤º ===\n")
    
    examples = [
        {
            "scenario": "ç”¨æˆ·è¿½è¸ªæ°´å°",
            "code": '''
# åœºæ™¯ï¼šç”¨æˆ·ç”Ÿæˆå†…å®¹è¿½è¸ª
user_id = "user20250725001"
result = watermark.embed(model, tokenizer, prompt, user_id, "smart")

# åˆ†å‰²æ•ˆæœ: ["user", "2025", "0725", "001"]
# æ¯ä¸ªæ®µä¾æ¬¡åµŒå…¥åˆ°ç”Ÿæˆæ–‡æœ¬çš„ä¸åŒä½ç½®
''',
            "benefits": ["ç²¾ç¡®ç”¨æˆ·è¿½è¸ª", "æ—¶é—´æˆ³è®°å½•", "åºå·ç®¡ç†"]
        },
        {
            "scenario": "ç‰ˆæœ¬ä¿¡æ¯åµŒå…¥",
            "code": '''
# åœºæ™¯ï¼šAIæ¨¡å‹ç‰ˆæœ¬è¿½è¸ª
version = "gpt4.5turbo2024"
result = watermark.embed(model, tokenizer, prompt, version, "smart")

# åˆ†å‰²æ•ˆæœ: ["gpt", "4", "5", "turbo", "2024"]
# å®Œæ•´ç‰ˆæœ¬ä¿¡æ¯åˆ†æ®µåµŒå…¥
''',
            "benefits": ["ç‰ˆæœ¬è¿½æº¯", "æ¨¡å‹è¯†åˆ«", "å‘å¸ƒæ—¶é—´è®°å½•"]
        },
        {
            "scenario": "APIå¯†é’¥æ°´å°",
            "code": '''
# åœºæ™¯ï¼šAPIè°ƒç”¨è¿½è¸ª
api_key = "key2025abc123def"
result = watermark.embed(model, tokenizer, prompt, api_key, "smart")

# åˆ†å‰²æ•ˆæœ: ["key", "2025", "abc", "123", "def"]
# åˆ†æ®µåµŒå…¥æé«˜éšè”½æ€§
''',
            "benefits": ["APIè¿½è¸ª", "å¯†é’¥ç®¡ç†", "ä½¿ç”¨ç›‘æ§"]
        }
    ]
    
    for i, example in enumerate(examples, 1):
        print(f"{i}. ğŸ¯ {example['scenario']}")
        print("   ä»£ç ç¤ºä¾‹:")
        print(example['code'])
        print("   ä¼˜åŠ¿:")
        for benefit in example['benefits']:
            print(f"     â€¢ {benefit}")
        print()

if __name__ == "__main__":
    print("ğŸš€ å¤æ‚æ··åˆæ¶ˆæ¯çœŸå®æ°´å°æµ‹è¯•\n")
    
    # 1. æ¶ˆæ¯æ ¼å¼è½¬æ¢æµ‹è¯•
    test_complex_message_formats()
    
    # 2. æ€§èƒ½åˆ†æ
    analyze_complex_message_performance()
    
    # 3. ä½¿ç”¨ç¤ºä¾‹
    demo_usage_examples()
    
    # 4. çœŸå®æ¨¡å‹æµ‹è¯•ï¼ˆéœ€è¦ç”¨æˆ·ç¡®è®¤ï¼‰
    print("=" * 60)
    do_real_test = input("æ˜¯å¦è¿›è¡ŒçœŸå®æ¨¡å‹æ°´å°æµ‹è¯•ï¼Ÿ(éœ€è¦åŠ è½½å¤§æ¨¡å‹ï¼Œçº¦3-5åˆ†é’Ÿ) [y/N]: ").lower().strip()
    
    if do_real_test == 'y':
        test_real_watermarking_with_complex_messages()
    else:
        print("è·³è¿‡çœŸå®æ¨¡å‹æµ‹è¯•")
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ¯ **æ ¸å¿ƒèƒ½åŠ›æ€»ç»“**:")
    print("   âœ… æ™ºèƒ½åˆ†å‰²æ··åˆå­—æ¯æ•°å­—æ¶ˆæ¯")
    print("   âœ… æ”¯æŒå¤šç§åˆ†å‰²æ¨¡å¼ (auto/smart/whole)")
    print("   âœ… çœŸå®æ¨¡å‹åµŒå…¥å’Œæå–")
    print("   âœ… ä¿æŒé«˜ç²¾åº¦å’Œå¯é æ€§")
    print("   âœ… é€‚åº”å„ç§å®é™…åº”ç”¨åœºæ™¯") 